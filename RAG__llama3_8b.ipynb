{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10454c728a434c7f9afe6a0e7f8a4c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11e2590f11374553b122f7b55a38127b",
              "IPY_MODEL_32b04e2dbea245e9a4cb2b394afbb9f7",
              "IPY_MODEL_0e505cdfab654d67a18a88445c64f561"
            ],
            "layout": "IPY_MODEL_6be34d60460f478ebca44b0f9df5db56"
          }
        },
        "11e2590f11374553b122f7b55a38127b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05aac84f025a484abeb4d99d3049bba7",
            "placeholder": "​",
            "style": "IPY_MODEL_7fb091441c9a4e8db55d75598389e3ce",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "32b04e2dbea245e9a4cb2b394afbb9f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_150e72b2d08b4df2a756e0124a0f07f2",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dba4929b9ec24e599a14b51f41aa1b9b",
            "value": 25
          }
        },
        "0e505cdfab654d67a18a88445c64f561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3787eaa63864966b13cb4782e876bdd",
            "placeholder": "​",
            "style": "IPY_MODEL_dbe29551da92428392ffb7260ddf0ade",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.13kB/s]"
          }
        },
        "6be34d60460f478ebca44b0f9df5db56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05aac84f025a484abeb4d99d3049bba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb091441c9a4e8db55d75598389e3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "150e72b2d08b4df2a756e0124a0f07f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dba4929b9ec24e599a14b51f41aa1b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3787eaa63864966b13cb4782e876bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbe29551da92428392ffb7260ddf0ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93b4e10a352047dab76214c3902c14e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52918b695ae247309215b29ad2d0d04b",
              "IPY_MODEL_a96c6de0aabe4df782cc27c056eb66fc",
              "IPY_MODEL_dec5b2f3f74b42e087e25e1f8f001e46"
            ],
            "layout": "IPY_MODEL_9737dbdd1026491cae936e6e08453062"
          }
        },
        "52918b695ae247309215b29ad2d0d04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7f7eec0c4240c5b3d5d71d8e0666a2",
            "placeholder": "​",
            "style": "IPY_MODEL_c6122e5c2e4c47aa97f7dbfeeffc6548",
            "value": "config.json: 100%"
          }
        },
        "a96c6de0aabe4df782cc27c056eb66fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6037da069824295a696721672e29949",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a94f9be8e2994d949923b0287dccfa6b",
            "value": 482
          }
        },
        "dec5b2f3f74b42e087e25e1f8f001e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_142692b04d98422fa243943bcaa88165",
            "placeholder": "​",
            "style": "IPY_MODEL_f273f296b39a4b6a9b5502032299079d",
            "value": " 482/482 [00:00&lt;00:00, 42.3kB/s]"
          }
        },
        "9737dbdd1026491cae936e6e08453062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c7f7eec0c4240c5b3d5d71d8e0666a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6122e5c2e4c47aa97f7dbfeeffc6548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6037da069824295a696721672e29949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94f9be8e2994d949923b0287dccfa6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "142692b04d98422fa243943bcaa88165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f273f296b39a4b6a9b5502032299079d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5d5617bb9d401d91c17828be30cc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db243bd6f9b142a99ab2b87c1fa6138b",
              "IPY_MODEL_a7fd0a25e37142a1be65516dbed93e37",
              "IPY_MODEL_cac975f02207447baae753016388043c"
            ],
            "layout": "IPY_MODEL_e8eff1db869b4c049e8ab283aadb4f07"
          }
        },
        "db243bd6f9b142a99ab2b87c1fa6138b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4639d1488002453a92614e113596f3d2",
            "placeholder": "​",
            "style": "IPY_MODEL_fa3bdb2ff56642fab89250af3a0d51b7",
            "value": "vocab.json: 100%"
          }
        },
        "a7fd0a25e37142a1be65516dbed93e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1a3f5de7c043928ace6f4811f7b07c",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ea54bd7f3984601a2ab0494e82ab7d5",
            "value": 898823
          }
        },
        "cac975f02207447baae753016388043c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7309d622630e4d218c5986c4b78c5354",
            "placeholder": "​",
            "style": "IPY_MODEL_cdaabca792a444efa4d072b00dcb8693",
            "value": " 899k/899k [00:00&lt;00:00, 22.2MB/s]"
          }
        },
        "e8eff1db869b4c049e8ab283aadb4f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4639d1488002453a92614e113596f3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3bdb2ff56642fab89250af3a0d51b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e1a3f5de7c043928ace6f4811f7b07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ea54bd7f3984601a2ab0494e82ab7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7309d622630e4d218c5986c4b78c5354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdaabca792a444efa4d072b00dcb8693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1536d0a7fc21455f91d31b7392025d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_321f6b8266064e938092725dde977bfa",
              "IPY_MODEL_c0c598ac6adf4ff883683d7769e0e1b9",
              "IPY_MODEL_3189a75b786b464d9a68a0dc2be0ac65"
            ],
            "layout": "IPY_MODEL_451b53bd148b42b2a62bbddd7bdb187d"
          }
        },
        "321f6b8266064e938092725dde977bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da3ae1a0c3234a2ca0e574a602e52354",
            "placeholder": "​",
            "style": "IPY_MODEL_0498fbb51b0c41c38d99be09cb6884f0",
            "value": "merges.txt: 100%"
          }
        },
        "c0c598ac6adf4ff883683d7769e0e1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80d359a6b3d04366ba5202e0d4bc672a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10a27d7dff9445f48eeb98b9a993bfeb",
            "value": 456318
          }
        },
        "3189a75b786b464d9a68a0dc2be0ac65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_967318d0d4c14317a331368500681e3b",
            "placeholder": "​",
            "style": "IPY_MODEL_5f5bee841c8942fd8444a2493bd98f06",
            "value": " 456k/456k [00:00&lt;00:00, 1.09MB/s]"
          }
        },
        "451b53bd148b42b2a62bbddd7bdb187d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3ae1a0c3234a2ca0e574a602e52354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0498fbb51b0c41c38d99be09cb6884f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80d359a6b3d04366ba5202e0d4bc672a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a27d7dff9445f48eeb98b9a993bfeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "967318d0d4c14317a331368500681e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5bee841c8942fd8444a2493bd98f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4694d0c755764a6fbc3fc7c2344c93f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_405ea57640d44dde8543209d34c2e488",
              "IPY_MODEL_5707be7179d9423096254aa09884257f",
              "IPY_MODEL_fa17d3f66bac40b684c75d843af6e12d"
            ],
            "layout": "IPY_MODEL_69c8fdc71e1846e293c06f327f51e723"
          }
        },
        "405ea57640d44dde8543209d34c2e488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb2ebdb6c9344117b0900146db4c9882",
            "placeholder": "​",
            "style": "IPY_MODEL_547a07e2c4494db68898b46aa4b0c994",
            "value": "tokenizer.json: 100%"
          }
        },
        "5707be7179d9423096254aa09884257f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b070b7de8104fbc95f24cbfab3f537b",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de84ee7e1903448992d0fe427b8d2718",
            "value": 1355863
          }
        },
        "fa17d3f66bac40b684c75d843af6e12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf5ee879d00d4f87b4799eae8b68165a",
            "placeholder": "​",
            "style": "IPY_MODEL_7c1effd8758b425ba72c97acfc60271f",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.52MB/s]"
          }
        },
        "69c8fdc71e1846e293c06f327f51e723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb2ebdb6c9344117b0900146db4c9882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547a07e2c4494db68898b46aa4b0c994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b070b7de8104fbc95f24cbfab3f537b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de84ee7e1903448992d0fe427b8d2718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf5ee879d00d4f87b4799eae8b68165a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c1effd8758b425ba72c97acfc60271f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0062b1e98ff843028de8642dd04111c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e3efb5886924672bfd2274222d6876e",
              "IPY_MODEL_f18c65d9c9df4e10aaf5f090d4eb8724",
              "IPY_MODEL_9bde4a8139a7464db1703ec9c5b89cf6"
            ],
            "layout": "IPY_MODEL_25eb79baf8ca4fd7b7d89a6db19b79b9"
          }
        },
        "7e3efb5886924672bfd2274222d6876e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb948c4ecf274400ace864221bf27934",
            "placeholder": "​",
            "style": "IPY_MODEL_33af5f2d1da64ae6a360ad2cf4d91f22",
            "value": "model.safetensors: 100%"
          }
        },
        "f18c65d9c9df4e10aaf5f090d4eb8724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72c775a95fbb4da19816f4c783d74a10",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddb72afeadb2491da0d359fb74dd4409",
            "value": 1421700479
          }
        },
        "9bde4a8139a7464db1703ec9c5b89cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4969959c897e41fa90d2471766e7a204",
            "placeholder": "​",
            "style": "IPY_MODEL_e9e288587594499e80816d117afb86ac",
            "value": " 1.42G/1.42G [00:06&lt;00:00, 217MB/s]"
          }
        },
        "25eb79baf8ca4fd7b7d89a6db19b79b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb948c4ecf274400ace864221bf27934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33af5f2d1da64ae6a360ad2cf4d91f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72c775a95fbb4da19816f4c783d74a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb72afeadb2491da0d359fb74dd4409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4969959c897e41fa90d2471766e7a204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e288587594499e80816d117afb86ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Clone the BARTScore repository\n",
        "!git clone https://github.com/neulab/BARTScore.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK73Z5_hOv0y",
        "outputId": "b4805ad9-6c65-41cc-9b69-b21e3ea6b5ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'BARTScore' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/BARTScore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUaIefowO0pv",
        "outputId": "ad5ffdef-4f82-42cc-dbd4-91daf18827e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BARTScore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from bart_score import BARTScorer\n",
        "import torch"
      ],
      "metadata": {
        "id": "cs8YNL48QHhC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install --upgrade pip  # ensures that pip is current\n",
        "!pip install tensorflow tensorflow_hub transformers\n",
        "!pip install git+https://github.com/google-research/bleurt.git\n",
        "!pip install pandas\n",
        "!pip install groq\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install nltk\n",
        "!pip install rouge\n",
        "!pip install sacrebleu\n",
        "!pip install bert-score\n",
        "!pip install rouge\n",
        "# Navigate to the repository directory\n",
        "%cd /content/BARTScore\n",
        "\n",
        "# Download and unzip BLEURT checkpoint\n",
        "!wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip\n",
        "!unzip BLEURT-20.zip\n",
        "\n",
        "# Initialize BART-Scorer\n",
        "bart_scorer = BARTScorer(device='cuda:0' if torch.cuda.is_available() else 'cpu',\n",
        "                         checkpoint='facebook/bart-large-cnn')\n",
        "\n",
        "!pip install groq\n",
        "!pip install sentence-transformers\n",
        "!pip install chromadb\n",
        "!pip install pymongo pandas\n",
        "!pip install transformers torch accelerate bitsandbytes\n",
        "!pip install --upgrade transformers\n",
        "!pip install rouge\n",
        "!pip install google-search-results\n",
        "!pip install requests beautifulsoup4 lxml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyVfTHT8QKl5",
        "outputId": "379c1002-dcbe-4bc0-9d9d-4ab1426980ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.3.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
            "  Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (2.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.3\n",
            "    Uninstalling protobuf-5.29.3:\n",
            "      Successfully uninstalled protobuf-5.29.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-proto 1.29.0 requires protobuf<6.0,>=5.0, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-4.25.5\n",
            "Collecting git+https://github.com/google-research/bleurt.git\n",
            "  Cloning https://github.com/google-research/bleurt.git to /tmp/pip-req-build-dqa_6d0w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-research/bleurt.git /tmp/pip-req-build-dqa_6d0w\n",
            "  Resolved https://github.com/google-research/bleurt.git to commit cebe7e6f996b40910cfaa520a63db47807e3bf5c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (1.13.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (2.17.1)\n",
            "Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (1.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from BLEURT==0.0.2) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->BLEURT==0.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->BLEURT==0.0.2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->BLEURT==0.0.2) (2024.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->BLEURT==0.0.2) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow->BLEURT==0.0.2) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow->BLEURT==0.0.2) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow->BLEURT==0.0.2) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->BLEURT==0.0.2) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->BLEURT==0.0.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->BLEURT==0.0.2) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow->BLEURT==0.0.2) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow->BLEURT==0.0.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow->BLEURT==0.0.2) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow->BLEURT==0.0.2) (0.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n",
            "/content/BARTScore\n",
            "--2025-01-19 04:36:06--  https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.207, 64.233.170.207, 142.251.175.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2140294207 (2.0G) [application/octet-stream]\n",
            "Saving to: ‘BLEURT-20.zip.1’\n",
            "\n",
            "BLEURT-20.zip.1     100%[===================>]   1.99G  21.7MB/s    in 92s     \n",
            "\n",
            "2025-01-19 04:37:38 (22.2 MB/s) - ‘BLEURT-20.zip.1’ saved [2140294207/2140294207]\n",
            "\n",
            "Archive:  BLEURT-20.zip\n",
            "replace BLEURT-20/bert_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: BLEURT-20/bert_config.json  \n",
            "replace BLEURT-20/saved_model.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: BLEURT-20/saved_model.pb  \n",
            "replace BLEURT-20/variables/variables.index? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: BLEURT-20/variables/variables.index  \n",
            "replace BLEURT-20/variables/variables.data-00000-of-00001? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: BLEURT-20/variables/variables.data-00000-of-00001  y\n",
            "\n",
            "replace BLEURT-20/sent_piece.vocab? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: BLEURT-20/sent_piece.vocab  \n",
            "replace BLEURT-20/bleurt_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: BLEURT-20/bleurt_config.json  \n",
            "replace BLEURT-20/sent_piece.model? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: BLEURT-20/sent_piece.model  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.5)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.8.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.69.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.14)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-5.29.3\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2024.12.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ2GRUGMCUQq",
        "outputId": "14740ecf-5694-4073-9e91-94cb6687ea1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cohere in /usr/local/lib/python3.11/dist-packages (5.13.8)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.10.5)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.0.20241016)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: llama2 in /usr/local/lib/python3.11/dist-packages (0.0.1.dev0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from llama2) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->llama2) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->llama2) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->llama2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->llama2) (3.0.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.5)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.8.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.69.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.14)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "# Install the required libraries\n",
        "!pip install -q cohere groq\n",
        "!pip install cohere\n",
        "!pip install llama2\n",
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install sentence-transformers\n",
        "!pip install chromadb\n",
        "!pip install pymongo pandas\n",
        "!pip install transformers torch accelerate bitsandbytes\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import cohere\n",
        "from pymongo import MongoClient\n",
        "from urllib.parse import quote_plus\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from groq import Groq\n",
        "import pandas as pd\n",
        "import random"
      ],
      "metadata": {
        "id": "kMhfozoHDVk5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate Groq API client\n",
        "api_key = \"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\" # Retrieve the API key securely\n",
        "client = Groq(api_key=api_key)"
      ],
      "metadata": {
        "id": "_f63iCEtDy7f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MongoDB credentials\n",
        "username = quote_plus('ravikiran66999')\n",
        "password = quote_plus('Chikk@l@123')\n",
        "\n",
        "# Initialize the MongoDB client\n",
        "mongo_client = MongoClient(f'mongodb+srv://{username}:{password}@cluster0.jexk5.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0')\n",
        "\n",
        "# Access the database and collection\n",
        "db = mongo_client['db1']\n",
        "collection = db['English']\n",
        "\n",
        "# Initialize the Cohere client with your API key\n",
        "co = cohere.ClientV2('0NMGq0hZ5bzIH5lR2p4FMpfBgVK1P5sz8wm6ofLe')"
      ],
      "metadata": {
        "id": "I9tlWym-D9r2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Specify the Hugging Face model explicitly (ensure this matches your expected dimension)\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": 0})  # Example for 384 dimensions\n",
        "\n",
        "# Function to insert claim and supporting evidence into MongoDB\n",
        "def insert_claim_to_mongo(claim, supporting_evidence):\n",
        "    claim = re.sub(r'[^a-zA-Z\\s\\.]+', '', claim)\n",
        "    supporting_evidence = re.sub(r'[^a-zA-Z\\s\\.]+', '', supporting_evidence)\n",
        "    document = {\n",
        "        \"claim\": claim,\n",
        "        \"supporting_evidence\": supporting_evidence\n",
        "    }\n",
        "    insert_doc = collection.insert_one(document)\n",
        "    print(f\"Inserted Document ID: {insert_doc.inserted_id}\")\n",
        "\n",
        "# Function to retrieve documents from MongoDB or insert supporting evidence if no documents are found\n",
        "def retrieve_or_insert_documents(claim, supporting_evidence):\n",
        "    # Escape special characters in the claim\n",
        "    escaped_claim = re.escape(claim)\n",
        "    query = {\"claim\": {\"$regex\": escaped_claim, \"$options\": \"i\"}}  # Case-insensitive match\n",
        "    docs_from_mongo = collection.find(query)\n",
        "    documents = []\n",
        "\n",
        "    # Initialize the text splitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
        "\n",
        "    # Retrieve documents from MongoDB\n",
        "    for doc in docs_from_mongo:\n",
        "        text = \"\"\n",
        "        if 'supporting_evidence' in doc:\n",
        "            text += doc['supporting_evidence'] + \"\\n\"\n",
        "        if text:\n",
        "            # Split the text into chunks without removing anything\n",
        "            chunks = text_splitter.split_text(text)\n",
        "            for chunk in chunks:\n",
        "                documents.append(Document(page_content=chunk))\n",
        "\n",
        "    # If no documents are found, insert the provided supporting evidence\n",
        "    if len(documents) == 0:\n",
        "        new_document = {\n",
        "            \"claim\": claim,\n",
        "            \"supporting_evidence\": supporting_evidence\n",
        "        }\n",
        "        inserted_id = collection.insert_one(new_document).inserted_id\n",
        "\n",
        "        # Split the supporting evidence into chunks and add to the documents list\n",
        "        chunks = text_splitter.split_text(supporting_evidence)\n",
        "        for chunk in chunks:\n",
        "            documents.append(Document(page_content=chunk))\n",
        "\n",
        "        print(f\"New document inserted with ID: {inserted_id}\")\n",
        "    else:\n",
        "        print(f\"Found {len(documents)} documents.\")\n",
        "\n",
        "    return documents\n",
        "\n",
        "# Function to generate a True/False answer using Groq's LLM based on all relevant documents\n",
        "def generate_yes_no_answer_groq(claim, relevant_documents):\n",
        "    all_docs_content = \"\\n\\n\".join([doc.page_content for doc in relevant_documents])\n",
        "    prompt = f\"Here are the relevant documents:\\n\\n{all_docs_content}\\n\\nBased on the above information, \\\n",
        "    provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context \\\n",
        "    in the second line.'{claim}'.\"\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a fact checker tasked with verifying the following claim.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama3-8b-8192\",\n",
        "        temperature=0.5,\n",
        "        max_tokens=4000,\n",
        "        top_p=1,\n",
        "        stop=None,\n",
        "        stream=False,\n",
        "    )\n",
        "\n",
        "    # Get the classification result from the model\n",
        "    predicted_result = chat_completion.choices[0].message.content.splitlines()\n",
        "    print(predicted_result)\n",
        "    predicted_label = re.sub(r'[^a-zA-Z]+', '', predicted_result[0]).lower()\n",
        "    predicted_label = label_map.get(predicted_label, \"unknown\")\n",
        "    predicted_justification = \" \".join(predicted_result[1:]).strip().lower()\n",
        "    return prompt, predicted_label, predicted_justification\n",
        "\n",
        "# Function to classify the answer based on the response content\n",
        "\n",
        "# Initialize label map\n",
        "label_map = {'true': 'true', 'fake': 'fake', \"correct\": \"true\", \"false\": \"fake\", \"incorrect\": \"fake\", \"not true\": \"fake\"}\n",
        "\n",
        "# Function to read and combine datasets\n",
        "def load_and_combine_datasets(file_paths):\n",
        "    combined_claims = []\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            data = pd.read_json(file_path)\n",
        "            combined_claims.extend(data.to_dict(orient='records'))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_path}: {e}\")\n",
        "    random.shuffle(combined_claims)  # Shuffle claims for randomness\n",
        "    return pd.DataFrame(combined_claims)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soN8yvR5HKTw",
        "outputId": "ae43eb08-b8ce-4fef-9526-2386602bf6b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-5e3f2c2e71cd>:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": 0})  # Example for 384 dimensions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset from Excel\n",
        "file_paths = [\"/content/last_fake_claims.json\", \"/content/Modified_true_claims.json\"]\n",
        "df = load_and_combine_datasets(file_paths)  # Update this path\n",
        "\n",
        "# Store results for accuracy calculation\n",
        "predicted_veracity_labels = []\n",
        "\n",
        "# Initialize lists for results\n",
        "results = []\n",
        "actual_labels = []\n",
        "predicted_labels = []\n",
        "predicted_justifications = []\n",
        "actual_justifications = []\n",
        "\n",
        "# Initialize counters for tracking model performance\n",
        "correct_predictions = 0\n",
        "n_claims = 5006  # Adjust this to the desired number of claims to process\n",
        "total_processed_claims = 0\n",
        "\n",
        "# Process each claim\n",
        "for index, row in df.head(n_claims).iterrows():\n",
        "    claim = row['claim']\n",
        "    actual_label = str(row['label'].strip().lower())\n",
        "    actual_justification = str(row['justification'].strip().lower())\n",
        "    # Generate the response\n",
        "    cohere_prompt = f\"Provide supporting documents for the claim: {claim}\"\n",
        "    response = co.chat(model=\"command-r7b-12-2024\",\n",
        "                       messages=[{\"role\": \"user\", \"content\": cohere_prompt}])\n",
        "\n",
        "    # Print the content of the response\n",
        "    supporting_evidence = response.message.content[0].text\n",
        "    insert_claim_to_mongo(claim, supporting_evidence)\n",
        "\n",
        "    # Retrieve or insert documents\n",
        "    documents = retrieve_or_insert_documents(claim, supporting_evidence)\n",
        "\n",
        "    # Build the Chroma vector database from document embeddings\n",
        "    chroma_vector_database = Chroma.from_documents(documents, embedding=embedding_model)\n",
        "    retriever = chroma_vector_database.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "    # Retrieve relevant documents\n",
        "    relevant_documents = retriever.get_relevant_documents(claim)\n",
        "\n",
        "    # Generate the answer using Groq\n",
        "    if relevant_documents:\n",
        "\n",
        "        prompt, predicted_label, predicted_justification = generate_yes_no_answer_groq(claim, relevant_documents)\n",
        "\n",
        "        total_processed_claims += 1\n",
        "\n",
        "        if (predicted_label, predicted_justification) == (\"\", \"\"):\n",
        "            continue\n",
        "\n",
        "        actual_labels.append(actual_label)\n",
        "        actual_justifications.append(actual_justification)\n",
        "        predicted_labels.append(predicted_label)\n",
        "        predicted_justifications.append(predicted_justification)\n",
        "\n",
        "        if predicted_label == actual_label:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        print(f\"Claim #{total_processed_claims}\")\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "        print(f\"Claim: {claim}\")\n",
        "        print(f\"Predicted Label: {predicted_label}\")\n",
        "        print(f\"Actual Label: {actual_label}\")\n",
        "        print(f\"Predicted Justification: {predicted_justification}\")\n",
        "        print(f\"Actual Justification: {actual_justification}\")\n",
        "        print('-' * 100)\n",
        "    else:\n",
        "        predicted_veracity_labels.append(\"Unknown\")  # Handle case with no documents found\n",
        "        print(f\"No relevant documents found for claim '{claim}'.\\n\")\n",
        "        print('-' * 100)\n",
        "\n",
        "accuracy = correct_predictions / total_processed_claims * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaQ8WDcSIsi0",
        "outputId": "6d493432-107e-46fe-f834-2e1a0a89a5d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted Document ID: 678c8206e6a9edc16c6752d2\n",
            "Found 10 documents.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-e1d12dd8c22b>:42: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  relevant_documents = retriever.get_relevant_documents(claim)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "* **Location and Timeframe:** Specify the area where the snow leopard killed over 40 sheep and the approximate timeframe of these incidents.\n",
            "\n",
            "* **Conservation Efforts:** Briefly mention any ongoing conservation efforts in the region related to snow leopards. This can provide context for the capture and transfer.\n",
            "\n",
            "Press Releases Official press releases issued by the Gujarat Forest Department announcing the leopard sighting the trapping efforts and any updates on the situation. These releases would likely\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Snow leopard which killed over 40 sheep in hp's spiti captured, sent to himalayan nature park in kufri.'.\n",
            "Claim: Snow leopard which killed over 40 sheep in hp's spiti captured, sent to himalayan nature park in kufri.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is based on the fact that the claim mentions specific details such as the location (spiti, hp), the timeframe (not specified), and the conservation efforts (transfer to himalayan nature park in kufri). the press releases issued by the gujarat forest department are also mentioned, which adds credibility to the claim. however, it's worth noting that the gujarat forest department is not mentioned in the context, which seems to be a discrepancy. nevertheless, the rest of the details provided seem to be accurate, making the claim true.\n",
            "Actual Justification: the article reports that a snow leopard which had killed over 40 sheep in spiti was captured and sent to the himalayan nature park in kufri.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb6e6e6a9edc16c676563\n",
            "Found 11 documents.\n",
            "['FAKE', '', 'The claim is considered fake because the author of the text states that it is \"highly unlikely\" that such a large force would mobilize for a protest, and instead offers to provide more accurate and reliable information on the topic.']\n",
            "Claim #4754\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that 20,000 Nihang Sikh warriors on 2,000 horses are on their way to join protesting farmers near Delhi. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "If you have specific questions about the Nihang Sikh warriors or the farmer protests, I'd be happy to provide more accurate and reliable information.\n",
            "\n",
            "highly unlikely that they would mobilize such a large force of 20,000 warriors and 2,000 horses for a protest near Delhi.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'20,000 Nihang Sikh warriors on 2,000 horses on their way to join protesting farmers near Delhi.'.\n",
            "Claim: 20,000 Nihang Sikh warriors on 2,000 horses on their way to join protesting farmers near Delhi.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is considered fake because the author of the text states that it is \"highly unlikely\" that such a large force would mobilize for a protest, and instead offers to provide more accurate and reliable information on the topic.\n",
            "Actual Justification: the video being shared is not related to the ongoing farmers' protest in delhi. it is an old video, and the claim about 20,000 nihang sikh warriors on their way to join the protest is misleading.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb6e9e6a9edc16c676564\n",
            "Found 22 documents.\n",
            "['**FAKE**', '', 'The given context does not support the claim that COVID is caused by bacteria instead of a virus. The claim is explicitly stated as \"not supported by the vast majority of scientific research and is not accepted by the global medical community\".']\n",
            "Claim #4755\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "COVID is caused by bacteria instead of a virus is not supported by the vast majority of scientific research and is not accepted by the global medical community.\n",
            "\n",
            "**Claim:** Five COVID-19 patients were killed in a fire at a hospital in Rajkot, Gujarat, and the Chief Minister, Mr. Vijay Rupani, has ordered an investigation.\n",
            "\n",
            "**Supporting Documents:**\n",
            "\n",
            "In fact Dr. Honjo a Japanese immunologist who won the Nobel Prize in Physiology or Medicine in  has not made such a claim. The origins of COVID the disease caused by the coronavirus are still being\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Singapore has become the first country in the world to perform an autopsy on a COVID victim. It found that COVID is not caused by a virus but bacteria and hence changed their treatment protocol.'.\n",
            "Claim: Singapore has become the first country in the world to perform an autopsy on a COVID victim. It found that COVID is not caused by a virus but bacteria and hence changed their treatment protocol.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not support the claim that covid is caused by bacteria instead of a virus. the claim is explicitly stated as \"not supported by the vast majority of scientific research and is not accepted by the global medical community\".\n",
            "Actual Justification: the claim that singapore performed an autopsy on a covid victim and found that covid is caused by bacteria instead of a virus is false. no such autopsy was performed, and singapore has not changed its treatment protocol based on such findings.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb6ece6a9edc16c676565\n",
            "Found 13 documents.\n",
            "['TRUE', '', 'The claim is considered true because it is mentioned in the provided documents, specifically in the \"Incident Overview\" section, that Subham Gupta was allegedly beaten to death by a group of people, including Raja Dwivedi, in the village of Bangarmau, Banda.']\n",
            "Claim #4756\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "1. **Incident Overview**: On November 12, 2016, Subham Gupta, a 23-year-old youth, was allegedly beaten to death by a group of people, including Raja Dwivedi, in the village of Bangarmau, Banda\n",
            "\n",
            "I cannot provide supporting documents for the claim that Subham Gupta was beaten to death by Raja Dwivedi, as I do not have access to real-time information or specific case details. However, I can\n",
            "\n",
            "- **Conviction and Sentence**: Pawan Gupta was one of the six men convicted in the Nirbhaya case. He was sentenced to death for his role in the gang rape and murder.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Subham Gupta being beaten to death in UP's Banda district by Raja Dwivedi, sibling of former UP MLA Purushottam Naresh Trivedi.'.\n",
            "Claim: Subham Gupta being beaten to death in UP's Banda district by Raja Dwivedi, sibling of former UP MLA Purushottam Naresh Trivedi.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is considered true because it is mentioned in the provided documents, specifically in the \"incident overview\" section, that subham gupta was allegedly beaten to death by a group of people, including raja dwivedi, in the village of bangarmau, banda.\n",
            "Actual Justification: the video is from shahjahanpur and not banda district. it shows a fight, not a murder. the person identified as raja dwivedi is not involved in the incident.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb6eee6a9edc16c676566\n",
            "Found 3 documents.\n",
            "['TRUE', 'The claim is supported by the text, which states that the Supreme Court has directed the Jammu and Kashmir administration and the Centre to respond to a plea seeking the restoration of 4G internet services in the region, implying that there is no 4G network coverage in the region at the moment, and a panel is being convened to make a decision on this.']\n",
            "Claim #4757\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you're referring to a situation where there is no 4G network coverage in the regions of Jammu and Kashmir (J&K) at the moment, and a panel is being convened to make a decision on this\n",
            "\n",
            "The Supreme Court has directed the Jammu and Kashmir administration, along with the Centre, to respond to a plea seeking the restoration of 4G internet services in the region. This decision comes as a\n",
            "\n",
            "Remember to stay updated with the JSSC's official communication and follow their instructions carefully. If you have any doubts or require further assistance, you can also contact the JSSC's support\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'no 4g in j&k for now, panel to take call: sc.'.\n",
            "Claim: no 4g in j&k for now, panel to take call: sc.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the text, which states that the supreme court has directed the jammu and kashmir administration and the centre to respond to a plea seeking the restoration of 4g internet services in the region, implying that there is no 4g network coverage in the region at the moment, and a panel is being convened to make a decision on this.\n",
            "Actual Justification: the article confirms that the supreme court stated there will be no 4g services in jammu and kashmir for the time being and that a panel will decide on the matter.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb6f1e6a9edc16c676567\n",
            "Found 31 documents.\n",
            "['TRUE', '', 'The justification is based on the provided context, which mentions \"Indian Railways BJP government station modernization and cleaning equipment\" and \"upgrades including those related to cleaning equipment during the BJP\\'s tenure\". This suggests that the BJP government did indeed upgrade the cleaning equipment at Indian railway stations during their tenure.']\n",
            "Claim #4758\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "While I cannot provide specific documents the above information can be used to support the claim that cleaning equipment at Indian railway stations was upgraded after the BJP came to power.\n",
            "\n",
            "Indian Railways BJP government station modernization and cleaning equipment to find relevant reports.\n",
            "\n",
            "upgrades including those related to cleaning equipment during the BJPs tenure.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Cleaning equipment at Indian railway stations was upgraded after the BJP came to power.'.\n",
            "Claim: Cleaning equipment at Indian railway stations was upgraded after the BJP came to power.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is based on the provided context, which mentions \"indian railways bjp government station modernization and cleaning equipment\" and \"upgrades including those related to cleaning equipment during the bjp's tenure\". this suggests that the bjp government did indeed upgrade the cleaning equipment at indian railway stations during their tenure.\n",
            "Actual Justification: the images are from 2020, well before the bjp's tenure, and do not reflect any upgrades made after the party came to power.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb6f4e6a9edc16c676568\n",
            "Found 18 documents.\n",
            "['TRUE', '', 'The justification is that the provided context states that the civil code in India leads to unfair advantages for large Muslim families, which suggests that the absence of a uniform civil code could result in certain benefits for large Muslim families, in line with the quoted statement.']\n",
            "Claim #4759\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "civil code in India leads to unfair advantages for large Muslim families, which is a complex and sensitive issue.\n",
            "\n",
            "reaction to the BJPs stance on the Ram Mandir and Uniform Civil Code.\n",
            "\n",
            "marriage, divorce, and inheritance. However, this does not mean that Muslim families automatically receive more benefits. The application of personal laws can vary, and it is not a uniform process\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Without uniform civil code in India, large Muslim families like this one will reap all the benefits of taxpayers' money.'.\n",
            "Claim: Without uniform civil code in India, large Muslim families like this one will reap all the benefits of taxpayers' money.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided context states that the civil code in india leads to unfair advantages for large muslim families, which suggests that the absence of a uniform civil code could result in certain benefits for large muslim families, in line with the quoted statement.\n",
            "Actual Justification: the image being circulated to push for a uniform civil code is not of a muslim family in india but an old photo of a large family from bangladesh. the claim about large muslim families benefiting from taxpayers' money is misleading and unverified.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb6f9e6a9edc16c676569\n",
            "Found 50 documents.\n",
            "['TRUE', '', 'The claim is supported by the fact that the provided documents include an \"Official Press Release\" which is a credible source, indicating that the Army has indeed started a permanent commission for women officers.']\n",
            "Claim #4760\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The introduction of a permanent commission for women officers in the army is a significant development in military history. This move not only recognizes the capabilities and contributions of women in\n",
            "\n",
            "I can help you with that Here are some supporting documents for the claim that the Army has started a permanent commission for women officers\n",
            "\n",
            ". Official Press Release\n",
            "\n",
            "To support the claim that The Army has started a permanent commission for women officers you would need to provide official documents or reputable sources that confirm this policy change. Here are\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Army starts permanent commission for women officers.'.\n",
            "Claim: Army starts permanent commission for women officers.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the fact that the provided documents include an \"official press release\" which is a credible source, indicating that the army has indeed started a permanent commission for women officers.\n",
            "Actual Justification: the article from *pib* confirms that the indian army has initiated the process for granting permanent commissions to women officers, marking a significant step in gender equality within the indian army.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb6fbe6a9edc16c67656a\n",
            "Found 3 documents.\n",
            "['FAKE', 'The claim is labeled as \"I cannot provide supporting documents\" which implies that the claim is false and there is no evidence to support it.']\n",
            "Claim #4761\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that BJP MLA Rajesh Mishra's son kissed a girl and allowed his friend to kiss her.\n",
            "\n",
            "I cannot provide supporting documents for the claim that actresses Kiara Advani and Kareena Kapoor Khan kissed each other.\n",
            "\n",
            "I cannot provide supporting documents for the claim that actresses Kiara Advani and Kareena Kapoor Khan kissed each other.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'BJP MLA Rajesh Mishra's son kissing a girl and also allowing his friend to kiss her.'.\n",
            "Claim: BJP MLA Rajesh Mishra's son kissing a girl and also allowing his friend to kiss her.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is labeled as \"i cannot provide supporting documents\" which implies that the claim is false and there is no evidence to support it.\n",
            "Actual Justification: the claim about bjp mla rajesh mishra's son kissing a girl and allowing his friend to kiss her is false. the boy in the video is not rajesh mishra's son, sakshi mishra's brother, as claimed.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb6fde6a9edc16c67656b\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The claim suggests that Mamata Banerjee is open to receiving political backing for non-political protests, which is supported by the context provided, stating that the protests in West Bengal, including the one led by Chief Minister Mamata Banerjee, are part of a broader movement against the CAA and the NRC update process, which indicates that the protest is driven by a genuine concern for a particular issue rather than political motives.']\n",
            "Claim #4762\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "This statement suggests that Mamata Banerjee, a prominent political figure, is engaging in a protest against the Central Bureau of Investigation (CBI) but is open to receiving political backing for\n",
            "\n",
            "1. **Non-Political Protests**: Mamata Banerjee might be emphasizing that the protest is not driven by political motives but rather by a genuine concern for a particular issue. This could indicate\n",
            "\n",
            "The protests in West Bengal, including the one led by Chief Minister Mamata Banerjee, are part of a broader movement against the CAA and the National Register of Citizens (NRC) update process, which\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Mamata banerjee says protest against cbi is non-political but welcomes political support.'.\n",
            "Claim: Mamata banerjee says protest against cbi is non-political but welcomes political support.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim suggests that mamata banerjee is open to receiving political backing for non-political protests, which is supported by the context provided, stating that the protests in west bengal, including the one led by chief minister mamata banerjee, are part of a broader movement against the caa and the nrc update process, which indicates that the protest is driven by a genuine concern for a particular issue rather than political motives.\n",
            "Actual Justification: the article from *theprint* confirms that mamata banerjee stated that the protest against the cbi is non-political, but she also welcomed political support from other parties.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb702e6a9edc16c67656c\n",
            "Found 73 documents.\n",
            "['TRUE', '', \"The provided context confirms that India's proposal is to use the Chabahar route for trade with Central Asia, which is supported by official government statements and additional documents/information.\"]\n",
            "Claim #4763\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "India's proposal to use the Chabahar route for trade with Central Asia holds significant promise. By leveraging the port's strategic location and India's investment, the initiative can facilitate\n",
            "\n",
            "These documents and information provide a comprehensive overview of Indias proposal to enhance trade with Central Asia through the Chabahar route highlighting the strategic advantages infrastructure\n",
            "\n",
            "Here are some supporting documents and information regarding Indias proposal to enhance trade with Central Asia through the Chabahar route\n",
            "\n",
            ". Official Government Statements\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'India proposes to enhance trade with central asia through chabahar route.'.\n",
            "Claim: India proposes to enhance trade with central asia through chabahar route.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the provided context confirms that india's proposal is to use the chabahar route for trade with central asia, which is supported by official government statements and additional documents/information.\n",
            "Actual Justification: india has proposed enhancing trade with central asia via the chabahar port route, aiming to improve connectivity and trade with the region.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb705e6a9edc16c67656d\n",
            "Found 17 documents.\n",
            "['FAKE', '', 'The claim is fake because the provided text explicitly states \"I cannot provide supporting documents for the claim that Liam Payne a former member of One Direction fell off a hotel balcony in Argentina.\" This implies that the claim is false and there is no evidence to support it.']\n",
            "Claim #4764\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "former member of the band One Direction, fell off a hotel balcony in Argentina.\n",
            "\n",
            "I cannot provide supporting documents for the claim that Liam Payne a former member of One Direction fell off a hotel balcony in Argentina. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that Liam Payne a former member of One Direction fell off a hotel balcony in Argentina. \n",
            "\n",
            "Heres why\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Former one direction singer liam payne fell off a hotel balcony in argentina.'.\n",
            "Claim: Former one direction singer liam payne fell off a hotel balcony in argentina.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is fake because the provided text explicitly states \"i cannot provide supporting documents for the claim that liam payne a former member of one direction fell off a hotel balcony in argentina.\" this implies that the claim is false and there is no evidence to support it.\n",
            "Actual Justification: the claim that this video shows former one direction singer liam payne falling off a hotel balcony in argentina is false. according to india today, the video is actually from a different incident and has no connection to liam payne's death.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb707e6a9edc16c67656e\n",
            "Found 15 documents.\n",
            "['FAKE', '', 'The justification is that the provided text explicitly states \"I cannot provide supporting documents for the claim that Muslims in France are being dragged off the road for blocking traffic while performing namaz.\" and also mentions that the claimant cannot confirm the specific incident described, implying that the claim is false.']\n",
            "Claim #4765\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Muslims in France are being dragged off the road for blocking traffic while performing namaz. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that Muslims in France are being dragged off the road for blocking traffic while performing namaz.\n",
            "\n",
            "While I cannot confirm the specific incident described it is not uncommon for people to perform namaz in public spaces including roads in Pakistan and other Muslimmajority countries. This is often\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Muslims in France being dragged off the road for blocking traffic while performing namaz.'.\n",
            "Claim: Muslims in France being dragged off the road for blocking traffic while performing namaz.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided text explicitly states \"i cannot provide supporting documents for the claim that muslims in france are being dragged off the road for blocking traffic while performing namaz.\" and also mentions that the claimant cannot confirm the specific incident described, implying that the claim is false.\n",
            "Actual Justification: the video actually shows climate activists protesting and blocking traffic in france, not muslims performing namaz. the claim is a misrepresentation of the event.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb709e6a9edc16c67656f\n",
            "Found 22 documents.\n",
            "['TRUE', '', 'The claim suggests that the BJP is taking a bid to assure the Minimum Support Price (MSP) for six crops and instructing its Members of Parliament (MPs) to spread the word. Although the exact documents or sources are not provided, the context implies that the claim is based on official statements or policy documents released by the BJP or the Indian government.']\n",
            "Claim #4766\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "To support the claim \"Bid to assure MSP for six crops, BJP tells MPs to spread the word,\" you would need to gather and reference various documents and sources that provide context, evidence, and\n",
            "\n",
            "- Search for any policy documents, white papers, or agricultural reform proposals released by the BJP or the government that mention the MSP guarantee for the six crops.\n",
            "\n",
            "- Locate official statements or press releases issued by the Bharatiya Janata Party (BJP) or the Indian government regarding the MSP assurance for the specified crops.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Bid to assure msp up for six crops, bjp tells mps to spread the word'.\n",
            "Claim: Bid to assure msp up for six crops, bjp tells mps to spread the word\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim suggests that the bjp is taking a bid to assure the minimum support price (msp) for six crops and instructing its members of parliament (mps) to spread the word. although the exact documents or sources are not provided, the context implies that the claim is based on official statements or policy documents released by the bjp or the indian government.\n",
            "Actual Justification: the claim is supported by the indian express article, which highlights that agriculture minister narendra singh tomar reassured the government's commitment to minimum support price (msp) for six crops and bjp leaders were asked to communicate this to the public to counter opposition narratives.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb70ae6a9edc16c676570\n",
            "Found 20 documents.\n",
            "['TRUE', 'The claim is supported by the provided context, which states \"there were reports of clashes and violence between police and migrant workers, including those from the state of Bihar, during the lockdown period.\"']\n",
            "Claim #4767\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that labourers from Bihar were thrashed by policemen during the lockdown.\n",
            "\n",
            "I cannot provide supporting documents for the claim that labourers from Bihar were thrashed by policemen during the lockdown.\n",
            "\n",
            "migrant populations. In India, there were reports of clashes and violence between police and migrant workers, including those from the state of Bihar, during the lockdown period.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Labourers from Bihar being thrashed by policemen during the lockdown.'.\n",
            "Claim: Labourers from Bihar being thrashed by policemen during the lockdown.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the provided context, which states \"there were reports of clashes and violence between police and migrant workers, including those from the state of bihar, during the lockdown period.\"\n",
            "Actual Justification: the claim is false. the video depicts an incident from telangana's khammam district where local residents were punished by police for violating lockdown norms. it does not involve bihar labourers. khammam police confirmed the individuals were locals, and disciplinary action was taken against the officer involved.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb70ce6a9edc16c676571\n",
            "Found 5 documents.\n",
            "['TRUE', 'The claim is supported by the given context, which mentions the slogan \"Jai Shree Ram, Sita Ram\" (which is likely a typo and intended to be \"Jai Shri Ram\") being featured on a poster with Mamata Banerjee and Amit Shah.']\n",
            "Claim #4768\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you're referring to a specific event or context where Mamata Banerjee, a prominent politician, is seen with a poster featuring Amit Shah, another prominent politician, and the slogan\n",
            "\n",
            "\"Ishwar Allah Tero Naam\" or \"Jai Shree Ram, Sita Ram.\"\n",
            "\n",
            "\"Jai Shri Ram.\"\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Mamata Banerjee is holding a poster with Amit Shah on which 'Jai Shri Ram' is written.'.\n",
            "Claim: Mamata Banerjee is holding a poster with Amit Shah on which 'Jai Shri Ram' is written.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the given context, which mentions the slogan \"jai shree ram, sita ram\" (which is likely a typo and intended to be \"jai shri ram\") being featured on a poster with mamata banerjee and amit shah.\n",
            "Actual Justification: the claim is false. the viral image of mamata banerjee holding a poster with amit shah's image and 'jai shri ram' written on it has been digitally altered. the original image shows her holding a different poster during a protest against the nrc in assam.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb70ee6a9edc16c676572\n",
            "Found 15 documents.\n",
            "['TRUE', '', 'According to the provided information, Feroze Khan is the husband of Indira Gandhi, and Yunus Khan is the father of Feroze Khan. Since Jawaharlal Nehru is the father of Indira Gandhi, this means that Feroze Khan, Yunus Khan, and Jawaharlal Nehru are all related to Indira Gandhi, making it possible for them to be together in family and political events.']\n",
            "Claim #4769\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "- **Feroze Khan:** The husband of Indira Gandhi and a close associate of Jawaharlal Nehru.\n",
            "\n",
            "- **Indira Gandhi:** The daughter of Jawaharlal Nehru, who became the third Prime Minister of India.\n",
            "   - **Yunus Khan:** The father of Feroze Khan, a close associate of Jawaharlal Nehru.\n",
            "\n",
            "- Indira Gandhi, being the daughter of Jawaharlal Nehru, would naturally be involved in family and political events with her father and her husband.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Jawaharlal Nehru, Indira Gandhi, her father-in-law Yunus Khan, and her husband Feroze Khan are together'.\n",
            "Claim: Jawaharlal Nehru, Indira Gandhi, her father-in-law Yunus Khan, and her husband Feroze Khan are together\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: according to the provided information, feroze khan is the husband of indira gandhi, and yunus khan is the father of feroze khan. since jawaharlal nehru is the father of indira gandhi, this means that feroze khan, yunus khan, and jawaharlal nehru are all related to indira gandhi, making it possible for them to be together in family and political events.\n",
            "Actual Justification: the photo in question is not of indira gandhi with her family members. it shows her with her husband, feroze gandhi, but the man mistaken for her father-in-law is actually her uncle, and the photo was clicked during a different period than claimed.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb711e6a9edc16c676573\n",
            "Found 3 documents.\n",
            "['FAKE', '', 'The justification is that there is no publicly available information suggesting a post made by Akshay Kumar, and the claim is referring to a specific news story or incident involving Akshay Kumar and a YouTuber, which cannot be verified without real-time access to the internet.']\n",
            "Claim #4770\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you're referring to a specific news story or incident involving Akshay Kumar, a well-known Indian actor, and a YouTuber. However, I don't have real-time access to the internet, and the\n",
            "\n",
            "Akshay Kumar He is a renowned Indian actor and producer known for his work in Bollywood. While he is primarily known for his acting career there is no publicly available information suggesting a\n",
            "\n",
            "posts made by Akshay Kumar.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Akshay Kumar serves Rs 500 crore defamation notice on YouTuber.'.\n",
            "Claim: Akshay Kumar serves Rs 500 crore defamation notice on YouTuber.\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that there is no publicly available information suggesting a post made by akshay kumar, and the claim is referring to a specific news story or incident involving akshay kumar and a youtuber, which cannot be verified without real-time access to the internet.\n",
            "Actual Justification: the article reports that actor akshay kumar has served a defamation notice worth rs 500 crore on a youtuber over defamatory content.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb715e6a9edc16c676574\n",
            "Found 15 documents.\n",
            "['TRUE', '', 'The provided context explicitly mentions \"Educational Programs\" and \"Memorials and Monuments\" to celebrate Narasimha Rao\\'s life and impact, which suggests that the centenary celebration is planned for a year, as stated in the claim.']\n",
            "Claim #4771\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Educational Programs:** Organize lectures, seminars, and workshops that delve into Narasimha Rao's life, his political career, and his impact on Telangana and Indian politics. Invite historians,\n",
            "\n",
            "Remember, the key is to engage people from all walks of life and showcase how Narasimha Rao's contributions continue to shape Telangana and India.\n",
            "\n",
            "* **Memorials and Monuments:** Consider erecting monuments or plaques in Narasimha Rao's honor in public spaces across Telangana.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Telangana to celebrate narasimha rao's centenary for a year.'.\n",
            "Claim: Telangana to celebrate narasimha rao's centenary for a year.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the provided context explicitly mentions \"educational programs\" and \"memorials and monuments\" to celebrate narasimha rao's life and impact, which suggests that the centenary celebration is planned for a year, as stated in the claim.\n",
            "Actual Justification: the claim is accurate as per the article, which reports that the state of telangana will celebrate the centenary of former prime minister narasimha rao for a year, starting from his birth centenary.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb718e6a9edc16c676575\n",
            "Found 26 documents.\n",
            "['TRUE', '', 'The claim is supported by the description, which mentions \"posts and videos\" that might include information about injured soldiers and tank collisions, indicating that the incident actually occurred during the Russian invasion of Ukraine.']\n",
            "Claim #4772\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Claim Injured soldiers being helped after Russian tanks collide during the invasion of Ukraine.\n",
            "\n",
            "Supporting Description\n",
            "\n",
            "invasion such as UkraineInvasion or RussianInvasion to find posts and videos that might include information about injured soldiers and tank collisions.\n",
            "\n",
            "This incident highlights the dangers faced by Ukrainian soldiers during the war and the resilience of the emergency response teams who quickly acted to help those in need. The collision of Russian\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Injured soldiers being helped after Russian tanks collide during the invasion of Ukraine.'.\n",
            "Claim: Injured soldiers being helped after Russian tanks collide during the invasion of Ukraine.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the description, which mentions \"posts and videos\" that might include information about injured soldiers and tank collisions, indicating that the incident actually occurred during the russian invasion of ukraine.\n",
            "Actual Justification: the video being circulated is not from the ukrainian battlefront. it is an old video from a russian military drill mishap, not related to the ongoing conflict in ukraine. the video has been misattributed and is being shared out of context.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb71ae6a9edc16c676576\n",
            "Found 4 documents.\n",
            "['FAKE', '', \"The justification is that the claim states that Africans are performing puja on the first Monday of the 'Sawan' month, which is a Hindu month observed by Hindus in India and other parts of South Asia, and not by Africans. Additionally, the claim is not verifiable as it is not a factual statement.\"]\n",
            "Claim #4773\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Africans are performing puja on the first Monday of the 'Sawan' month, as this is not a factual or verifiable statement. The 'Sawan' month is a\n",
            "\n",
            "Hindu month that is observed by Hindus in India and other parts of South Asia, and it is not a month that is celebrated or observed by Africans. Additionally, the claim that Africans are performing\n",
            "\n",
            "accompanied by traditional Gujarati music.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Africans performing puja on the first Monday of 'Sawan' month. Some Africans are seen singing bhajans and performing Hindu rituals in the video.'.\n",
            "Claim: Africans performing puja on the first Monday of 'Sawan' month. Some Africans are seen singing bhajans and performing Hindu rituals in the video.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claim states that africans are performing puja on the first monday of the 'sawan' month, which is a hindu month observed by hindus in india and other parts of south asia, and not by africans. additionally, the claim is not verifiable as it is not a factual statement.\n",
            "Actual Justification: the claim is false. the video does not show africans performing hindu rituals on the first monday of 'sawan' month. it was a misrepresentation of the original video, which shows people from another country performing religious rituals, but not specifically hindu 'sawan' puja.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb71ce6a9edc16c676577\n",
            "Found 9 documents.\n",
            "['**FAKE**', '', 'The justification is that there is no mention of a person named Noa Argamani or a music festival in the provided documents, and the description of the event is not supported by any evidence in the given articles.']\n",
            "Claim #4774\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "2. **Emotional Impact**: The description of the event as \"Noa Argamani, the woman kidnapped by Hamas militants from a music festival, being burned alive\" is highly graphic and emotionally charged.\n",
            "\n",
            "Iranian Woman Beaten During Protests Dies of Her Injuries BBC News December  This article reports on the tragic case of Mahsa Amini a yearold woman who was arrested by Irans morality police for\n",
            "\n",
            "The victim, a 24-year-old woman named Soniya, was found dead in her home on February 15, 2013. She had been brutally raped and murdered, and the case quickly became a high-profile issue in the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Noa Argamani, the woman kidnapped by Hamas militants from a music festival, being burned alive.'.\n",
            "Claim: Noa Argamani, the woman kidnapped by Hamas militants from a music festival, being burned alive.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that there is no mention of a person named noa argamani or a music festival in the provided documents, and the description of the event is not supported by any evidence in the given articles.\n",
            "Actual Justification: the claim is false. the video is from a 2015 incident in guatemala and shows a 16-year-old girl being beaten and burned to death by a mob. it has nothing to do with noa argamani or the israel-hamas conflict.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb71fe6a9edc16c676578\n",
            "Found 23 documents.\n",
            "['TRUE', '', \"The statement is verified to be true as it is directly quoted from the given text, which suggests a concern about China's actions and their potential impact on regional stability.\"]\n",
            "Claim #4775\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement \"China's attempt to alter status quo can have repercussions, says Indian envoy\" suggests a concern about China's actions and their potential impact on regional stability, particularly in\n",
            "\n",
            "The Indian envoy's comment highlights the potential consequences of China's actions, suggesting that such attempts to change the status quo can lead to increased instability, heightened military\n",
            "\n",
            "Given these points, the statement highlights the potential for a range of negative outcomes if China's actions to alter the status quo are not managed carefully. It underscores the importance of\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'China's attempt to alter status quo can have repercussions, says indian envoy.'.\n",
            "Claim: China's attempt to alter status quo can have repercussions, says indian envoy.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the statement is verified to be true as it is directly quoted from the given text, which suggests a concern about china's actions and their potential impact on regional stability.\n",
            "Actual Justification: the article confirms that the indian envoy warned china that attempts to alter the status quo, particularly regarding the border issue, could have serious repercussions.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb721e6a9edc16c676579\n",
            "Found 5 documents.\n",
            "['TRUE', 'The claim is true because the original text mentions visiting the official BPCL website at bharatpetroleum.com for information about the recruitment, which suggests that the recruitment drive is real and not fake.']\n",
            "Claim #4776\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "If you're interested in applying for BPCL's trainee positions, I recommend visiting the official BPCL website at bharatpetroleum.com. There, you can find the latest information about the recruitment\n",
            "\n",
            "It seems like you're referring to a specific recruitment drive by BPCL (Bharat Petroleum Corporation Limited) for trainee positions in 2019. However, I don't have real-time access to the internet or\n",
            "\n",
            "It seems like you've shared a notice about a recruitment drive for various positions at the Post Graduate Institute of Medical Education and Research (PGIMER) in Chandigarh. The application deadline\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'BPCL recruitment 2019 application process for trainee posts to end tomorrow, apply now at bharatpetroleum.com'.\n",
            "Claim: BPCL recruitment 2019 application process for trainee posts to end tomorrow, apply now at bharatpetroleum.com\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is true because the original text mentions visiting the official bpcl website at bharatpetroleum.com for information about the recruitment, which suggests that the recruitment drive is real and not fake.\n",
            "Actual Justification: the bpcl recruitment application process for trainee posts is closing soon, as mentioned in the report. applicants are urged to apply before the deadline.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb723e6a9edc16c67657a\n",
            "Found 9 documents.\n",
            "['TRUE', 'The claim mentions a political crisis in Karnataka in 2019, which is supported by the provided context, specifically point 1, which states that the government led by the Janata Dal (Secular) (JDS) and the Congress faced a crisis in 2019.']\n",
            "Claim #4777\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Karnataka, having served as the Chief Minister of the state from 2013 to 2017. He is a member of the Indian National Congress (INC) and has been a prominent figure in Karnataka's politics.\n",
            "\n",
            "It seems like you might be referring to a specific event or situation in Karnataka, India, involving the state's Chief Minister, H. D. Kumaraswamy, and the state Congress chief. However, the\n",
            "\n",
            "1. **Political Crisis in Karnataka**: Karnataka has experienced political turmoil in the past, particularly in 2019 when the government led by the Janata Dal (Secular) (JDS) and the Congress faced a\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Karnataka govt in crisis, cm kumaraswamy, state congress chief travel abroad.'.\n",
            "Claim: Karnataka govt in crisis, cm kumaraswamy, state congress chief travel abroad.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim mentions a political crisis in karnataka in 2019, which is supported by the provided context, specifically point 1, which states that the government led by the janata dal (secular) (jds) and the congress faced a crisis in 2019.\n",
            "Actual Justification: the karnataka government faced a crisis as both chief minister kumaraswamy and the state congress chief were abroad during a critical period, raising concerns over the state's political situation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb725e6a9edc16c67657b\n",
            "Found 8 documents.\n",
            "['TRUE', '', \"The context does not provide any evidence that Bhupinder Hooda, a member of Congress, made the claim that JJP disrespected Haryana's mandate by shaking hands with BJP. In fact, the context mentions that JJP and BJP have joined forces to form a new coalition government in Haryana, which suggests a partnership rather than disrespect.\"]\n",
            "Claim #4778\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Congress' Bhupinder Hooda says JJP disrespected Haryana mandate by shaking hands with BJP. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "- Haryana's new coalition government: This refers to the government formed in the state of Haryana, where the JJP and the BJP have joined forces, potentially with the support of the Congress.\n",
            "\n",
            "- JJP: This likely refers to the Jarnail Singh JJP, a regional political party in Haryana, India.\n",
            "- BJP: The Bharatiya Janata Party (BJP) is a major national political party in India.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Congress' bhupinder hooda says jjp disrespected haryana mandate by shaking hands with bjp.'.\n",
            "Claim: Congress' bhupinder hooda says jjp disrespected haryana mandate by shaking hands with bjp.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the context does not provide any evidence that bhupinder hooda, a member of congress, made the claim that jjp disrespected haryana's mandate by shaking hands with bjp. in fact, the context mentions that jjp and bjp have joined forces to form a new coalition government in haryana, which suggests a partnership rather than disrespect.\n",
            "Actual Justification: the claim is accurate as the article reports bhupinder hooda's statement accusing the jjp of disrespecting the haryana mandate by aligning with the bjp.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb727e6a9edc16c67657c\n",
            "Found 1 documents.\n",
            "['TRUE', '', 'The claim is supported by the provided documents, specifically the article \"COVID-19: Tragic Loss of Italian Doctors\" published in the International Journal of Infectious Diseases, which mentions the cases of Dr. Donati and Dr. Messina, two experienced healthcare professionals who contracted COVID-19 while providing care to patients.']\n",
            "Claim #4779\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Messina. It mentions that both doctors were experienced healthcare professionals who contracted COVID-19 while providing care to patients. The article highlights the tragic impact of the virus on the\n",
            "\n",
            "- On [Date of Incident], a patient tested positive for COVID-19 and was admitted to our hospital. Despite our best efforts, the patient passed away due to complications related to the virus.\n",
            "\n",
            "- \"COVID-19: Tragic Loss of Italian Doctors\" - This peer-reviewed article published in the International Journal of Infectious Diseases on March 25, 2020, details the cases of Dr. Donati and Dr.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Man seen in viral pics was a COVID-19 patient who fell in love with his lady doctor. The two got engaged in the same hospital in Egypt.'.\n",
            "Claim: Man seen in viral pics was a COVID-19 patient who fell in love with his lady doctor. The two got engaged in the same hospital in Egypt.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the provided documents, specifically the article \"covid-19: tragic loss of italian doctors\" published in the international journal of infectious diseases, which mentions the cases of dr. donati and dr. messina, two experienced healthcare professionals who contracted covid-19 while providing care to patients.\n",
            "Actual Justification: the claim is false. the viral images are actually of a pre-wedding photoshoot, not of a covid-19 patient and his doctor in egypt. the photoshoot took place in egypt, but it was not related to a covid-19 case or hospital engagement.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb729e6a9edc16c67657d\n",
            "Found 4 documents.\n",
            "['FAKE', '', \"The claim states that the Ib Security Assistant exam results 2019 will be declared soon at mha.gov.in, but the provided documents do not support this claim. The documents only mention searching for exam results on IBPS' website, not on mha.gov.in, and do not provide any information about the declaration of results for the Ib Security Assistant exam in 2019.\"]\n",
            "Claim #4780\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can't provide real-time information or predict future events, including the declaration of results for the Ib Security Assistant exam in 2019. However, I can tell you that if you're looking for\n",
            "\n",
            "* Keep in mind that IBPS might have updated information on their website regarding the exam results.\n",
            "\n",
            "2. **Search for Exam Results:** Look for a section labeled \"Exam Results\" or \"Announcements.\" This section typically lists all the exams conducted by IBPS, including the RRB PO Prelims.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Ib security assistant results 2019 to be declared soon at mha.gov.in.'.\n",
            "Claim: Ib security assistant results 2019 to be declared soon at mha.gov.in.\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim states that the ib security assistant exam results 2019 will be declared soon at mha.gov.in, but the provided documents do not support this claim. the documents only mention searching for exam results on ibps' website, not on mha.gov.in, and do not provide any information about the declaration of results for the ib security assistant exam in 2019.\n",
            "Actual Justification: the claim is accurate as per the article, which reports that the ib security assistant 2019 results will be declared soon on the mha website, and provides steps to check the results.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb72be6a9edc16c67657e\n",
            "Found 13 documents.\n",
            "['TRUE', '', 'The justification is that the provided context does not mention a Chhattisgarh man being killed in a \"crossfire\" by police in Madhya Pradesh. Instead, it mentions a separate incident involving the Assam Rifles and the Manipur Police, and another incident of a fire breaking out in Gwalior, Madhya Pradesh.']\n",
            "Claim #4781\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The incident you described involves a man from Chhattisgarh being killed in a \"crossfire\" by police in Madhya Pradesh. This type of incident often involves a misunderstanding or a situation where\n",
            "\n",
            "the Assam Rifles, identified as Naib Subedar Manjit Singh, was killed in an exchange of fire with the Manipur Police during an operation in the district of Imphal West.\n",
            "\n",
            "A fire broke out at a shop-cum-residential complex in Gwalior, Madhya Pradesh, resulting in the deaths of seven people, including four children. The incident highlights the vulnerability of\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'chhattisgarh man killed in ‘crossfire’ by police in madhya pradesh'.\n",
            "Claim: chhattisgarh man killed in ‘crossfire’ by police in madhya pradesh\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the provided context does not mention a chhattisgarh man being killed in a \"crossfire\" by police in madhya pradesh. instead, it mentions a separate incident involving the assam rifles and the manipur police, and another incident of a fire breaking out in gwalior, madhya pradesh.\n",
            "Actual Justification: the claim that a man from chhattisgarh was killed in a crossfire by police in madhya pradesh is true. according to the indian express, a man named ramesh from chhattisgarh was killed during an encounter between the police and alleged criminals in madhya pradesh. the police stated that ramesh was caught in the crossfire and succumbed to his injuries. an investigation has been launched into the incident.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb72de6a9edc16c67657f\n",
            "Found 38 documents.\n",
            "['FAKE', 'The justification is that there is no supporting document provided to verify the claim, and the text itself says \"I cannot provide supporting documents\" for the claim.']\n",
            "Claim #4782\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The information you provided is a tragic and concerning report. The killing of a Hindu family in Bangladesh by Muslims amid the ongoing unrest in the country highlights the deep-seated tensions and\n",
            "\n",
            "I cannot provide supporting documents for the claim that a Hindu family was killed by Muslims in Bangladesh amid the ongoing unrest in the country. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that a Hindu family was killed by Muslims in Bangladesh amid the ongoing unrest in the country. \n",
            "\n",
            "Heres why\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A Hindu family was killed by Muslims in Bangladesh amid the ongoing unrest in the country'.\n",
            "Claim: A Hindu family was killed by Muslims in Bangladesh amid the ongoing unrest in the country\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that there is no supporting document provided to verify the claim, and the text itself says \"i cannot provide supporting documents\" for the claim.\n",
            "Actual Justification: the claim that the video shows the corpses of a hindu family killed by muslims in bangladesh amid the ongoing unrest is false. according to india today, the video is actually from july 28, 2024, and shows a muslim family from brahmanbaria's nabinagar in bangladesh. the family members were found dead under mysterious circumstances, and the video has no connection to any communal violence involving hindus and muslims.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb731e6a9edc16c676580\n",
            "Found 9 documents.\n",
            "['TRUE', 'The justification is based on the phrase \"The implementation of the police commissionerate system in Lucknow and Noida, as approved by the UP cabinet, is a significant step towards modernizing law enforcement in the state.\" which explicitly mentions that the UP cabinet has approved the implementation of the police commissionerate system in Lucknow and Noida.']\n",
            "Claim #4783\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The implementation of the police commissionerate system in Lucknow and Noida, as approved by the UP cabinet, is a significant step towards modernizing law enforcement in the state. This system\n",
            "\n",
            "This initiative is part of a broader effort to enhance the overall security and well-being of citizens in Lucknow and Noida, and it is expected to have a positive impact on crime prevention,\n",
            "\n",
            "the Government of Uttar Pradesh or the Ministry of Home Affairs Government of India.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'UP cabinet gives nod for police commissionerate system in lucknow, noida.'.\n",
            "Claim: UP cabinet gives nod for police commissionerate system in lucknow, noida.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is based on the phrase \"the implementation of the police commissionerate system in lucknow and noida, as approved by the up cabinet, is a significant step towards modernizing law enforcement in the state.\" which explicitly mentions that the up cabinet has approved the implementation of the police commissionerate system in lucknow and noida.\n",
            "Actual Justification: the article from the statesman confirms that the uttar pradesh cabinet approved the implementation of the police commissionerate system in lucknow and noida.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb738e6a9edc16c676581\n",
            "Found 42 documents.\n",
            "['TRUE', '', 'The claim is supported by the context provided, which mentions the need for in-depth case studies of specific reserved seat constituencies to analyze local factors and their impact on NOTA (Not Applicable) vote share. This suggests that the claim is referring to a real phenomenon or issue related to NOTA votes in reserved constituencies.']\n",
            "Claim #4784\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Could you please provide more context or clarify what you mean by \"nota vote\" and \"reserved constituencies\"? This will help me provide a more accurate and helpful response.\n",
            "\n",
            "To support the claim The curious case of nota vote in reserved constituencies youll need to gather a variety of documents that provide context data and analysis related to the Not Applicable NOTA\n",
            "\n",
            "* In-depth case studies of specific reserved seat constituencies, analyzing local factors and their impact on NOTA vote share.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'The curious case of nota vote in reserved constituencies.'.\n",
            "Claim: The curious case of nota vote in reserved constituencies.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the context provided, which mentions the need for in-depth case studies of specific reserved seat constituencies to analyze local factors and their impact on nota (not applicable) vote share. this suggests that the claim is referring to a real phenomenon or issue related to nota votes in reserved constituencies.\n",
            "Actual Justification: the claim that nota (none of the above) vote share is higher in reserved constituencies was reported by factly. according to the article, data from multiple elections indicates that the vote share for nota is consistently higher in sc and st reserved constituencies compared to general constituencies. this trend has been observed in both lok sabha and assembly elections since the introduction of nota in 2013.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb73be6a9edc16c676582\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The given context provides evidence of the puppet\\'s dancing through the \"Audio\" document, which is the full audio track of the song \"Naatu Naatu\", and the \"Visual\" document, which shows a video clip of the puppet dancing to the song\\'s rhythm.']\n",
            "Claim #4785\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Audio:** The full audio track of 'Naatu Naatu', a popular song from the 2022 Indian film \"RRR\". The puppet's dancing should be clearly audible, with the energetic rhythm and catchy melody of the\n",
            "\n",
            "Remember that the key is to provide evidence of the puppet's dancing to the specific song 'Naatu Naatu'.\n",
            "\n",
            "* **Visual:** A video clip showing a puppet, likely a traditional Indian puppet like a shadow puppet or a string puppet, dancing energetically to the rhythm of 'Naatu Naatu'. The puppet's movements\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A puppet dancing to the tune of 'naatu naatu'.'.\n",
            "Claim: A puppet dancing to the tune of 'naatu naatu'.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context provides evidence of the puppet's dancing through the \"audio\" document, which is the full audio track of the song \"naatu naatu\", and the \"visual\" document, which shows a video clip of the puppet dancing to the song's rhythm.\n",
            "Actual Justification: the video is doctored; the dancing figure is a puppet manipulated to appear as if it is dancing to the song 'naatu naatu'.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb73fe6a9edc16c676583\n",
            "Found 6 documents.\n",
            "['FAKE', '', 'The justification is that the text states \"there is no credible evidence or widely accepted scientific proof that Nostradamus, the French astrologer and physician of the 16th century, predicted the outbreak of [COVID-19]\" and \"there is no historical or scientific evidence linking Nostradamus\\'s prophecies to the specific [COVID-19]\". This indicates that there is no evidence to support the claim that Nostradamus predicted the outbreak of coronavirus.']\n",
            "Claim #4786\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "the coronavirus (COVID-19) in his book \"Les Prophéties\" or any other work. Nostradamus is known for his prophecies, which often involve cryptic and symbolic language, and while some of his\n",
            "\n",
            "It's important to clarify that there is no credible evidence or widely accepted scientific proof that Nostradamus, the French astrologer and physician of the 16th century, predicted the outbreak of\n",
            "\n",
            "community and health organizations have been instrumental in tracking and understanding the virus, and there is no historical or scientific evidence linking Nostradamus's prophecies to the specific\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'French astrologer Nostradamus had predicted the outbreak of coronavirus in his book 'Les Prophéties'.'.\n",
            "Claim: French astrologer Nostradamus had predicted the outbreak of coronavirus in his book 'Les Prophéties'.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the text states \"there is no credible evidence or widely accepted scientific proof that nostradamus, the french astrologer and physician of the 16th century, predicted the outbreak of [covid-19]\" and \"there is no historical or scientific evidence linking nostradamus's prophecies to the specific [covid-19]\". this indicates that there is no evidence to support the claim that nostradamus predicted the outbreak of coronavirus.\n",
            "Actual Justification: while nostradamus's cryptic verses have been interpreted in many ways, there is no direct or specific mention of the coronavirus pandemic in his book 'les prophéties'. the claim is speculative and not based on any verifiable evidence.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb743e6a9edc16c676584\n",
            "Found 22 documents.\n",
            "['TRUE', '', 'The justification is that the text does not specify the country of origin for the app-based mobile drone toilet, but it does mention features and concepts related to the technology, such as an app-based interface and convenience and accessibility, without mentioning China specifically.']\n",
            "Claim #4787\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The app-based mobile drone toilet is an innovative concept that combines mobile technology and drone technology to provide a unique and modern solution for public sanitation. Here's a breakdown of its\n",
            "\n",
            "- **App-Based Interface:** Users can access and control the drone toilet through a mobile application. This app likely includes features like booking a toilet, tracking the drone's location, and\n",
            "\n",
            "- **Convenience and Accessibility:** This technology could revolutionize public sanitation by providing a convenient and accessible solution. Users can easily access the drone toilet through the app,\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.' An app-based mobile drone toilet developed in China.'.\n",
            "Claim:  An app-based mobile drone toilet developed in China.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the text does not specify the country of origin for the app-based mobile drone toilet, but it does mention features and concepts related to the technology, such as an app-based interface and convenience and accessibility, without mentioning china specifically.\n",
            "Actual Justification: the claim is false. the image does not depict a real mobile drone toilet developed in china. it is an ai-generated image that has been misrepresented as a real product.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb744e6a9edc16c676585\n",
            "Found 1 documents.\n",
            "['TRUE', '', 'The context does not mention Charanjit Singh Channi, the former Chief Minister of Punjab, climbing a pole and fixing the power supply. The only information provided about Channi is that he was a singer in his youth, but there is no mention of him fixing power supply or climbing a pole.']\n",
            "Claim #4788\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "3. **Charanjit Singh Channi**: Another former Chief Minister of Punjab, who also held various political offices. Channi is known for his contributions to the Congress party in the state.\n",
            "\n",
            "Singh Channi the former Chief Minister of Punjab was a singer in his youth.\n",
            "\n",
            "- **Privatization of the Chandigarh Electricity Wing**: Privatization refers to the process of transferring state-owned assets or services to the private sector. In this context, the Chandigarh\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Punjab CM Charanjit Singh Channi climbed a pole and fixed the power supply of Kurali area after getting complaints that electricity was disconnected in poor households due to non-payment of bills.'.\n",
            "Claim: Punjab CM Charanjit Singh Channi climbed a pole and fixed the power supply of Kurali area after getting complaints that electricity was disconnected in poor households due to non-payment of bills.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the context does not mention charanjit singh channi, the former chief minister of punjab, climbing a pole and fixing the power supply. the only information provided about channi is that he was a singer in his youth, but there is no mention of him fixing power supply or climbing a pole.\n",
            "Actual Justification: the image shared in the claim is not recent. it is an old photo of punjab cm charanjit singh channi from 2019, not an event involving a power supply issue in kurali. the claim is misleading as the photo does not depict a recent action related to the electricity supply in kurali.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb746e6a9edc16c676586\n",
            "Found 16 documents.\n",
            "['FAKE', 'The justification is that the text states \"I cannot provide supporting documents for the claim\" which implies that the claim is false and there is no evidence to support it.']\n",
            "Claim #4789\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Yes, that's correct! Aishwarya Rai Bachchan, the former Miss World and actress, posed with Salman Khan for a picture at the wedding of Anant Ambani and Radhika Merchant. The event was a grand affair,\n",
            "\n",
            "I cannot provide supporting documents for the claim that Aishwarya Rai Bachchan posed with Salman Khan for a picture at the wedding of Anant Ambani and Radhika Merchant. As an AI language model I do\n",
            "\n",
            "I cannot provide supporting documents for the claim that Aishwarya Rai Bachchan posed with Salman Khan for a picture at the wedding of Anant Ambani and Radhika Merchant. As an AI language model I do\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Aishwarya rai bachchan posed with salman khan for a picture at the wedding of anant ambani and radhika merchant.'.\n",
            "Claim: Aishwarya rai bachchan posed with salman khan for a picture at the wedding of anant ambani and radhika merchant.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the text states \"i cannot provide supporting documents for the claim\" which implies that the claim is false and there is no evidence to support it.\n",
            "Actual Justification: the claim that aishwarya rai bachchan posed with salman khan for a picture at the wedding of anant ambani and radhika merchant is false. according to news18, the viral photo is edited. the original picture featured salman khan posing with just his sister arpita khan, not aishwarya rai bachchan.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb74be6a9edc16c676587\n",
            "Found 46 documents.\n",
            "['TRUE', '', 'The given context suggests that the fact checker should search online for images or news articles related to a \"mazar on national highway India\" which implies that such a structure does exist. The fact checker is not provided with any evidence to the contrary, and therefore, the claim is considered true.']\n",
            "Claim #4790\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you might be asking about a specific location or structure, but the phrase \"A mazar built on a national highway in India\" is not entirely clear. Here are a few possible interpretations:\n",
            "\n",
            "Heres how you can approach finding supporting documents for A mazar built on a national highway in India\n",
            "\n",
            ". Search Online\n",
            "\n",
            "Google Images Search for mazar on national highway India or similar keywords. You might find images or news articles that could provide evidence.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A mazar built on a national highway in India.'.\n",
            "Claim: A mazar built on a national highway in India.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context suggests that the fact checker should search online for images or news articles related to a \"mazar on national highway india\" which implies that such a structure does exist. the fact checker is not provided with any evidence to the contrary, and therefore, the claim is considered true.\n",
            "Actual Justification: the claim is false. the picture circulating on social media is photoshopped. the image does not show a real mazar built on a national highway in india. the picture has been manipulated and misrepresented to create a false narrative about 'land jihad'.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb74ce6a9edc16c676588\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The claim is true because it is mentioned in the context that Rahul Gandhi is a member of the Indian National Congress (INC) party, not the Bharatiya Janata Party (BJP). Therefore, it is unlikely that he would be holding a kid wearing a BJP t-shirt.']\n",
            "Claim #4791\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Rahul Gandhi is holding a kid wearing a BJP t-shirt.\n",
            "\n",
            "Who is Rahul Gandhi Rahul Gandhi is a prominent Indian politician and a member of the Indian National Congress party. He is the son of former Prime Minister Rajiv Gandhi and the grandson of Indias\n",
            "\n",
            "It seems there might be a bit of confusion or a typo in your statement. Rahul Gandhi is a prominent figure in the Indian National Congress (INC), not the BJP (Bharatiya Janata Party). The BJP and the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Rahul Gandhi is holding a kid wearing a BJP t-shirt.'.\n",
            "Claim: Rahul Gandhi is holding a kid wearing a BJP t-shirt.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is true because it is mentioned in the context that rahul gandhi is a member of the indian national congress (inc) party, not the bharatiya janata party (bjp). therefore, it is unlikely that he would be holding a kid wearing a bjp t-shirt.\n",
            "Actual Justification: the image circulating online, showing rahul gandhi holding a kid in a bjp t-shirt, is morphed. the original picture has been edited to add the bjp t-shirt to the child.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb74ee6a9edc16c676589\n",
            "Found 19 documents.\n",
            "['TRUE', 'The claim is TRUE because the provided context mentions \"the threat of \\'serious consequences\\' for protestors\" which is similar to the language used in the adani group press release, warning of \"serious consequences\" for Kenyan protestors.']\n",
            "Claim #4792\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Threats and Coercion:** The threat of \"serious consequences\" for protestors could be seen as a criminal offense, potentially falling under laws against threats, coercion, or intimidation.\n",
            "\n",
            "political consequences.\n",
            "\n",
            "**Challenges and Consequences:** Protesting against a government's actions, especially during a military conflict, can be risky. Protesters may face challenges such as:\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'An adani group press release warns of ‘serious consequences’ for kenyan protestors, threatening to name government beneficiaries and individuals who got bribes from the company.'.\n",
            "Claim: An adani group press release warns of ‘serious consequences’ for kenyan protestors, threatening to name government beneficiaries and individuals who got bribes from the company.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is true because the provided context mentions \"the threat of 'serious consequences' for protestors\" which is similar to the language used in the adani group press release, warning of \"serious consequences\" for kenyan protestors.\n",
            "Actual Justification: the claim that an adani group press release warns of ‘serious consequences’ for kenyan protestors, threatening to name government beneficiaries and individuals who got bribes from the company is false. according to india today, the press release is fake and was never issued by the adani group. the company clarified this through a statement on september 16, 2024.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb750e6a9edc16c67658a\n",
            "Found 16 documents.\n",
            "['TRUE', '', 'The justification is that the claim states \"I can confirm that PM Narendra Modi has not paid any tribute to Nathuram Godse, the assassin of Mahatma Gandhi\" which implies that the claim is false, and there is no evidence provided to suggest that the claim is true.']\n",
            "Claim #4793\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can confirm that PM Narendra Modi has not paid any tribute to Nathuram Godse, the assassin of Mahatma Gandhi. In fact, the Indian government and its leaders have consistently condemned the actions\n",
            "\n",
            "I cannot provide supporting documents for the claim that PM Narendra Modi paid tribute to Nathuram Godse.\n",
            "\n",
            "I cannot provide supporting documents for the claim that PM Narendra Modi paid tribute to Nathuram Godse.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'PM Narendra Modi paying tribute to Nathuram Godse.'.\n",
            "Claim: PM Narendra Modi paying tribute to Nathuram Godse.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claim states \"i can confirm that pm narendra modi has not paid any tribute to nathuram godse, the assassin of mahatma gandhi\" which implies that the claim is false, and there is no evidence provided to suggest that the claim is true.\n",
            "Actual Justification: the claim that pm narendra modi paid tribute to nathuram godse is false. the photo being circulated was misleading and doctored. in reality, the photo was taken during an event where modi was paying tribute to martyrs of the freedom struggle, not godse.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb755e6a9edc16c67658b\n",
            "Found 4 documents.\n",
            "['TRUE', '', \"The justification is that the article provides specific details about the incident, including the fact that the driver was arrested on his way to Hathras, and the family of the driver stating that he did not know the others' intentions, which matches the provided claim.\"]\n",
            "Claim #4794\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "A driver and three others were arrested for sedition after an incident in Hathras. The driver, who was arrested on his way to Hathras, claimed he did not know the other individuals involved. The\n",
            "\n",
            "family of the driver stated that he was unaware of the others' intentions. The charges of sedition are serious and could have significant legal consequences. The details of the case and the specific\n",
            "\n",
            "The information you've provided describes a serious legal situation involving four individuals who were arrested on suspicion of conspiring to commit violence in Hathras, a town in India. They are\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Arrested on way to hathras: driver among 4 booked for sedition, family says he did not know the others'.\n",
            "Claim: Arrested on way to hathras: driver among 4 booked for sedition, family says he did not know the others\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the article provides specific details about the incident, including the fact that the driver was arrested on his way to hathras, and the family of the driver stating that he did not know the others' intentions, which matches the provided claim.\n",
            "Actual Justification: the claim that a driver among four individuals arrested on their way to hathras was booked for sedition, with his family stating he did not know the others, is true. according to india today, the uttar pradesh police arrested four people, including a cab driver, on their way to hathras and booked them under the unlawful activities (prevention) act (uapa) and sedition charges. the family of the driver claimed he did not know the other three individuals.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb758e6a9edc16c67658c\n",
            "Found 9 documents.\n",
            "['FAKE', '', 'The justification is that there is no credible, verified source that confirms Ronaldo uttering \"Inshallah\" in an Instagram live after joining Al Nassr, and the only information provided is a lack of verified sources, indicating that the claim is likely false.']\n",
            "Claim #4795\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide a supporting document for the claim that Cristiano Ronaldo said 'Inshallah' during an Instagram live after joining Al Nassr. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "* **Lack of Verified Sources:** There are no credible, verified sources (news outlets, official club statements, Ronaldo's social media accounts) that confirm Ronaldo uttering \"Inshallah\" in this\n",
            "\n",
            "In  Cristiano Ronaldo the renowned Portuguese professional soccer player expressed his support for the Palestinian cause. He posted a message on his Instagram story which read Free Palestine. This\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Cristiano Ronaldo said 'Inshallah' during an Instagram live after joining the Saudi Arabian club, Al Nassr.'.\n",
            "Claim: Cristiano Ronaldo said 'Inshallah' during an Instagram live after joining the Saudi Arabian club, Al Nassr.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that there is no credible, verified source that confirms ronaldo uttering \"inshallah\" in an instagram live after joining al nassr, and the only information provided is a lack of verified sources, indicating that the claim is likely false.\n",
            "Actual Justification: cristiano ronaldo did not say 'inshallah' during his instagram live after joining al nassr. the claim is based on a misinterpretation of his words.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb75be6a9edc16c67658d\n",
            "Found 25 documents.\n",
            "['TRUE', 'The justification is that the provided context states the incident took place in the Kondapur area of Hyderabad, India, not Hubli, Karnataka, which contradicts the initial claim.']\n",
            "Claim #4796\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Introduction\n",
            " Briefly describe the incident mentioning the successful apprehension of a terrorist at the Hubli bus stand in Karnataka.\n",
            "\n",
            "Understanding the Request\n",
            "\n",
            "Youre asking for supporting evidence for a specific event a terrorist being caught at a bus stand in Hubli Karnataka that likely occurred in the past.\n",
            "\n",
            "* The incident took place in the Kondapur area of Hyderabad, India.\n",
            "* The police officer was allegedly attacked by a group of people.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Police nabbed a terrorist at Hubli bus stand in Karnataka. The entire action was caught on camera.'.\n",
            "Claim: Police nabbed a terrorist at Hubli bus stand in Karnataka. The entire action was caught on camera.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided context states the incident took place in the kondapur area of hyderabad, india, not hubli, karnataka, which contradicts the initial claim.\n",
            "Actual Justification: the claim about a terrorist being nabbed at hubli bus stand is false. the person arrested was not a terrorist, but a person with a criminal background who had been involved in other offenses.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb75ee6a9edc16c67658e\n",
            "Found 15 documents.\n",
            "['TRUE', '', 'The statement \"Modi talks development but ally Udhhav says \\'come look at farmers\\' plight\\'\" is supported by the quote from Uddhav Thackeray, which highlights the contrast in perspectives between the central government led by PM Modi and the state government led by Uddhav Thackeray on the issue of farmers\\' welfare in Maharashtra.']\n",
            "Claim #4797\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement \"Modi talks development but ally Udhhav says 'come look at farmers' plight'\" reflects a potential contrast in perspectives between the central government led by Prime Minister Narendra\n",
            "\n",
            "bring attention to our plight. Our farmers are determined to protect their livelihoods and will not be silenced.\"\n",
            "\n",
            "- **Farmer Welfare**: Maharashtra, like many other states in India, has a significant agrarian economy, and farmers' welfare is a critical issue. Uddhav Thackeray's statement, \"come look at farmers'\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'In maharashtra, modi talks development but ally uddhav says 'come look at farmers' plight'.'.\n",
            "Claim: In maharashtra, modi talks development but ally uddhav says 'come look at farmers' plight'.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the statement \"modi talks development but ally udhhav says 'come look at farmers' plight'\" is supported by the quote from uddhav thackeray, which highlights the contrast in perspectives between the central government led by pm modi and the state government led by uddhav thackeray on the issue of farmers' welfare in maharashtra.\n",
            "Actual Justification: the claim is accurate according to the article, which reports that uddhav thackeray criticized modi's focus on development while highlighting the plight of farmers in maharashtra.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb761e6a9edc16c67658f\n",
            "Found 12 documents.\n",
            "['TRUE', '', 'The statement is not entirely accurate as it is comparing West Bengal to Kashmir, which is a sensitive topic in Indian politics, and it is not a factual comparison. The statement is also making a sensational claim about daily arrests of terrorists in West Bengal, which is not supported by any concrete evidence.']\n",
            "Claim #4798\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement made by the BJP chief of West Bengal, suggesting that the state has become akin to Kashmir due to the frequent arrests of terrorists, is a controversial and potentially inflammatory\n",
            "\n",
            "- **West Bengal Elections**: West Bengal is a significant state in Indian politics, known for its diverse demographics and political history. The BJP has been working to strengthen its position in\n",
            "\n",
            "The statement you provided is a comparison of the number of terrorists killed in the Jammu and Kashmir region during two different periods of Indian governance. Here's a breakdown of the information:\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'West bengal has become second kashmir with terrorists arrested daily, says state bjp chief'.\n",
            "Claim: West bengal has become second kashmir with terrorists arrested daily, says state bjp chief\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the statement is not entirely accurate as it is comparing west bengal to kashmir, which is a sensitive topic in indian politics, and it is not a factual comparison. the statement is also making a sensational claim about daily arrests of terrorists in west bengal, which is not supported by any concrete evidence.\n",
            "Actual Justification: the claim is true, as reported by *theprint*. the bjp's state chief in west bengal has stated that the region has become like kashmir, with terrorists being arrested daily, highlighting the security situation in the state.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb765e6a9edc16c676590\n",
            "Found 25 documents.\n",
            "['TRUE', '', \"The justification is that the given context mentions India providing historical records and legal documents to support its claim of ownership over the Jinnah House, which is in line with the claim that India rejects Pakistan's claim and says the property belongs to it.\"]\n",
            "Claim #4799\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The claim in question pertains to the ownership of the Jinnah House, a historical building in Karachi, Pakistan. Pakistan has been asserting its claim over the property, but India has disputed this,\n",
            "\n",
            "- India could provide historical records and legal documents that trace the ownership of the Jinnah House back to the time of its construction or earlier. These records might include deeds,\n",
            "\n",
            "the Jinnah House or similar properties, these could support India's case.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'India rejects pakistan's claim over jinnah house saying property belongs to it'.\n",
            "Claim: India rejects pakistan's claim over jinnah house saying property belongs to it\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the given context mentions india providing historical records and legal documents to support its claim of ownership over the jinnah house, which is in line with the claim that india rejects pakistan's claim and says the property belongs to it.\n",
            "Actual Justification: india rejected pakistan's claim over jinnah house, stating that the property in mumbai rightfully belongs to india. the government maintained that the house, associated with the founder of pakistan, mohammad ali jinnah, was a part of india's heritage and jurisdiction.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb768e6a9edc16c676591\n",
            "Found 8 documents.\n",
            "['TRUE', '', 'The statement is TRUE because the context suggests that there is a significant political event or movement taking place in India, specifically a nationwide \"Bharat Bandh\", and the BJP is criticizing the government or another party through the phrase \"slams doublespeak\", implying that the event is being supported by the opposition.']\n",
            "Claim #4800\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement \"Bharat bandh today: BJP slams doublespeak as opposition backs stir\" suggests that there is a significant political event or movement taking place in India, specifically a nationwide\n",
            "\n",
            "2. **BJP Slams Doublespeak**: The BJP (Bharatiya Janata Party) is a major political party in India. The phrase \"slams doublespeak\" implies that the BJP is criticizing the government or another party\n",
            "\n",
            "Without specific details about the nature of the \"Bharat Bandh\" and its organizers, it's challenging to provide a more precise response. However, the key lies in a balanced approach that addresses\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Bharat bandh today: bjp slams doublespeak as opposition backs stir.'.\n",
            "Claim: Bharat bandh today: bjp slams doublespeak as opposition backs stir.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the statement is true because the context suggests that there is a significant political event or movement taking place in india, specifically a nationwide \"bharat bandh\", and the bjp is criticizing the government or another party through the phrase \"slams doublespeak\", implying that the event is being supported by the opposition.\n",
            "Actual Justification: according to *the indian express*, the bjp criticized opposition parties for their support of the bharat bandh called by farmers protesting against new agricultural laws, accusing them of doublespeak on the issue.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb76be6a9edc16c676592\n",
            "Found 14 documents.\n",
            "['TRUE', '', 'The justification is based on the provided context, which suggests that the Allahabad High Court has made a statement regarding the misuse of the UP cow slaughter law against innocent individuals, implying that the claim is true.']\n",
            "Claim #4801\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The Allahabad High Court's statement regarding the misuse of the UP cow slaughter law against innocent individuals highlights a serious issue in the application of legal provisions. Here are some key\n",
            "\n",
            "- **Legal Context**: The UP cow slaughter law, likely referring to the Prevention of Cruelty to Animals (Prohibition of Slaughter) Act, 1960, or similar legislation, is designed to protect animals\n",
            "\n",
            "Legal Considerations In many places including West Bengal there are laws regulating animal slaughtering often requiring specific conditions to be met such as proper facilities trained personnel and\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'UP cow slaughter law is being misused against innocent: allahabad hc'.\n",
            "Claim: UP cow slaughter law is being misused against innocent: allahabad hc\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is based on the provided context, which suggests that the allahabad high court has made a statement regarding the misuse of the up cow slaughter law against innocent individuals, implying that the claim is true.\n",
            "Actual Justification: the allahabad high court observed that the uttar pradesh cow slaughter law was being misused against innocent individuals. the court's remark came during a hearing where it emphasized that the law should not be misused to harass or target innocent people. the court's observations pointed out that certain individuals were being wrongfully accused under this law.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb76de6a9edc16c676593\n",
            "Found 54 documents.\n",
            "['TRUE', '', 'The justification is that the context mentions \"the jostling to enter the cinema during its inauguration reflects the enthusiasm and curiosity of the Saudi public for this new form of entertainment\" which suggests that people are excited and curious about the new cinema, and the fact that it is showing an Israeli movie is not explicitly mentioned as a contradictory point.']\n",
            "Claim #4802\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The jostling to enter the cinema during its inauguration reflects the enthusiasm and curiosity of the Saudi public for this new form of entertainment. It also symbolizes a significant cultural\n",
            "\n",
            "The idea of a cinema in Saudi Arabia showing an Israeli movie is contrary to the current social and political climate of the country. While there have been discussions and some steps towards opening\n",
            "\n",
            "Check the website of the Saudi Arabian government or the Royal Court They might issue press releases or statements regarding the inauguration of new cinemas or cultural events.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'People in Saudi Arabia are seen jostling to enter a cinema hall during its inauguration by Crown Prince Mohammed bin Salman. The theatre is showing an Israeli movie.'.\n",
            "Claim: People in Saudi Arabia are seen jostling to enter a cinema hall during its inauguration by Crown Prince Mohammed bin Salman. The theatre is showing an Israeli movie.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the context mentions \"the jostling to enter the cinema during its inauguration reflects the enthusiasm and curiosity of the saudi public for this new form of entertainment\" which suggests that people are excited and curious about the new cinema, and the fact that it is showing an israeli movie is not explicitly mentioned as a contradictory point.\n",
            "Actual Justification: the claim is partly false. while there was an inauguration of a cinema in saudi arabia with crowds seen outside, the movie shown was not an israeli film. the crowd was not specifically related to the screening of an israeli movie, but was instead a general reaction to the opening of a new cinema. the movie shown was not linked to any particular country, including israel.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb770e6a9edc16c676594\n",
            "Found 13 documents.\n",
            "['TRUE', 'The claim states \"Diwali deals can get you a smartphone for as low as rs 9!\", which is mentioned in the context of searching for news articles or press releases that highlight low-priced smartphones during the festival, specifically mentioning prices similar to Rs 9. This suggests that the claim is indeed TRUE, as it is mentioned in the context of Diwali deals and low-priced smartphones.']\n",
            "Claim #4803\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "4. **News Articles or Press Releases:** Search for recent news articles or press releases from reputable sources that mention Diwali smartphone deals. Look for articles that specifically highlight\n",
            "\n",
            "Look for sections highlighting smartphones priced at Rs 9 or similar low prices.\n",
            "\n",
            "low-priced smartphones during the festival.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Diwali deals can get you a smartphone for as low as rs 9!'.\n",
            "Claim: Diwali deals can get you a smartphone for as low as rs 9!\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim states \"diwali deals can get you a smartphone for as low as rs 9!\", which is mentioned in the context of searching for news articles or press releases that highlight low-priced smartphones during the festival, specifically mentioning prices similar to rs 9. this suggests that the claim is indeed true, as it is mentioned in the context of diwali deals and low-priced smartphones.\n",
            "Actual Justification: the claim that diwali deals can get you a smartphone for as low as rs 9 is false. according to india today, this is a data harvesting scam. the offers are fake and are designed to collect personal information from unsuspecting users.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb774e6a9edc16c676595\n",
            "Found 28 documents.\n",
            "['FAKE', '', 'The claim lacks specific details about the incident, including the name of the imam, location of the mosque, and nature of the arrest, making it difficult to verify the claim.']\n",
            "Claim #4804\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide specific documents or information that directly support the claim of an imam being arrested in a Saudi Arabian mosque for expressing support for Palestine. However I can offer some\n",
            "\n",
            "The claim you mentioned involves a specific incident of a Saudi Arabian imam being arrested for expressing support for Palestine. Here are some points to consider and potential sources of information\n",
            "\n",
            "leaders being detained or arrested for their political or religious views. Look for specific details about the incident including the name of the imam the location of the mosque and the nature of the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Saudi Arabian police arresting an imam in a mosque for expressing support for Palestine.'.\n",
            "Claim: Saudi Arabian police arresting an imam in a mosque for expressing support for Palestine.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim lacks specific details about the incident, including the name of the imam, location of the mosque, and nature of the arrest, making it difficult to verify the claim.\n",
            "Actual Justification: the claim is false. the video is from 2018 and shows a mentally unstable person being escorted out of a mosque in yanbu, saudi arabia. it is not related to recent events or any expression of support for palestine.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb777e6a9edc16c676596\n",
            "Found 3 documents.\n",
            "['TRUE', 'The claim is supported by the context, which states that \"States) did not have any restrictions related to the coronavirus during the event this year.\" This suggests that there were no mask-wearing, social distancing, or quarantine protocols in place during the G7 summit.']\n",
            "Claim #4805\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "States), did not have any restrictions related to the coronavirus during the event this year. This is in contrast to the measures that were widely implemented during the early stages of the pandemic,\n",
            "\n",
            "violations covered such as not adhering to social distancing rules not wearing masks or not following quarantine protocols.\n",
            "\n",
            "lead to the spread of the virus, especially in a high-profile event like the G7 summit.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'No masks, no social distancing, no quarantine – there were no coronavirus restrictions at this year’s G7 summit.'.\n",
            "Claim: No masks, no social distancing, no quarantine – there were no coronavirus restrictions at this year’s G7 summit.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the context, which states that \"states) did not have any restrictions related to the coronavirus during the event this year.\" this suggests that there were no mask-wearing, social distancing, or quarantine protocols in place during the g7 summit.\n",
            "Actual Justification: this claim is false as it misrepresents the covid-19 protocols followed during the g7 summit. world leaders at the summit were seen following social distancing and mask-wearing protocols as part of the guidelines. the summit did have measures in place to prevent the spread of covid-19, including testing and safety measures for attendees.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb77ae6a9edc16c676597\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The claim \"Massive flood in Uttarakhand\\'s Chamoli as glacier breaks off, 150 labourers missing\" is supported by the document, which states \"The flood resulted in the disappearance of approximately 150 labourers who were working in the area.\" This matches the claim, indicating that the information is true.']\n",
            "Claim #4806\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "- The flood resulted in the disappearance of approximately 150 labourers who were working in the area. Rescue operations were initiated, but many were still missing as of the initial reports.\n",
            "\n",
            "On February 7, 2021, a massive flood occurred in the Chamoli district of Uttarakhand, India, due to the sudden breaking off of a glacier. The event was caused by a combination of factors, including a\n",
            "\n",
            "The statement \"Over 200 people feared missing following Uttarakhand floods, says CM Rawat\" indicates a serious and potentially tragic situation in the state of Uttarakhand, India. Here are some key\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Massive flood in uttarakhand's chamoli as glacier breaks off, 150 labourers missing.'.\n",
            "Claim: Massive flood in uttarakhand's chamoli as glacier breaks off, 150 labourers missing.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim \"massive flood in uttarakhand's chamoli as glacier breaks off, 150 labourers missing\" is supported by the document, which states \"the flood resulted in the disappearance of approximately 150 labourers who were working in the area.\" this matches the claim, indicating that the information is true.\n",
            "Actual Justification: the claim is accurate as the article reports that a massive flood occurred in chamoli, uttarakhand, due to a glacier breaking off, resulting in the disappearance of 150 labourers.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb77ee6a9edc16c676598\n",
            "Found 39 documents.\n",
            "['TRUE', '', 'The supporting points provided are \"Media Reports\", but no specific media reports are mentioned or linked, making it impossible to verify the claim.']\n",
            "Claim #4807\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Claim UK MPs seek ministerial intervention in farmer protests in India.\n",
            "\n",
            "Supporting Points\n",
            "\n",
            ". Media Reports\n",
            "\n",
            "Claim UK MPs seek ministerial intervention in farmer protests in India.\n",
            "\n",
            "Supporting Information\n",
            "\n",
            "The statement \"UK MPs seek ministerial intervention in farmer protests in India\" suggests that members of the UK Parliament (MPs) are calling for the UK government to take action or intervene in the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'UK mps seek ministerial intervention in farmer protests in india.'.\n",
            "Claim: UK mps seek ministerial intervention in farmer protests in india.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the supporting points provided are \"media reports\", but no specific media reports are mentioned or linked, making it impossible to verify the claim.\n",
            "Actual Justification: uk members of parliament (mps) called for ministerial intervention to address the ongoing farmer protests in india, expressing concern over the situation and urging the uk government to take action.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb782e6a9edc16c676599\n",
            "Found 4 documents.\n",
            "['TRUE', '', 'The justification is that the claim \"A woman was killed when a car driven by a drunk driver hit her\" matches the incident described in the Gujarat article, but the location is different (Bharuch, Gujarat instead of Mumbai, India).']\n",
            "Claim #4808\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Location:** Mumbai, India\n",
            "* **Incident:** A woman was killed when a car driven by a drunk driver hit her.\n",
            "* **Arrests:** Three people have been arrested in connection with the incident.\n",
            "\n",
            "---\n",
            "\n",
            "**Gujarat: Three Women Killed in Hit-and-Run Accident in Bharuch**\n",
            "\n",
            "Bharuch, Gujarat - In a tragic incident that has left the community reeling, three women were killed in a hit-and-run accident on the evening of [Date]. The accident occurred on the [Road Name] near\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Mumbai woman killed as car driven by drunk man hits her, three held.'.\n",
            "Claim: Mumbai woman killed as car driven by drunk man hits her, three held.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the claim \"a woman was killed when a car driven by a drunk driver hit her\" matches the incident described in the gujarat article, but the location is different (bharuch, gujarat instead of mumbai, india).\n",
            "Actual Justification: the claim is accurate as a woman in mumbai was killed after being hit by a car driven by a drunk man, and three people were arrested, as reported by the times of india.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb783e6a9edc16c67659a\n",
            "Found 9 documents.\n",
            "['TRUE', \"The first line of the article mentions that the Supreme Court dismissed the Chhattisgarh government's plea against the judicial commission's refusal to examine additional witnesses in the 2013 Jheeram Ghati Naxal attack, which matches the given context.\"]\n",
            "Claim #4809\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The Supreme Court's decision to dismiss the Chhattisgarh government's plea regarding the 2013 Jheeram Ghati Naxal attack is significant for several reasons:\n",
            "\n",
            "5. **Further Legal Action**: Despite the Supreme Court's decision, the Chhattisgarh government might still have options for further legal action, such as appealing to the High Court or seeking a\n",
            "\n",
            "Claim The Supreme Court dismissed a plea regarding government nominees on a mosque trust.\n",
            "\n",
            "Supporting Information\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'the supreme court tuesday dismissed chhattisgarh government's plea against judicial commission's refusal to examine additional witnesses in the 2013 jheeram ghati naxal attack that killed 29 people, including leaders of the state congress unit'.\n",
            "Claim: the supreme court tuesday dismissed chhattisgarh government's plea against judicial commission's refusal to examine additional witnesses in the 2013 jheeram ghati naxal attack that killed 29 people, including leaders of the state congress unit\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the first line of the article mentions that the supreme court dismissed the chhattisgarh government's plea against the judicial commission's refusal to examine additional witnesses in the 2013 jheeram ghati naxal attack, which matches the given context.\n",
            "Actual Justification: the claim that the supreme court dismissed chhattisgarh government's plea against the judicial commission's refusal to examine additional witnesses in the 2013 jheeram ghati naxal attack is true. according to business standard, the supreme court dismissed the plea, noting that the commission had already closed its proceedings. the attack in jheeram ghati, darbha area of bastar district, resulted in the deaths of 29 people, including prominent state congress leaders. the state government had sought to examine additional witnesses, but the commission refused, leading to the plea being filed and subsequently dismissed by the supreme court.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb787e6a9edc16c67659b\n",
            "Found 36 documents.\n",
            "['FAKE', '', 'The justification is that the text explicitly states that the accuracy of the claim cannot be verified without further investigation, and that the situation in Assam regarding the NRC process is complex and evolving. Additionally, the text suggests contacting the Assam NRC Coordinator or relevant authorities to report discrepancies, which implies that the claim may not be accurate.']\n",
            "Claim #4810\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            ". Review the Final List Start by carefully examining the final National Register of Citizens NRC list for Assam. Look for any discrepancies errors or inconsistencies in the data. Pay attention to the\n",
            "\n",
            "Accuracy I cannot verify the accuracy of such a claim without further investigation. The situation in Assam regarding the NRC process is complex and evolving.\n",
            "\n",
            ". Contact the Coordinator Reach out to the Assam NRC Coordinator or the relevant authorities responsible for overseeing the NRC process. Send the complaint letter and supporting documents. Request an\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Firs lodged against assam nrc coordinator for discrepancies in the final list'.\n",
            "Claim: Firs lodged against assam nrc coordinator for discrepancies in the final list\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the text explicitly states that the accuracy of the claim cannot be verified without further investigation, and that the situation in assam regarding the nrc process is complex and evolving. additionally, the text suggests contacting the assam nrc coordinator or relevant authorities to report discrepancies, which implies that the claim may not be accurate.\n",
            "Actual Justification: firs have been lodged against prateek hajela, the assam nrc coordinator, over alleged discrepancies found in the final nrc list.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb789e6a9edc16c67659c\n",
            "Found 8 documents.\n",
            "['TRUE', 'The claim states that the government of Andhra Pradesh, led by the YSR Congress Party (YSRCP), has taken a proactive approach to addressing the illegal trade of liquor and sand by establishing a Special Enforcement Bureau, which is supported by the provided documents.']\n",
            "Claim #4811\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The government of Andhra Pradesh, led by the YSR Congress Party (YSRCP), has taken a proactive approach to addressing the illegal trade of liquor and sand by establishing a Special Enforcement Bureau.\n",
            "\n",
            "Regarding alcohol distribution during these protests, it is important to note that the sale and distribution of alcohol are regulated by state governments in India. Each state has its own laws and\n",
            "\n",
            "I cannot provide supporting documents for the claim that Liquor mafia goons thrashing a policeman during the rule of the Mahagathbandhan government in Bihar. \n",
            "\n",
            "Heres why\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'andhra pradesh ysrcp govt sets up special enforcement bureau to crack down on illegal sale of liquor, sand.'.\n",
            "Claim: andhra pradesh ysrcp govt sets up special enforcement bureau to crack down on illegal sale of liquor, sand.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim states that the government of andhra pradesh, led by the ysr congress party (ysrcp), has taken a proactive approach to addressing the illegal trade of liquor and sand by establishing a special enforcement bureau, which is supported by the provided documents.\n",
            "Actual Justification: the andhra pradesh government, led by the ysr congress party (ysrcp), established a special enforcement bureau to address the illegal sale of liquor and sand, as reported by *the statesman*.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb78ce6a9edc16c67659d\n",
            "Found 9 documents.\n",
            "['TRUE', '', 'The justification is that there is no supporting document provided for the claim, and the task requires reviewing historical records, which suggests that the claim is likely to be false.']\n",
            "Claim #4812\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I'm sorry, but I cannot provide supporting documents for the claim \"Mamata Banerjee demands four national capitals on Netaji's birth anniversary.\"\n",
            "\n",
            "* **Review historical records:** Consult historical archives, government documents, or biographies related to Netaji and Mamata Banerjee.\n",
            "\n",
            "- **Mamata**: This is the name of the politician, Mamata Banerjee, who is the Chief Minister of West Bengal and the leader of the TMC.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Mamata banerjee demands four national capitals on netaji's birth anniversary'.\n",
            "Claim: Mamata banerjee demands four national capitals on netaji's birth anniversary\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that there is no supporting document provided for the claim, and the task requires reviewing historical records, which suggests that the claim is likely to be false.\n",
            "Actual Justification: on netaji subhas chandra bose's birth anniversary, west bengal chief minister mamata banerjee proposed the idea of having four national capitals on a rotation basis. she emphasized that this would help ensure balanced development across the country and improve governance.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb78de6a9edc16c67659e\n",
            "Found 29 documents.\n",
            "['TRUE', '', 'The given context does not provide any information or evidence to support the claim that Zaira Wasim has returned to acting after announcing her retirement. There are no articles, interviews, or transcripts mentioned that confirm her return. The task is to verify the claim, and based on the provided information, there is no evidence to support the truthfulness of the claim.']\n",
            "Claim #4813\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "have articles or interviews confirming Zaira Wasims return.\n",
            "\n",
            ". Interview Transcripts If there have been recent interviews with Zaira Wasim search for transcripts or summaries of those interviews. She might have discussed her decision to return to acting and\n",
            "\n",
            "However I can provide some general information about Zaira Wasim and her career if youd like.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Actor Zaira Wasim returns to movies after announcing retirement.'.\n",
            "Claim: Actor Zaira Wasim returns to movies after announcing retirement.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not provide any information or evidence to support the claim that zaira wasim has returned to acting after announcing her retirement. there are no articles, interviews, or transcripts mentioned that confirm her return. the task is to verify the claim, and based on the provided information, there is no evidence to support the truthfulness of the claim.\n",
            "Actual Justification: the claim is false. zaira wasim has not returned to movies after her retirement announcement. a viral image of her on a beach was misinterpreted to suggest her return to bollywood, but she clarified that the image was old and unrelated to any comeback.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb790e6a9edc16c67659f\n",
            "Found 4 documents.\n",
            "['TRUE', 'The claim \"Protest to demand resumption of local train service turns violent in Hooghly\" is true because it is supported by the provided context, which states that \"They damaged railway property including trains tracks and stations leading to a breakdown in law and order. The police had to intervene to control the situation using force to disperse the crowd.\" This indicates that the protest turned violent, which aligns with the claim.']\n",
            "Claim #4814\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "lives. This incident highlights the urgent need for a comprehensive review of railway safety measures and labor rights for migrant workers.\n",
            "\n",
            "They damaged railway property including trains tracks and stations leading to a breakdown in law and order.\n",
            " The police had to intervene to control the situation using force to disperse the crowd.\n",
            "\n",
            "Claim Protest to demand resumption of local train service turns violent in Hooghly\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Bandra chaos after activists' arrest, tv scribe booked over railways note on trains for migrants'.\n",
            "Claim: Bandra chaos after activists' arrest, tv scribe booked over railways note on trains for migrants\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim \"protest to demand resumption of local train service turns violent in hooghly\" is true because it is supported by the provided context, which states that \"they damaged railway property including trains tracks and stations leading to a breakdown in law and order. the police had to intervene to control the situation using force to disperse the crowd.\" this indicates that the protest turned violent, which aligns with the claim.\n",
            "Actual Justification: the article confirms that there was chaos in bandra after the arrest of activists, and a tv journalist was booked in relation to a note about trains for migrants issued by the railways. the claim is accurate based on the report.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb793e6a9edc16c6765a0\n",
            "Found 14 documents.\n",
            "['TRUE', 'The claim is supported by the given context, specifically the phrase \"Addressing Industry Issues\" and \"Film Industry Image Being Tarnished\", which suggests that Jaya Bachchan\\'s role in the Rajya Sabha could be an opportunity for her to advocate for reforms and address concerns related to the Indian film industry\\'s tarnished image.']\n",
            "Claim #4815\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "- **Addressing Industry Issues**: If the film industry is facing tarnishment, Jaya Bachchan’s role in the Rajya Sabha could be an opportunity for her to advocate for reforms, address concerns, and\n",
            "\n",
            "It seems like you're referring to a specific event or context involving Jaya Bachchan, a prominent figure in the Indian film industry, and her involvement in the Rajya Sabha, the upper house of the\n",
            "\n",
            "1. **Film Industry Image Being Tarnished**: This phrase could refer to various issues or controversies in the Indian film industry that have led to a negative perception or tarnishing of its image.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Film industry image being tarnished, jaya bachchan in rajya sabha'.\n",
            "Claim: Film industry image being tarnished, jaya bachchan in rajya sabha\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the given context, specifically the phrase \"addressing industry issues\" and \"film industry image being tarnished\", which suggests that jaya bachchan's role in the rajya sabha could be an opportunity for her to advocate for reforms and address concerns related to the indian film industry's tarnished image.\n",
            "Actual Justification: the claim is supported by a report from *the statesman*, which details jaya bachchan's statement in rajya sabha about the film industry’s image being tarnished.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb795e6a9edc16c6765a1\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The justification is that the provided context mentions Sonia and Rahul Gandhi praising Narasimha Rao, a former Prime Minister of India, and highlighting his contributions to shaping Telangana and India, which aligns with the claim.']\n",
            "Claim #4816\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you're referring to a specific event or context where Sonia and Rahul Gandhi, prominent figures in Indian politics, are praising Narasimha Rao, a former Prime Minister of India. However,\n",
            "\n",
            "Remember, the key is to engage people from all walks of life and showcase how Narasimha Rao's contributions continue to shape Telangana and India.\n",
            "\n",
            "* **Educational Programs:** Organize lectures, seminars, and workshops that delve into Narasimha Rao's life, his political career, and his impact on Telangana and Indian politics. Invite historians,\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Ignored for years, sonia and rahul gandhi now praise narasimha rao for bold leadership'.\n",
            "Claim: Ignored for years, sonia and rahul gandhi now praise narasimha rao for bold leadership\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the provided context mentions sonia and rahul gandhi praising narasimha rao, a former prime minister of india, and highlighting his contributions to shaping telangana and india, which aligns with the claim.\n",
            "Actual Justification: the claim is accurate as sonia gandhi and rahul gandhi acknowledged narasimha rao’s leadership during an online event commemorating his birth centenary. this marks a shift from the congress's previous stance of downplaying his contributions.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb798e6a9edc16c6765a2\n",
            "Found 7 documents.\n",
            "['TRUE', '', 'The justification is that the text states \"The Serum Institute of India, one of the world\\'s largest vaccine manufacturers, has announced its intention to resume COVID-19 vaccine trials following a nod from the Drug Controller General of India\", which clearly indicates that the claim is true.']\n",
            "Claim #4817\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The Serum Institute of India, one of the world's largest vaccine manufacturers, has announced its intention to resume COVID-19 vaccine trials following a nod from the Drug Controller General of India\n",
            "\n",
            "efficacy of the COVID-19 vaccine. The institute has been working on developing a vaccine in collaboration with the University of Oxford and AstraZeneca, and the recent DCGI nod is a crucial step\n",
            "\n",
            "The DCGI's approval is a significant milestone for the Serum Institute, as it provides the green light to proceed with the next phase of vaccine trials, which are essential to ensure the safety and\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Will resume covid-19 vaccine trials after dcgi nod, says serum institute'.\n",
            "Claim: Will resume covid-19 vaccine trials after dcgi nod, says serum institute\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the text states \"the serum institute of india, one of the world's largest vaccine manufacturers, has announced its intention to resume covid-19 vaccine trials following a nod from the drug controller general of india\", which clearly indicates that the claim is true.\n",
            "Actual Justification: the claim that the serum institute of india will resume covid-19 vaccine trials after receiving approval from the drugs controller general of india (dcgi) is true. according to india today, the serum institute of india announced that it would restart the clinical trials of the astrazeneca covid-19 vaccine candidate once it receives the necessary permissions from the dcgi. the trials had been paused due to an adverse reaction in a participant in the uk, but were cleared to resume by the medicines health regulatory authority (mhra) in the uk.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb79ae6a9edc16c6765a3\n",
            "Found 27 documents.\n",
            "['TRUE', 'The justification is that the AI language model does not have access to real-time information, but it is unable to provide supporting documents to confirm or deny the claim that the Andhra Pradesh Government has abolished the Waqf Board in the state.']\n",
            "Claim #4818\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The abolition of the Waqf Board in Andhra Pradesh is a significant development that could have various implications for the Muslim community and religious affairs in the state. Here are some points to\n",
            "\n",
            "Im sorry but I cannot provide supporting documents for the claim that the Andhra Pradesh Government has abolished the Waqf Board in the state. As an AI language model I do not have access to realtime\n",
            "\n",
            "I cannot provide supporting documents for the claim that the Andhra Pradesh Government has abolished the Waqf Board in the state. As an AI language model I do not have access to realtime information\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'The Andhra Pradesh Government has abolished the Waqf Board in the state.'.\n",
            "Claim: The Andhra Pradesh Government has abolished the Waqf Board in the state.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the ai language model does not have access to real-time information, but it is unable to provide supporting documents to confirm or deny the claim that the andhra pradesh government has abolished the waqf board in the state.\n",
            "Actual Justification: the article confirms that the claim about the andhra pradesh government abolishing the waqf board is false. the waqf board in the state has not been abolished, and there is no official government order supporting this claim.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb79ce6a9edc16c6765a4\n",
            "Found 4 documents.\n",
            "['I cannot verify the authenticity of the claim.']\n",
            "Claim #4819\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Victim:** A 20-year-old Hindu girl from West Midnapore.\n",
            "\n",
            "* **Allegations:** She was allegedly gang-raped and murdered by individuals described as \"Rohingyas and Bangladeshi jihadis.\"\n",
            "\n",
            "To support the claim that A Muslim girl from Haryana whose house was demolished by the authorities in Nuh following communal clashes you would need to gather evidence from reliable sources. Here are\n",
            "\n",
            "This is a serious and disturbing incident involving a young tribal girl in Odisha, India. Here's a summary of the situation:\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A muslim girl from vaishali, Bihar has been taken from her house, killed and her body was later dumped into a well. police have not taken any action & the accused person is not arrested.'.\n",
            "Claim: A muslim girl from vaishali, Bihar has been taken from her house, killed and her body was later dumped into a well. police have not taken any action & the accused person is not arrested.\n",
            "Predicted Label: unknown\n",
            "Actual Label: fake\n",
            "Predicted Justification: \n",
            "Actual Justification: the claim that a muslim girl from vaishali, bihar was taken from her house, killed, and her body dumped into a well, with no police action taken and the accused not arrested, is false. according to alt news, the viral photos being shared are unrelated to the recent incident. the photos are old and have been misused to spread misinformation. the actual incident involved a young girl being burnt, and the police have taken action in the case.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb79ee6a9edc16c6765a5\n",
            "Found 6 documents.\n",
            "['FAKE', '', 'The claim is likely fabricated because the text explicitly states \"I cannot provide supporting documents\" for the claim, and there is no evidence presented to support the claim, making it unreliable and likely false.']\n",
            "Claim #4820\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim A black man beating up a white woman. The attacker is still on the loose.\n",
            "\n",
            "I cannot provide supporting documents for the claim A black man beating up a white woman. The attacker is still on the loose.\n",
            "\n",
            "personnel and the attacker.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A black man beating up a white woman. The attacker is still on the loose.'.\n",
            "Claim: A black man beating up a white woman. The attacker is still on the loose.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is likely fabricated because the text explicitly states \"i cannot provide supporting documents\" for the claim, and there is no evidence presented to support the claim, making it unreliable and likely false.\n",
            "Actual Justification: the video does not show a black man attacking a white woman. it is actually a case of woman-on-woman violence, and the claim misrepresents the incident.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb79fe6a9edc16c6765a6\n",
            "Found 6 documents.\n",
            "['TRUE', '', 'The justification is that the claim does not provide any specific information about the incident, and the fact checker could not find any recent reports of a specific incident where a child protected his sister during a shooting in Kashmir.']\n",
            "Claim #4821\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I understand you're looking for supporting documents for a claim involving an injured mother-child duo from Kashmir. However, I cannot provide specific documents or personal information about\n",
            "\n",
            "* **News articles and reports** about recent incidents involving mother-child pairs in Kashmir.\n",
            "* **Humanitarian organization reports** detailing the impact of injuries on families in Kashmir.\n",
            "\n",
            "I could not find any recent reports of a specific incident where a child protected his sister during a shooting in Kashmir. The region has experienced periods of intense conflict and civil unrest, but\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Injured mother-child duo from Kashmir.'.\n",
            "Claim: Injured mother-child duo from Kashmir.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claim does not provide any specific information about the incident, and the fact checker could not find any recent reports of a specific incident where a child protected his sister during a shooting in kashmir.\n",
            "Actual Justification: the claim is false. the photograph in question is not from kashmir but is an old image from gaza. it was misattributed to an incident in kashmir. the image has been used inappropriately to spread misinformation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7a2e6a9edc16c6765a7\n",
            "Found 11 documents.\n",
            "['FAKE', '', 'The justification is that there is no mention of the claim in the given context, and the claim itself is absurd and lacks any supporting evidence. Additionally, the claim is about a specific incident involving a class 8 girl and coronavirus, which is not mentioned in the provided documents.']\n",
            "Claim #4822\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Brahmins in UP's Bundelkhand region cut off the tongue of a class 8 girl and offered it as a sacrifice to Lord Shiva to save their village from\n",
            "\n",
            "In the context of South India, particularly in the Brahmin community, which is one of the oldest and most respected castes in the region, the idea of an elderly Brahmin man being stripped and forced\n",
            "\n",
            "- The presence of a Shiva linga in Vietnam could be a result of the Champa kingdom's religious practices, trade, or cultural exchange with India during this period.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Brahmins in UP's Bundelkhand region cut off the tongue of a class 8 girl and offered it as sacrifice to Lord Shiva to save their village from coronavirus.'.\n",
            "Claim: Brahmins in UP's Bundelkhand region cut off the tongue of a class 8 girl and offered it as sacrifice to Lord Shiva to save their village from coronavirus.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that there is no mention of the claim in the given context, and the claim itself is absurd and lacks any supporting evidence. additionally, the claim is about a specific incident involving a class 8 girl and coronavirus, which is not mentioned in the provided documents.\n",
            "Actual Justification: the claim is false. no such incident took place in uttar pradesh's bundelkhand region. this is a baseless rumor. the girl's death was due to other reasons, and there is no evidence of any sacrificial act or connection to lord shiva or coronavirus.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7a6e6a9edc16c6765a8\n",
            "Found 23 documents.\n",
            "['TRUE', '', \"The claim is supported by the provided context, which suggests that economic reports and analyses can provide a broader context for increased coal production and regular power supply, and that news articles from reputable sources in India's energy sector can offer evidence of increased coal production.\"]\n",
            "Claim #4823\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can provide some supporting documents and information for the claim that India's coal production has increased and factories are receiving a regular power supply. Here are a few points to consider:\n",
            "\n",
            "- Economic reports and analyses can provide a broader context. Increased coal production and a regular power supply might be linked to economic growth and industrialization in India.\n",
            "\n",
            "- News articles from reputable sources in India's energy sector can offer evidence of increased coal production. Look for articles that discuss recent developments, government initiatives, or\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'India’s coal production increased recently. Factories are getting regular power supply.'.\n",
            "Claim: India’s coal production increased recently. Factories are getting regular power supply.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the provided context, which suggests that economic reports and analyses can provide a broader context for increased coal production and regular power supply, and that news articles from reputable sources in india's energy sector can offer evidence of increased coal production.\n",
            "Actual Justification: this claim is misleading. while coal production in india has been ramped up, there are still significant challenges with coal shortages affecting power plants, leading to power cuts in some regions.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7a8e6a9edc16c6765a9\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The justification is that the text does not deny the murder of Goldy Brar, but rather focuses on the claim that he was beaten by a mob in Canada, which is the specific claim being verified. The text does not provide evidence to support or refute this claim, but it does mention Punjab Chief Minister Bhagwant Mann taking a photo with Goldy Brar, which is a real event.']\n",
            "Claim #4824\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you're referring to a specific case or a fictional scenario involving the murder of gangster Goldy Brar and the singer Sidhu Moose Wala. However, I need a bit more context or\n",
            "\n",
            "I cannot provide supporting documents for the claim that Punjabi singer Sidhu Moose Wala’s alleged killer, gangster Goldy Brar, was beaten by a mob in Canada.\n",
            "\n",
            "Yes, that's correct. Punjab Chief Minister Bhagwant Mann took a photo with Goldy Brar, who claimed responsibility for the assassination of Sidhu Moose Wala. This incident sparked controversy and\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'The murder of gangster goldy brar, the prime suspect in punjabi singer siddhu moose wala's murder.'.\n",
            "Claim: The murder of gangster goldy brar, the prime suspect in punjabi singer siddhu moose wala's murder.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the text does not deny the murder of goldy brar, but rather focuses on the claim that he was beaten by a mob in canada, which is the specific claim being verified. the text does not provide evidence to support or refute this claim, but it does mention punjab chief minister bhagwant mann taking a photo with goldy brar, which is a real event.\n",
            "Actual Justification: the claim that the video shows the murder of gangster goldy brar, the prime suspect in punjabi singer siddhu moose wala's murder, is false. according to india today, the viral video shows an unrelated shootout in new orleans, us, from july 2023. us police have refuted rumours of goldy brar's murder.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7aae6a9edc16c6765aa\n",
            "Found 4 documents.\n",
            "['FAKE', 'The given context does not mention a specific bridge collapse in Russia\\'s Smolensk region on April 8, but rather mentions an \"Example Structural Analysis Report of the AkkalkuvaAnkleshwar Bridge Collapse\" which suggests that the bridge collapse is likely to be a different one, and not the one mentioned in the claim.']\n",
            "Claim #4825\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I'm sorry, but I cannot provide specific documents or information about the bridge collapse in Russia's Smolensk region on April 8. As an AI language model, I do not have access to real-time news or\n",
            "\n",
            "Example Structural Analysis Report of the AkkalkuvaAnkleshwar Bridge Collapse  Engineering Firm Date.\n",
            "\n",
            "Example Photographs of the AkkalkuvaAnkleshwar Bridge Collapse  Source e.g. local news outlet social media Date.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A bridge that collapsed on monday, april 8, in russia's smolensk region.'.\n",
            "Claim: A bridge that collapsed on monday, april 8, in russia's smolensk region.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not mention a specific bridge collapse in russia's smolensk region on april 8, but rather mentions an \"example structural analysis report of the akkalkuvaankleshwar bridge collapse\" which suggests that the bridge collapse is likely to be a different one, and not the one mentioned in the claim.\n",
            "Actual Justification: the video dates back to october 2018 and shows an accident in russia's zabailkalsk region, not the recent bridge collapse in the smolensk region. the recent incident on april 8 involved a road bridge in vyazma, smolensk region, but the viral video is unrelated.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7ace6a9edc16c6765ab\n",
            "Found 11 documents.\n",
            "['FAKE', \"There is no mention of Vivek Oberoi's residence being raided or his brother-in-law Aditya Alva being searched in the given context, which only talks about a search warrant and raid on a gang's headquarters, not Vivek Oberoi's residence.\"]\n",
            "Claim #4826\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "- **News Reports:** Several news outlets reported on the raid and the subsequent investigation. For example, the Indian Express published an article titled \"Vivek Oberoi's residence raided as cops\n",
            "\n",
            ". Search Warrant Based on the gathered evidence a search warrant was obtained for the gangs headquarters. During the raid officers discovered\n",
            "\n",
            ". Search Warrant A search warrant or similar document authorizing the CBI to conduct the raid on Amnesty Internationals office outlining the specific premises and items to be searched.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Vivek oberoi's residence raided as cops search brother-in-law aditya alva in drugs case.'.\n",
            "Claim: Vivek oberoi's residence raided as cops search brother-in-law aditya alva in drugs case.\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: there is no mention of vivek oberoi's residence being raided or his brother-in-law aditya alva being searched in the given context, which only talks about a search warrant and raid on a gang's headquarters, not vivek oberoi's residence.\n",
            "Actual Justification: the article from *the tribune* mentions that vivek oberoi's residence was raided by the police as part of their search for his brother-in-law, aditya alva, in connection with a drugs case.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7b0e6a9edc16c6765ac\n",
            "Found 6 documents.\n",
            "['TRUE', '', 'The justification is that the provided documents do not mention any specific claim about the number of Pakistani soldiers killed by Indian forces on the Line of Control, whereas the claim being verified is about Pakistan claiming 3 of its soldiers were killed.']\n",
            "Claim #4827\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can provide you with information about the situation in the region, but I cannot confirm the specific claim about the number of Pakistani soldiers killed by Indian forces on the Line of Control\n",
            "\n",
            "- An army jawan (Indian soldier) was killed in a ceasefire violation by Pakistani forces along the LoC.\n",
            "- This incident marks the fourth death of Indian soldiers in ceasefire violations this month.\n",
            "\n",
            "incident occurred when Pakistani troops fired across the Line of Control (LoC) into Indian territory.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Pakistan claims 3 of its soldiers killed by Indian forces on LOC.'.\n",
            "Claim: Pakistan claims 3 of its soldiers killed by Indian forces on LOC.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the provided documents do not mention any specific claim about the number of pakistani soldiers killed by indian forces on the line of control, whereas the claim being verified is about pakistan claiming 3 of its soldiers were killed.\n",
            "Actual Justification: according to *hindustan times*, pakistan has claimed that three of its soldiers were killed by indian forces along the line of control (loc).\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7b2e6a9edc16c6765ad\n",
            "Found 12 documents.\n",
            "['FAKE', 'The claim is labeled as \"I cannot provide supporting documents\" which suggests that the claim is false and there is no evidence to support it.']\n",
            "Claim #4828\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that a Muslim mob attacked a Hindu boy with swords in Nalasopara near Mumbai.\n",
            "\n",
            "I cannot provide supporting documents for the claim that a Muslim mob attacked a Hindu boy with swords in Nalasopara near Mumbai.\n",
            "\n",
            "During this period, there were reports of Muslim mobs attacking Hindu temples and properties, leading to widespread violence and displacement of Hindu families. The violence was triggered by a\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Muslim mob attacking a Hindu boy with swords in Nalasopara near Mumbai.'.\n",
            "Claim: Muslim mob attacking a Hindu boy with swords in Nalasopara near Mumbai.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is labeled as \"i cannot provide supporting documents\" which suggests that the claim is false and there is no evidence to support it.\n",
            "Actual Justification: the claim that the video shows a muslim mob attacking a hindu boy with swords in nalasopara is false. the video in question is not related to any communal attack. it was actually part of a different incident and was misinterpreted and falsely linked to a communal narrative.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7b4e6a9edc16c6765ae\n",
            "Found 12 documents.\n",
            "['FAKE', '', 'The provided documents are unable to provide supporting documents for the claim, indicating that the claim is likely false or fabricated, hence it is classified as FAKE.']\n",
            "Claim #4829\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Palestinians insulting the Indian flag.\n",
            "\n",
            "I cannot provide supporting documents for the claim that Palestinians insulting the Indian flag.\n",
            "\n",
            "I cannot provide supporting documents for the claim that Palestinians insulting the Indian flag.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Palestinians insulting the Indian flag.'.\n",
            "Claim: Palestinians insulting the Indian flag.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the provided documents are unable to provide supporting documents for the claim, indicating that the claim is likely false or fabricated, hence it is classified as fake.\n",
            "Actual Justification: the claim is false. the visuals circulating online were not of palestinians insulting the indian flag, but of protests in pakistan. these visuals were misattributed, and fact-checking revealed the actual source to be protests in pakistan, not palestine.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7b6e6a9edc16c6765af\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The scenario described does not match the provided documents, but the document mentions a severe weather event (blizzard) in Buffalo, New York, which matches the claim.']\n",
            "Claim #4830\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The scenario you described involves a Walmart store being looted during a severe weather event, specifically a blizzard, in Buffalo, New York. This event would likely be newsworthy due to the\n",
            "\n",
            "goodwill.\n",
            "\n",
            "It seems like you've provided a description of a scene involving a crowd looting a clothing store in Manipur, India, during a period of violence in the state. However, I don't see a specific question\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A Walmart store that was looted during the deadly blizzard that hit New York’s Buffalo on Christmas day.'.\n",
            "Claim: A Walmart store that was looted during the deadly blizzard that hit New York’s Buffalo on Christmas day.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the scenario described does not match the provided documents, but the document mentions a severe weather event (blizzard) in buffalo, new york, which matches the claim.\n",
            "Actual Justification: the video shared on social media, showing a looted walmart, is not from the recent buffalo blizzard. the footage is from a different incident and is unrelated to the blizzard that hit buffalo on christmas day.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7bbe6a9edc16c6765b0\n",
            "Found 9 documents.\n",
            "['FAKE', 'The claim is fake because there is no widely accepted historical evidence that places BR Ambedkar and his wife on a city bus in Columbia, United States, during the independence and post-independence period, and the fact-checker is unable to provide supporting documents to support this claim.']\n",
            "Claim #4831\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that BR Ambedkar and his wife were seen on a city bus running in Columbia, United States. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "independence and post-independence period. While he traveled internationally, there is no widely accepted historical evidence that places him and his wife on a city bus in Columbia, United States.\n",
            "\n",
            "If you have any other historical claims or need information about B.R. Ambedkar's life and work, I'd be happy to help!\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'BR Ambedkar and his wife seen on a city bus running in Columbia, United States.'.\n",
            "Claim: BR Ambedkar and his wife seen on a city bus running in Columbia, United States.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is fake because there is no widely accepted historical evidence that places br ambedkar and his wife on a city bus in columbia, united states, during the independence and post-independence period, and the fact-checker is unable to provide supporting documents to support this claim.\n",
            "Actual Justification: the claim is false. the image of br ambedkar and his wife seen on a bus in columbia, united states is morphed. the image was digitally manipulated and was not taken from an actual bus in the united states. no such bus featuring this image of ambedkar and his wife exists in columbia, usa.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7bde6a9edc16c6765b1\n",
            "Found 15 documents.\n",
            "['FAKE', '', 'The justification is that the fact-checker explicitly states they \"cannot provide supporting documents for the claim of a recent public flogging of a woman in Afghanistan\", indicating that the claim is unsubstantiated and likely false.']\n",
            "Claim #4832\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It sounds like you might be referring to a specific incident or event, but the phrase \"a recent public flogging of a woman in Afghanistan\" is quite specific and may not be a widely reported or\n",
            "\n",
            "I cannot provide you with supporting documents for the claim of a recent public flogging of a woman in Afghanistan.\n",
            "\n",
            "I cannot provide supporting documents for the claim of a recent public flogging of a woman in Afghanistan.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A recent public flogging of a woman in Afghanistan.'.\n",
            "Claim: A recent public flogging of a woman in Afghanistan.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the fact-checker explicitly states they \"cannot provide supporting documents for the claim of a recent public flogging of a woman in afghanistan\", indicating that the claim is unsubstantiated and likely false.\n",
            "Actual Justification: the video is not a recent incident. it shows an event from 2021, not a recent public flogging. the claim circulating online is misleading and distorts the video’s origin.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7c3e6a9edc16c6765b2\n",
            "Found 17 documents.\n",
            "['TRUE', 'The statement \"No country in the world says everybody is welcome: S. Jaishankar hits back at critics of CAA\" is true because it is a quote from S. Jaishankar, the Indian Minister of State for External Affairs, as mentioned in the \"Statement by S. Jaishankar\" document, which contradicts the idea of open immigration policies and emphasizes the complexity of immigration policies in various countries.']\n",
            "Claim #4833\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Statement by S. Jaishankar:** S. Jaishankar, the Indian Minister of State for External Affairs, has been a vocal defender of the CAA. In various interviews and statements, he has emphasized that\n",
            "\n",
            "* **Global Context:** While many countries have open immigration policies and welcome refugees, no nation officially states that \"everybody is welcome.\" Immigration policies are often complex and\n",
            "\n",
            "The statement \"Nationalism will be a dominating feature in a post-COVID world, says Jaishankar\" suggests that the Indian Foreign Minister, S. Jaishankar, has expressed an opinion about the potential\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'No country in world says everybody is welcome: s. jaishankar hits back at critics of CAA.'.\n",
            "Claim: No country in world says everybody is welcome: s. jaishankar hits back at critics of CAA.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the statement \"no country in the world says everybody is welcome: s. jaishankar hits back at critics of caa\" is true because it is a quote from s. jaishankar, the indian minister of state for external affairs, as mentioned in the \"statement by s. jaishankar\" document, which contradicts the idea of open immigration policies and emphasizes the complexity of immigration policies in various countries.\n",
            "Actual Justification: the claim is verified by the article, which reports that external affairs minister s. jaishankar stated that no country in the world claims to welcome everybody, while defending india's citizenship amendment act (caa) and responding to international critics.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7c6e6a9edc16c6765b3\n",
            "Found 12 documents.\n",
            "['TRUE', '', 'The justification is that the statement is based on the given context, which mentions that the Maharashtra government has provided a guarantee for 32 mills, and the mill owners are expressing concerns about the timing of this guarantee, suggesting that it may have come too late for some mills.']\n",
            "Claim #4834\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement \"Finally, 32 mills get Maharashtra govt guarantee, but owners say measure may have come too late\" suggests that the Maharashtra government has provided a guarantee for 32 mills, but the\n",
            "\n",
            "- **Maharashtra Government Guarantee**: The government's decision to provide a guarantee for 32 mills is a significant step, especially if these mills are part of the state's textile or other\n",
            "\n",
            "- **Mill Owners' Perspective**: Mill owners might have concerns about the timing of this guarantee. They could argue that the measure is too late if the mills have already faced significant financial\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Finally, 32 mills get maharashtra govt guarantee, but owners say measure may have come too late'.\n",
            "Claim: Finally, 32 mills get maharashtra govt guarantee, but owners say measure may have come too late\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the statement is based on the given context, which mentions that the maharashtra government has provided a guarantee for 32 mills, and the mill owners are expressing concerns about the timing of this guarantee, suggesting that it may have come too late for some mills.\n",
            "Actual Justification: the claim that 32 mills received a maharashtra government guarantee, but owners say the measure may have come too late, is true. according to the indian express, after multiple deliberations since march, the maharashtra government finally chose 32 sugar mills to receive government guarantees to raise short-duration funds for the 2020-21 sugarcane crushing season. however, mill owners expressed concerns that the decision might have come too late to be effective.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7cae6a9edc16c6765b4\n",
            "Found 18 documents.\n",
            "['TRUE', '', 'The claim is supported by the Facebook post, which mentions \"3-phase voting in Bihar\\'s COVID election\" and \"taking COVID-19 precautions\", indicating that the election was conducted in phases and COVID-19 precautions were taken.']\n",
            "Claim #4835\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "**3-Phase Voting in Bihar's COVID Election:**\n",
            "\n",
            "The reference to \"Online nominations and masks: 3-phase voting in bihar’s covid election\" likely pertains to the 2020 legislative assembly elections in the Indian state of Bihar, which were conducted\n",
            "\n",
            "* **Facebook Post:** \"Bihar, it's time to make your voice heard! Leaders from across the spectrum are urging you to vote while taking COVID-19 precautions. Your participation is crucial for a fair\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Online nominations and masks, 3-phase voting in bihar's covid election'.\n",
            "Claim: Online nominations and masks, 3-phase voting in bihar's covid election\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the facebook post, which mentions \"3-phase voting in bihar's covid election\" and \"taking covid-19 precautions\", indicating that the election was conducted in phases and covid-19 precautions were taken.\n",
            "Actual Justification: the claim is accurate as the election commission of india announced online nominations, mask mandates, and a 3-phase voting process for bihar's 2020 assembly elections due to covid-19 precautions.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7cce6a9edc16c6765b5\n",
            "Found 6 documents.\n",
            "['TRUE', '', 'The claim \"ansari\\'s aide gunned down in encounter\" is supported by the information provided, which states \"Three terrorists were killed in the encounter, and a significant amount of arms and ammunition was recovered.\" This suggests that there was an encounter in which Ansari\\'s aide was killed, as described in the claim.']\n",
            "Claim #4836\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The murder of Tabrez Ansari is a tragic event, and it is understandable that it may have caused tensions and strong emotions among various religious groups. However, responding to such incidents with\n",
            "\n",
            "individuals involved in the Tabrez Ansari case. These sources can provide a more comprehensive understanding of the events and the reactions they elicited.\n",
            "\n",
            "* \"Three terrorists were killed in the encounter, and a significant amount of arms and ammunition was recovered. The district administration extends its gratitude to the security forces for their\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'ansari's aide gunned down in encounter.'.\n",
            "Claim: ansari's aide gunned down in encounter.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim \"ansari's aide gunned down in encounter\" is supported by the information provided, which states \"three terrorists were killed in the encounter, and a significant amount of arms and ammunition was recovered.\" this suggests that there was an encounter in which ansari's aide was killed, as described in the claim.\n",
            "Actual Justification: mukhtar ansari's aide was gunned down in an encounter with the police, as reported by *the indian express*.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7cfe6a9edc16c6765b6\n",
            "Found 28 documents.\n",
            "['I cannot verify the claim as TRUE or FALSE based on the provided documents.']\n",
            "Claim #4837\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            ". Complaint Letter A formal letter from the female staff member detailing the alleged incidents of sexual harassment including dates times and specific behaviors. This letter should also mention the\n",
            "\n",
            ". Medical Records If the staff member has sought medical attention or counseling due to the alleged harassment medical records or counseling reports can be included to show the emotional and physical\n",
            "\n",
            "* **Medical Examination:** A report from a medical professional who examined the victim. This report would document any physical injuries consistent with sexual assault and may include evidence of\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'NCW seeks inquiry against doctor for sexually harassing female staff member in faridabad.'.\n",
            "Claim: NCW seeks inquiry against doctor for sexually harassing female staff member in faridabad.\n",
            "Predicted Label: unknown\n",
            "Actual Label: true\n",
            "Predicted Justification: \n",
            "Actual Justification: the claim is supported by the article, which reports that the national commission for women (ncw) has sought an inquiry against a doctor for sexually harassing a female staff member in faridabad.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7d1e6a9edc16c6765b7\n",
            "Found 9 documents.\n",
            "['TRUE', 'The claim is supported by the context, which states that the CBI has questioned four accused individuals in the Hathras case, indicating that the questioning has taken place.']\n",
            "Claim #4838\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The Central Bureau of Investigation (CBI) has questioned four accused individuals in the Hathras case, which involves the alleged gang rape and murder of a 20-year-old Dalit woman in Hathras, Uttar\n",
            "\n",
            "The four accused, who are all from the same village as the victim, were arrested by the CBI on charges of murder, gang rape, and destruction of evidence. The investigation has been transferred to the\n",
            "\n",
            "By taking over the investigation, the CBI aims to provide a more comprehensive and unbiased approach to the case. This is especially important in high-profile incidents such as the Hathras gangrape\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'CBI questions 4 accused arrested in hathras case'.\n",
            "Claim: CBI questions 4 accused arrested in hathras case\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the context, which states that the cbi has questioned four accused individuals in the hathras case, indicating that the questioning has taken place.\n",
            "Actual Justification: the claim is supported by a report from *times of india*, which confirms that the cbi questioned the four accused arrested in the hathras case.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7d4e6a9edc16c6765b8\n",
            "Found 13 documents.\n",
            "['TRUE', '', 'The claim is supported by the context, which mentions the need for historical AQI data for Delhi, Ghaziabad, and Noida, and citing reliable sources such as the Central Pollution Control Board (CPCB) of India or the System of Air Quality and Weather Forecasting and Research (SAFAR). This suggests that the claim is based on actual data and not an unfounded statement.']\n",
            "Claim #4839\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Provide historical AQI data for Delhi, Ghaziabad, and Noida for the specific period in question (e.g., a month or a season when air quality is typically poor).**\n",
            "\n",
            "Several factors contribute to the poor air quality in the Delhi-NCR region:\n",
            "\n",
            "* **Cite reliable sources for the AQI data, such as the Central Pollution Control Board (CPCB) of India or the System of Air Quality and Weather Forecasting and Research (SAFAR).**\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'aqi very poor in delhi despite rise in wind speed, worst in ghaziabad and noida.'.\n",
            "Claim: aqi very poor in delhi despite rise in wind speed, worst in ghaziabad and noida.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the context, which mentions the need for historical aqi data for delhi, ghaziabad, and noida, and citing reliable sources such as the central pollution control board (cpcb) of india or the system of air quality and weather forecasting and research (safar). this suggests that the claim is based on actual data and not an unfounded statement.\n",
            "Actual Justification: the article reports that despite an increase in wind speed, air quality in delhi remained 'very poor,' with ghaziabad and noida recording the worst aqi levels among neighboring cities.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7d6e6a9edc16c6765b9\n",
            "Found 9 documents.\n",
            "['TRUE', 'The justification is that the provided context does not contain any information about \"Producer kshitij ravi\" being brought to an NCB office for questioning, and the NCB Zonal Director Sameer Wankhede is mentioned, but there is no specific mention of this individual being questioned.']\n",
            "Claim #4840\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I'm sorry, I don't have any information about a specific case or individual named \"Producer kshitij ravi\" being brought to an office for questioning. If you have more details or context about this\n",
            "\n",
            "The information you provided is a short, incomplete sentence. It seems to be a news snippet about a Bollywood drugs probe, mentioning that two officials from the National Crime Bureau (NCB) have been\n",
            "\n",
            "1. **NCB Zonal Director Sameer Wankhede**: He is a senior official in the Narcotics Control Bureau (NCB), a law enforcement agency in India.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Producer kshitij ravi brought to ncb office for questioning'.\n",
            "Claim: Producer kshitij ravi brought to ncb office for questioning\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the provided context does not contain any information about \"producer kshitij ravi\" being brought to an ncb office for questioning, and the ncb zonal director sameer wankhede is mentioned, but there is no specific mention of this individual being questioned.\n",
            "Actual Justification: producer kshitij ravi prasad was brought to the narcotics control bureau (ncb) office for questioning in connection with the drug probe linked to the bollywood industry. the questioning followed raids conducted at his residence as part of the investigation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7d8e6a9edc16c6765ba\n",
            "Found 7 documents.\n",
            "['FAKE', '', 'The justification is that the provided information does not mention anything about Muslim men disguising themselves as Sikh farmers to join the protests, and the claim is explicitly denied by the author.']\n",
            "Claim #4841\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Muslim men are disguising themselves as Sikh farmers to join the 'Delhi Chalo' protests.\n",
            "\n",
            "The information you provided suggests that Sikh farmers who were protesting were using language that could be interpreted as supportive of the Khalistan movement and Pakistan. The Khalistan movement\n",
            "\n",
            "During the \"Delhi Chalo\" protests, there were reports of farmers and protesters carrying out various activities, including holding meetings, rallies, and sit-ins. Some of these events may have\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Muslim men disguising themselves as sikh farmers to join the ongoing 'delhi chalo' protests.'.\n",
            "Claim: Muslim men disguising themselves as sikh farmers to join the ongoing 'delhi chalo' protests.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided information does not mention anything about muslim men disguising themselves as sikh farmers to join the protests, and the claim is explicitly denied by the author.\n",
            "Actual Justification: the video is from punjabi singer sidhu moosewala’s final prayer ceremony and is unrelated to the farmers' protests. it shows a muslim man taking off his skull cap and donning a sikh turban during the ceremony.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7dbe6a9edc16c6765bb\n",
            "Found 15 documents.\n",
            "['TRUE', '', \"The claim does not provide specific details about the incident, but it is based on a real event, as evidenced by the existence of news articles and reports about a worker being beaten to death in West Bengal. The BJP's blame on the TMC is also mentioned, which suggests that the claim is referencing a real event and not entirely fabricated.\"]\n",
            "Claim #4842\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "**Claim:** A worker was beaten to death in West Bengal, and the BJP (Bharatiya Janata Party) has blamed the TMC (Trinamool Congress).\n",
            "\n",
            "1. **Political Context**: West Bengal has a history of political violence, often fueled by religious and ethnic tensions. The murder of a BJP worker could be a result of these tensions, especially if\n",
            "\n",
            "1. **Historical Context**: The TMC, led by Mamata Banerjee, has been a dominant force in West Bengal's politics since 2011. They won a landslide victory in the 2016 assembly elections, securing 211\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'West bengal: worker beaten to death, bjp blames tmc'.\n",
            "Claim: West bengal: worker beaten to death, bjp blames tmc\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim does not provide specific details about the incident, but it is based on a real event, as evidenced by the existence of news articles and reports about a worker being beaten to death in west bengal. the bjp's blame on the tmc is also mentioned, which suggests that the claim is referencing a real event and not entirely fabricated.\n",
            "Actual Justification: the claim that a worker was beaten to death in west bengal and the bjp blamed the tmc is true. according to the indian express, a bjp worker named saikat bhawal was beaten to death during the party’s griha sampark abhiyan in halishahar of north 24-parganas district. the bjp accused the trinamool congress (tmc) of murder, while the tmc claimed the death was a result of a fight between two groups of bjp workers.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7dde6a9edc16c6765bc\n",
            "Found 3 documents.\n",
            "['TRUE', \"The claim is supported by the provided context, which mentions that PM Modi's official social media handles and those of his political party BJP often share updates about his activities, including videos or photos of him. This suggests that it is possible for PM Modi to be discussed on social media, and the context does not provide any evidence to refute the claim.\"]\n",
            "Claim #4843\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems there might be a bit of a misunderstanding or a specific context that I'm missing regarding Prime Minister Narendra Modi and a stack of 'Burnol' being discussed on social media. 'Burnol' is a\n",
            "\n",
            ". Social Media Posts PM Modi and his official social media handles as well as those of his political party BJP often share updates about his activities. Posts featuring videos or photos of him\n",
            "\n",
            "Narendra Modi is the current Prime Minister of India. He is known for his active social media presence and often posts greetings and messages on his official Twitter account.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Prime Minister Narendra Modi is being widely discussed on social media for holding a stack of 'Burnol''.\n",
            "Claim: Prime Minister Narendra Modi is being widely discussed on social media for holding a stack of 'Burnol'\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the provided context, which mentions that pm modi's official social media handles and those of his political party bjp often share updates about his activities, including videos or photos of him. this suggests that it is possible for pm modi to be discussed on social media, and the context does not provide any evidence to refute the claim.\n",
            "Actual Justification: the claim is misleading. the picture of prime minister narendra modi holding a stack of ‘burnol’ is photoshopped. the original image does not show him holding burnol. this has been confirmed by fact-checkers.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7dee6a9edc16c6765bd\n",
            "Found 9 documents.\n",
            "['FAKE', '', 'The justification is that the provided context states that the event is not a widely recognized or documented occurrence, and the fact-checker is unable to provide supporting documents, implying that the claim is likely fictional or exaggerated.']\n",
            "Claim #4844\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that King of Bahrain arriving in Dubai with his robot bodyguard because this event is not a widely recognized or documented occurrence. It appears\n",
            "\n",
            "It seems like you're describing a fictional scenario involving the King of Bahrain and a robot bodyguard arriving in Dubai. If you have any specific questions or need information about the King of\n",
            "\n",
            "Im sorry but I cannot provide supporting documents for the claim that the King of Bahrain arrived in Dubai with a robot bodyguard. This claim appears to be a fictional or exaggerated statement and\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'King of Bahrain arriving in Dubai with his robot bodyguard.'.\n",
            "Claim: King of Bahrain arriving in Dubai with his robot bodyguard.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided context states that the event is not a widely recognized or documented occurrence, and the fact-checker is unable to provide supporting documents, implying that the claim is likely fictional or exaggerated.\n",
            "Actual Justification: the video does not show the king of bahrain arriving in dubai with a robot bodyguard. the video depicts an automaton (robot-like figure) performing a greeting, not an actual bodyguard of the king.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7e1e6a9edc16c6765be\n",
            "Found 23 documents.\n",
            "['TRUE', '', 'The given context mentions \"Title Young Indian Activist Named to UN\\'s New Advisory Group on Climate Change\" which suggests that the claim is accurate.']\n",
            "Claim #4845\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Title Young Indian Activist Named to UNs New Advisory Group on Climate Change\n",
            "\n",
            "Supporting Points\n",
            "\n",
            "Supporting Documents for the Claim Young Indian Activist Named to UN Advisory Group on Climate Change\n",
            "\n",
            "Biographical Information A brief biography or profile of the young Indian activist highlighting their relevant experience achievements and commitment to environmental activism.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Young indian activist named by un chief to new advisory group on climate change'.\n",
            "Claim: Young indian activist named by un chief to new advisory group on climate change\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given context mentions \"title young indian activist named to un's new advisory group on climate change\" which suggests that the claim is accurate.\n",
            "Actual Justification: the claim is true, as reported by the economic times. a young indian activist has been named by the un chief to the new advisory group on climate change.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7e3e6a9edc16c6765bf\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The claim is not explicitly supported by the provided documents, but it is inferred that Rishi Sunak may have sought blessings from a Hindu monk as a gesture of respect and connection to Hindu voters, as he was seen wearing rudraksha in Kashi (Varanasi), a holy city for Hindus.']\n",
            "Claim #4846\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Rishi Sunak sought blessings from a Hindu monk before taking the oath as the UK's Prime Minister. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "Kashi also known as Varanasi is a holy city for Hindus. Wearing rudraksha in Kashi could be seen as a gesture of respect and connection to Hindu voters.\n",
            "\n",
            "- The Prime Minister of India, [Name], expressed deep concern and offered prayers for the quick recovery and safety of those affected.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Rishi Sunak seeking blessings from a Hindu monk before he took oath as UK’s Prime Minister.'.\n",
            "Claim: Rishi Sunak seeking blessings from a Hindu monk before he took oath as UK’s Prime Minister.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is not explicitly supported by the provided documents, but it is inferred that rishi sunak may have sought blessings from a hindu monk as a gesture of respect and connection to hindu voters, as he was seen wearing rudraksha in kashi (varanasi), a holy city for hindus.\n",
            "Actual Justification: the video being shared is from august 2022, not after rishi sunak took oath as the uk prime minister. it shows him seeking blessings before his political rise, not during his appointment as pm.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7e5e6a9edc16c6765c0\n",
            "Found 4 documents.\n",
            "['TRUE', 'The justification is provided in the given context, which states that \"the use of a hair dryer and clothes iron to dry the pitch is an innovative approach to ensure the playing surface is in optimal condition for the match.\" This suggests that the method was actually used during the 2023 IPL final, as mentioned in the additional document provided.']\n",
            "Claim #4847\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It's interesting to see how technology is being utilized to manage sports fields, especially in high-stakes events like the IPL final. The use of a hair dryer and clothes iron to dry the pitch is an\n",
            "\n",
            "innovative approach to ensure the playing surface is in optimal condition for the match. This method can help speed up the drying process and potentially prevent any issues that could arise from a\n",
            "\n",
            "wet pitch, such as reduced traction for players or an uneven playing field.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Ahmedabad's Narendra Modi Stadium: a hair dryer and clothes iron were used to dry the wet pitch during the 2023 IPL final.'.\n",
            "Claim: Ahmedabad's Narendra Modi Stadium: a hair dryer and clothes iron were used to dry the wet pitch during the 2023 IPL final.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is provided in the given context, which states that \"the use of a hair dryer and clothes iron to dry the pitch is an innovative approach to ensure the playing surface is in optimal condition for the match.\" this suggests that the method was actually used during the 2023 ipl final, as mentioned in the additional document provided.\n",
            "Actual Justification: the claim is misleading. the images showing the use of a hair dryer and clothes iron on the pitch are from a different event and not the 2023 ipl final. the pitch in question was not dried using these items during the ipl match.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7e8e6a9edc16c6765c1\n",
            "Found 4 documents.\n",
            "['TRUE', '', 'The justification is that the context mentions \"The Bombay High Court has denied interim bail to Arnab a prominent individual facing legal proceedings\", which matches with the claim \"Arnab Goswami\\'s bail plea rejected\".']\n",
            "Claim #4848\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "\"Arnab Goswami's plea,\" are not provided in your message. Could you please provide more context or clarify what you're referring to? This will help me give you a more accurate and helpful response.\n",
            "\n",
            "* **Event:** A US court has rejected a bail plea for an individual named Rana, who is being sought by India in connection with the 2008 Mumbai attacks (26/11).\n",
            "\n",
            "The Bombay High Court has denied interim bail to Arnab a prominent individual facing legal proceedings. The courts decision was based on the assessment that Arnabs application lacked sufficient\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Arnab goswami's bail plea rejected, will face daily questioning.'.\n",
            "Claim: Arnab goswami's bail plea rejected, will face daily questioning.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the context mentions \"the bombay high court has denied interim bail to arnab a prominent individual facing legal proceedings\", which matches with the claim \"arnab goswami's bail plea rejected\".\n",
            "Actual Justification: the article from indian express confirms that arnab goswami's bail plea was rejected, and he will undergo daily questioning in relation to his case.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7ede6a9edc16c6765c2\n",
            "Found 22 documents.\n",
            "['TRUE', '', 'The justification is that the text explicitly states that the debate surrounding abortion is complex and multifaceted, and that it extends far beyond the simplistic \"pro-choice\" versus \"pro-life\" dichotomy, supporting the claim that abortion needs to go beyond the pro-choice/pro-life debate.']\n",
            "Claim #4849\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The debate surrounding abortion is complex and multifaceted, and it's important to recognize that it extends far beyond the simplistic \"pro-choice\" versus \"pro-life\" dichotomy. Here are some points to\n",
            "\n",
            "Engaging in a nuanced discussion that goes beyond the pro-choice/pro-life debate can lead to a more comprehensive understanding of abortion, allowing for informed decision-making, policy development,\n",
            "\n",
            "- **Legal and Ethical Considerations:** The abortion debate involves a range of legal and ethical questions. These include the right to privacy, the protection of vulnerable populations, the role of\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Abortion need to go beyond prochoice, prolife debate'.\n",
            "Claim: Abortion need to go beyond prochoice, prolife debate\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the text explicitly states that the debate surrounding abortion is complex and multifaceted, and that it extends far beyond the simplistic \"pro-choice\" versus \"pro-life\" dichotomy, supporting the claim that abortion needs to go beyond the pro-choice/pro-life debate.\n",
            "Actual Justification: the claim is supported by the article from the tribune, which discusses the evolving discourse on abortion rights, emphasizing that the debate needs to transcend the traditional pro-choice and pro-life dichotomy to include broader considerations such as women's health, societal norms, and legal frameworks.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7f1e6a9edc16c6765c3\n",
            "Found 14 documents.\n",
            "['TRUE', '', 'The claim is supported by the provided documents, which mention a former army jawan from Uttar Pradesh and his family members being allegedly brutally thrashed in Ayodhya due to a property dispute.']\n",
            "Claim #4850\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The incident you described involves a former army jawan from Uttar Pradesh who, along with his family members, was allegedly brutally thrashed in Ayodhya due to a property dispute. This is a serious\n",
            "\n",
            "I cannot provide supporting documents for the claim that the Indian Army thrashed a Kashmiri boy.\n",
            "\n",
            "I cannot provide supporting documents for the claim that the Indian Army thrashed a Kashmiri boy.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Uttar Pradesh ex-army jawan, his family members brutally thrashed over property dispute in Ayodhya.'.\n",
            "Claim: Uttar Pradesh ex-army jawan, his family members brutally thrashed over property dispute in Ayodhya.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the provided documents, which mention a former army jawan from uttar pradesh and his family members being allegedly brutally thrashed in ayodhya due to a property dispute.\n",
            "Actual Justification: the article reports that an ex-army jawan and his family members were brutally attacked in ayodhya due to a property dispute.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7f3e6a9edc16c6765c4\n",
            "Found 14 documents.\n",
            "['TRUE', 'The claim is true because the provided information does not contain any evidence or details about a large explosion taking place in Ukraine after Russian President Vladimir Putin announced a military operation. The only information provided is the date of the announcement, but no information about an explosion is given.']\n",
            "Claim #4851\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that a large explosion took place in Ukraine after Russian President Vladimir Putin announced a military operation in Ukraine. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that a large explosion took place in Ukraine after Russian President Vladimir Putin announced a military operation in Ukraine. \n",
            "\n",
            "Heres why\n",
            "\n",
            "Date of the Announcement Russian President Vladimir Putin announced a military operation in Ukraine on February  .\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A large explosion that took place in Ukraine after Russian President Vladimir Putin announced a military operation in Ukraine.'.\n",
            "Claim: A large explosion that took place in Ukraine after Russian President Vladimir Putin announced a military operation in Ukraine.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is true because the provided information does not contain any evidence or details about a large explosion taking place in ukraine after russian president vladimir putin announced a military operation. the only information provided is the date of the announcement, but no information about an explosion is given.\n",
            "Actual Justification: the video circulating does not show an explosion from the ongoing conflict in ukraine. it actually shows an old chemical blast in china, not a bombing in ukraine following putin's announcement.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7f5e6a9edc16c6765c5\n",
            "Found 2 documents.\n",
            "['TRUE', '', 'The claim is supported by the document, which mentions \"reports of Hindu women facing harassment, violence, and intimidation by Muslim mobs in various parts of Bangladesh\" and specifically mentions a 20-year-old Hindu girl from West Midnapore who was allegedly gang-raped and murdered by individuals described as \"Rohingyas and Bangladeshi jihadis\".']\n",
            "Claim #4852\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Recent Incidents:** There have been reports of Hindu women facing harassment, violence, and intimidation by Muslim mobs in various parts of Bangladesh. These incidents often stem from religious\n",
            "\n",
            "* **Victim:** A 20-year-old Hindu girl from West Midnapore.\n",
            "\n",
            "* **Allegations:** She was allegedly gang-raped and murdered by individuals described as \"Rohingyas and Bangladeshi jihadis.\"\n",
            "\n",
            "- On October 20, 2020, a 19-year-old woman from the Hathras district of Uttar Pradesh was allegedly gang-raped by six men, including a village head and a local leader of a political party.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A hindu woman being gang-raped by an islamic mob in bangladesh.'.\n",
            "Claim: A hindu woman being gang-raped by an islamic mob in bangladesh.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the document, which mentions \"reports of hindu women facing harassment, violence, and intimidation by muslim mobs in various parts of bangladesh\" and specifically mentions a 20-year-old hindu girl from west midnapore who was allegedly gang-raped and murdered by individuals described as \"rohingyas and bangladeshi jihadis\".\n",
            "Actual Justification: the video actually shows a conflict between students during a protest at jahangirnagar university in bangladesh. it has been misrepresented as a gang-rape incident. the footage depicts students seeking shelter after being attacked by armed individuals during the protest, and the sexual assault claims are unfounded.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7f8e6a9edc16c6765c6\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The justification is that the statement uses the phrase \"good signs of high biodiversity\" which indicates that the survey found positive indicators of a wide variety of species and ecosystems within the river, and the percentage \"49% of the Ganga-Brahmaputra river\" suggests that the high biodiversity was observed in a substantial portion of the river system, covering almost half of its length or area.']\n",
            "Claim #4853\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement \"Survey sights good signs of high biodiversity in 49% of the Ganga-Brahmaputra river\" suggests that a study or survey has found evidence of rich biodiversity in a significant portion of\n",
            "\n",
            "- **49% of the Ganga-Brahmaputra River:** This percentage suggests that the high biodiversity was observed in a substantial portion of the river system, covering almost half of its length or area.\n",
            "\n",
            "- **Good Signs of High Biodiversity:** This indicates that the survey found positive indicators of a wide variety of species and ecosystems within the river. Biodiversity refers to the variety of\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Survey sights good signs of high biodiversity in 49% of ganga main river.'.\n",
            "Claim: Survey sights good signs of high biodiversity in 49% of ganga main river.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the statement uses the phrase \"good signs of high biodiversity\" which indicates that the survey found positive indicators of a wide variety of species and ecosystems within the river, and the percentage \"49% of the ganga-brahmaputra river\" suggests that the high biodiversity was observed in a substantial portion of the river system, covering almost half of its length or area.\n",
            "Actual Justification: the claim is accurate as the survey found signs of high biodiversity in 49% of the main ganga river, as reported by the indian express.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7fae6a9edc16c6765c7\n",
            "Found 10 documents.\n",
            "['FAKE', 'The claim cannot be verified as the AI language model does not have access to real-time information or personal documents, and the user lacks sufficient context or clarification to provide supporting evidence.']\n",
            "Claim #4854\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Ashok Gehlot baited Sachin Pilot to turn rebel. As an AI language model I do not have access to realtime information or personal\n",
            "\n",
            "I cannot provide supporting documents for the claim that Ashok Gehlot baited Sachin Pilot to turn rebel. As an AI language model I do not have access to realtime information or personal\n",
            "\n",
            "You seem to be referring to a political situation involving Ashok Gehlot and Sachin Pilot, but your question is incomplete. Could you please provide more context or clarify what specific information\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Ashok gehlot baited sachin pilot to turn rebel'.\n",
            "Claim: Ashok gehlot baited sachin pilot to turn rebel\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim cannot be verified as the ai language model does not have access to real-time information or personal documents, and the user lacks sufficient context or clarification to provide supporting evidence.\n",
            "Actual Justification: the article discusses how ashok gehlot played a role in sachin pilot's rebellion by strategically sidelining him and creating a situation that led to pilot's defection.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb7fde6a9edc16c6765c8\n",
            "Found 11 documents.\n",
            "['TRUE', '', 'The claim is supported by the provided context, which states that \"Byelections can be crucial in determining the strength and influence of political parties, especially in states like Gujarat where they hold significant legislative power\". This suggests that the outcome of the byelections in Gujarat can have a significant impact on the political landscape, which in turn could affect the political future of the defectors.']\n",
            "Claim #4855\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can't provide specific documents to support the claim that the Gujarat byelections will decide the political future of 5 defectors. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "defection, and the political landscape in Gujarat.\n",
            "\n",
            "* **Impact of Byelections:** Byelections can be crucial in determining the strength and influence of political parties, especially in states like Gujarat where they hold significant legislative\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Gujarat byelections will decide the political future of 5 defectors.'.\n",
            "Claim: Gujarat byelections will decide the political future of 5 defectors.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the provided context, which states that \"byelections can be crucial in determining the strength and influence of political parties, especially in states like gujarat where they hold significant legislative power\". this suggests that the outcome of the byelections in gujarat can have a significant impact on the political landscape, which in turn could affect the political future of the defectors.\n",
            "Actual Justification: the gujarat byelections are considered crucial for determining the political prospects of five defectors who switched parties.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb800e6a9edc16c6765c9\n",
            "Found 17 documents.\n",
            "['TRUE', 'The given context does not mention Nayib Bukele\\'s reelection as President of El Salvador, but rather states that it \"will\" happen in February 2024, making the claim about the celebrations after his reelection false.']\n",
            "Claim #4856\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The reelection of Nayib Bukele as President of El Salvador in February 2024 sparked a wave of celebrations across the country. Bukele, who is known for his controversial policies and strong leadership\n",
            "\n",
            "The reelection of Nayib Bukele has been a significant event in El Salvador's political landscape, with both supporters and critics expressing their views. The celebrations reflect the mixed emotions\n",
            "\n",
            "Here are some key points about the celebrations and the context of Bukele's presidency:\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Celebrations in el salvador after nayib bukele’s reelection as president.'.\n",
            "Claim: Celebrations in el salvador after nayib bukele’s reelection as president.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not mention nayib bukele's reelection as president of el salvador, but rather states that it \"will\" happen in february 2024, making the claim about the celebrations after his reelection false.\n",
            "Actual Justification: the video is from october 2020 and shows the 70th anniversary celebration of torcida, the supporters' group of croatian football club hajduk split. it has been falsely linked to bukele’s reelection.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb803e6a9edc16c6765ca\n",
            "Found 43 documents.\n",
            "['TRUE', '', \"This claim is supported by the provided documents, specifically Facebook's policy change allowing them to use user-generated content, including photos and posts, as evidence in legal proceedings against users.\"]\n",
            "Claim #4857\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Facebook has changed its policy to allow the use of users pictures and posts in lawsuits as this information is not accurate. Facebooks\n",
            "\n",
            "I cannot provide supporting documents for the claim that Facebook has changed its policy to allow the use of users pictures and posts in lawsuits as this is not a factual statement. Facebooks policies\n",
            "\n",
            "Facebook's new policy allows them to use user-generated content, including photos and posts, as evidence in legal proceedings against those users. This could potentially be used in various legal\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Facebook has changed its policy. It can now use pictures and posts of users in lawsuits against them. This can be prevented by posting a disclaimer on your Facebook wall.'.\n",
            "Claim: Facebook has changed its policy. It can now use pictures and posts of users in lawsuits against them. This can be prevented by posting a disclaimer on your Facebook wall.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: this claim is supported by the provided documents, specifically facebook's policy change allowing them to use user-generated content, including photos and posts, as evidence in legal proceedings against users.\n",
            "Actual Justification: the claim is false. facebook has not changed its policy to allow the use of user posts and pictures in lawsuits against them. the idea that posting a disclaimer on your facebook wall can prevent such use is also incorrect. the policy regarding user data remains unchanged.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb805e6a9edc16c6765cb\n",
            "Found 5 documents.\n",
            "['FAKE', '', 'The claim states that \"Actor Ali Fazal\\'s mother passing away\", but the provided documents do not confirm or mention anything about Ali Fazal\\'s mother passing away. The documents only express sympathy and respect for Ali Fazal\\'s privacy during a difficult time, but do not provide any specific information about his mother\\'s passing.']\n",
            "Claim #4858\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I'm sorry to hear that. Actor Ali Fazal's mother passing away is a tragic event. It's important to remember that this is a personal matter and it's best to respect his privacy during this difficult\n",
            "\n",
            "Ali Fazal is an Indian actor known for his roles in films like \"3 Idiots,\" \"Fukrey,\" and the Hollywood film \"Victoria & Abdul.\" If this news is true, it would be a difficult time for him and his\n",
            "\n",
            "If youre interested in learning more about Philemon Mulalas life and career I can provide general information based on reliable sources. However I cannot confirm the specific cause of his death.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Actor ali fazal's mother passes away.'.\n",
            "Claim: Actor ali fazal's mother passes away.\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim states that \"actor ali fazal's mother passing away\", but the provided documents do not confirm or mention anything about ali fazal's mother passing away. the documents only express sympathy and respect for ali fazal's privacy during a difficult time, but do not provide any specific information about his mother's passing.\n",
            "Actual Justification: the article reports the sad news of ali fazal's mother's passing due to health complications. ali fazal shared a heartfelt message on social media after her death.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb806e6a9edc16c6765cc\n",
            "Found 8 documents.\n",
            "['TRUE', '', 'The given context does not mention anything about a dispute over COVID-19 test or a doctor and local leader being involved. It only mentions a 22-year-old man from Kanpur, India being beaten to death, which matches the initial claim.']\n",
            "Claim #4859\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "In 2020, a 22-year-old man in Kanpur, India, was allegedly beaten to death by a group of people due to a minor dispute over water splatter. The incident sparked widespread outrage and led to\n",
            "\n",
            "**Incident:** A 22-year-old man from Kanpur, India, was brutally beaten to death by a group of people.\n",
            "\n",
            "According to the information available, a 24-year-old man in UP was allegedly beaten to death by a group of people, including a doctor and a local leader, because he did not get a COVID-19 test done.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Kanpur 22-year-old man beaten to death due to water splatter.'.\n",
            "Claim: Kanpur 22-year-old man beaten to death due to water splatter.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given context does not mention anything about a dispute over covid-19 test or a doctor and local leader being involved. it only mentions a 22-year-old man from kanpur, india being beaten to death, which matches the initial claim.\n",
            "Actual Justification: the claim is verified by the article, which reports that a 22-year-old man in kanpur was beaten to death due to an altercation over water splashing during a fight.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb809e6a9edc16c6765cd\n",
            "Found 36 documents.\n",
            "['TRUE', '', 'The claim is supported by the provided documents, which mention that there were reports and investigations into a WhatsApp data breach that affected several Indian political figures, including Priyanka Gandhi Vadra, a prominent leader of the Indian National Congress.']\n",
            "Claim #4860\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can confirm that there have been reports and investigations into a WhatsApp data breach that affected several Indian political figures, including Priyanka Gandhi Vadra, a prominent leader of the\n",
            "\n",
            ". WhatsApp Security Breach In  WhatsApp faced a significant security breach where the personal phone numbers of several highprofile individuals including politicians activists and journalists were\n",
            "\n",
            "In  a security vulnerability in WhatsApps messaging platform was exploited allowing hackers to access the phones of several highprofile individuals including politicians and activists. This incident\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Whatsapp hack targeted priyanka gandhi vadra among other leaders of opposition congress'.\n",
            "Claim: Whatsapp hack targeted priyanka gandhi vadra among other leaders of opposition congress\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the provided documents, which mention that there were reports and investigations into a whatsapp data breach that affected several indian political figures, including priyanka gandhi vadra, a prominent leader of the indian national congress.\n",
            "Actual Justification: the claim is accurate as it reports that priyanka gandhi vadra, along with other leaders from the opposition congress, was targeted in a whatsapp hacking incident.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb80be6a9edc16c6765ce\n",
            "Found 4 documents.\n",
            "['TRUE', 'The claim is supported by the provided documents, which mention that \"169 Sikkim residents who were stranded due to the coronavirus lockdown are returning to their state.\"']\n",
            "Claim #4861\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "That's a significant development! It's great to see that 169 Sikkim residents who were stranded due to the coronavirus lockdown are returning to their state. This news highlights the ongoing efforts\n",
            "\n",
            "- **Health and Safety Measures:** Migrants returning to villages might need to adhere to specific health and safety measures to minimize the risk of spreading the virus. This could include\n",
            "\n",
            "5. **COVID-19: Guidance on risk assessment and management**: This guidance document helps countries assess and manage the risks associated with the virus, including the implementation of lockdown\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'169 stranded sikkim residents due to coronavirus lockdown return to state'.\n",
            "Claim: 169 stranded sikkim residents due to coronavirus lockdown return to state\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the provided documents, which mention that \"169 sikkim residents who were stranded due to the coronavirus lockdown are returning to their state.\"\n",
            "Actual Justification: the article reports that 169 residents of sikkim who were stranded due to the coronavirus lockdown have successfully returned to the state.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb80ee6a9edc16c6765cf\n",
            "Found 46 documents.\n",
            "['TRUE', '', 'The claim is true because it is stated in the given context that \"Palestinian children, especially those involved in the conflict, are typically not conforming to Israeli soldiers. Children in such situations are often victims of the conflict,\" which implies that Palestinian children are not conforming to Israeli soldiers.']\n",
            "Claim #4862\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "1. **Age and Role**: Palestinian children, especially those involved in the conflict, are typically not conforming to Israeli soldiers. Children in such situations are often victims of the conflict,\n",
            "\n",
            "I cannot provide supporting documents for the claim that Palestinian children are conforming to Israeli soldiers during the ongoing conflict between Israel and Hamas. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that Palestinian children are conforming to Israeli soldiers during the ongoing conflict between Israel and Hamas. \n",
            "\n",
            "Heres why\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Palestinian children conforming to Israeli soldiers during the ongoing conflict between Israel and Hamas.'.\n",
            "Claim: Palestinian children conforming to Israeli soldiers during the ongoing conflict between Israel and Hamas.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is true because it is stated in the given context that \"palestinian children, especially those involved in the conflict, are typically not conforming to israeli soldiers. children in such situations are often victims of the conflict,\" which implies that palestinian children are not conforming to israeli soldiers.\n",
            "Actual Justification: the claim is false. the video dates back to 2012 and shows palestinian children confronting israeli soldiers in the west bank village of nabi saleh. it is unrelated to the ongoing israel-hamas conflict.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb80fe6a9edc16c6765d0\n",
            "Found 4 documents.\n",
            "['TRUE', '', 'The justification is based on the provided documents, which state that the park\\'s name has not been changed to Hajrat Haji Peer Baba Rani Baug by the Shiv Sena. The documents confirm that the park is still officially known as \"Veer Mata Jijabai Bhosale Udyan\", named after the mother of Chhatrapati Shivaji, and there is no evidence to suggest that the name has been changed.']\n",
            "Claim #4863\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "This statement is incorrect. The name of the iconic park in Mumbai, previously known as the Veer Mata Jijabai Bhosale Udyan, has not been changed to Hajrat Haji Peer Baba Rani Baug by the Shiv Sena\n",
            "\n",
            "The park, located in South Mumbai, is still officially known as the \"Veer Mata Jijabai Bhosale Udyan,\" named after the mother of Chhatrapati Shivaji, the founder of the Maratha Empire. The name\n",
            "\n",
            "The information you provided indicates that the Indian government has cleared the name of Vijay Sampla, a former member of the Punjab BJP (Bhartiya Janata Party), as the head of the Scheduled Castes\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'The Shiv Sena government in Maharashtra has changed the name of Mumbai’s iconic Veer Mata Jijabai Bhosale Udyan to Hajrat Haji Peer Baba Rani Baug.'.\n",
            "Claim: The Shiv Sena government in Maharashtra has changed the name of Mumbai’s iconic Veer Mata Jijabai Bhosale Udyan to Hajrat Haji Peer Baba Rani Baug.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is based on the provided documents, which state that the park's name has not been changed to hajrat haji peer baba rani baug by the shiv sena. the documents confirm that the park is still officially known as \"veer mata jijabai bhosale udyan\", named after the mother of chhatrapati shivaji, and there is no evidence to suggest that the name has been changed.\n",
            "Actual Justification: the claim is false. mumbai's veer mata jijabai bhosale udyan (also known as byculla zoo) has not been renamed to hajrat haji peer baba rani baug. this is a case of misinformation, as there is no official announcement or record confirming such a name change.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb812e6a9edc16c6765d1\n",
            "Found 9 documents.\n",
            "['TRUE', '', \"The given context does not provide any evidence that Mamata Banerjee's rest was recommended by doctors or that she has tweeted about it. However, it does mention that Mithun Chakraborty, an actor-politician, might have made such a claim, but it does not confirm whether the claim is true or not.\"]\n",
            "Claim #4864\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Media Reports:** Reputable news outlets might have reported on this claim. Searching for news articles from reliable sources using keywords like \"Mithun Chakraborty Mamata Banerjee rest\" could\n",
            "\n",
            "- **Mamata**: This is the name of the politician, Mamata Banerjee, who is the Chief Minister of West Bengal and the leader of the TMC.\n",
            "\n",
            "- **Mamata Banerjee:** The Chief Minister of West Bengal, Mamata Banerjee, is known for her strong political presence and has been a key figure in the opposition against the ruling party. She has\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Actor-politician Mithun Chakraborty has tweeted that doctors have recommended West Bengal Chief Minister Mamata Banerjee take a five-year rest.'.\n",
            "Claim: Actor-politician Mithun Chakraborty has tweeted that doctors have recommended West Bengal Chief Minister Mamata Banerjee take a five-year rest.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not provide any evidence that mamata banerjee's rest was recommended by doctors or that she has tweeted about it. however, it does mention that mithun chakraborty, an actor-politician, might have made such a claim, but it does not confirm whether the claim is true or not.\n",
            "Actual Justification: the tweet in question was posted from a fake twitter account impersonating mithun chakraborty. his only genuine twitter account is '@mithunda_off', which he created recently and is trying to get verified.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb814e6a9edc16c6765d2\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The provided claim is FALSE because the given context states that Pakistan won by 10 wickets, but there were no reports of explosions or injuries related to this event, contradicting the claim that Pakistanis celebrated the win by exploding bombs, resulting in many deaths and injuries.']\n",
            "Claim #4865\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "was played on October 24, 2021, and Pakistan won by 10 wickets, which is a significant victory in cricket. However, there were no reports of explosions or injuries related to this event.\n",
            "\n",
            "It's important to clarify that the information you've provided is not accurate. The 10-wicket win by Pakistan over India in the T20 World Cup did not involve any explosions or casualties. The match\n",
            "\n",
            "The win by Australia in the T20 World Cup semifinal against Pakistan was a moment of national pride and celebration, particularly in Balochistan, where the love for cricket and the spirit of\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Pakistanis celebrated the 10-wicket win over India in the T20 World Cup by exploding bombs instead of firecrackers. Many were dead and injured.'.\n",
            "Claim: Pakistanis celebrated the 10-wicket win over India in the T20 World Cup by exploding bombs instead of firecrackers. Many were dead and injured.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the provided claim is false because the given context states that pakistan won by 10 wickets, but there were no reports of explosions or injuries related to this event, contradicting the claim that pakistanis celebrated the win by exploding bombs, resulting in many deaths and injuries.\n",
            "Actual Justification: the image circulating is not from the recent t20 world cup celebrations but from a 2013 bomb blast in quetta. no major explosions or deaths were reported during the celebrations in pakistan after the t20 match. however, there were some injuries due to celebratory firing.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb816e6a9edc16c6765d3\n",
            "Found 7 documents.\n",
            "['TRUE', '', 'The given context does not mention anything about the NGT lifting a ban on ten-year-old diesel cars and fifteen-year-old petrol cars in the NCR. The provided document only talks about a penalty imposed on LG Polymers and a subject line about a Telangana HC order banning crackers, which is unrelated to the claim being checked.']\n",
            "Claim #4866\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Its important to note that the situation regarding the NRC in Assam is complex and has been the subject of ongoing debate and legal challenges. If youre interested in learning more about the NRC\n",
            "\n",
            "**Subject: Supporting Documents for the Claim: SC Modifies Telangana HC Order Banning Crackers, Asks It to Comply with NGT Order**\n",
            "\n",
            "**To Whom It May Concern:**\n",
            "\n",
            "- The NGT imposed a penalty of Rs 50 crore (Indian Rupees) on LG Polymers for their failure to adhere to safety and environmental protection norms.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'The NGT has lifted its ban on ten-year-old diesel cars and fifteen-year-old petrol cars in the NCR. All you have to do is pay a registration fee of Rs. 5,000.'.\n",
            "Claim: The NGT has lifted its ban on ten-year-old diesel cars and fifteen-year-old petrol cars in the NCR. All you have to do is pay a registration fee of Rs. 5,000.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not mention anything about the ngt lifting a ban on ten-year-old diesel cars and fifteen-year-old petrol cars in the ncr. the provided document only talks about a penalty imposed on lg polymers and a subject line about a telangana hc order banning crackers, which is unrelated to the claim being checked.\n",
            "Actual Justification: this claim is false. the national green tribunal (ngt) has not lifted the ban on fifteen-year-old petrol cars or ten-year-old diesel cars in delhi ncr. the rule that restricts the operation of older vehicles in the ncr still holds, and there is no provision allowing owners to pay a registration fee of rs. 5,000 to circumvent the ban. the claim circulating is misleading and incorrect.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb819e6a9edc16c6765d4\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The claim is about Nita Ambani, a prominent Indian businesswoman and philanthropist, and her involvement in the Ram Mandir movement, which is mentioned in the provided context.']\n",
            "Claim #4867\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "PM Modi recalled her journey from a successful actress to a powerful political leader emphasizing her unwavering commitment to the welfare of Tamil Nadu. He mentioned her contributions to the states\n",
            "\n",
            "* **Nita Ambani:** A prominent Indian businesswoman and philanthropist. She is the wife of Reliance Industries Limited chairman Mukesh Ambani. While her involvement in the Ram Mandir movement is less\n",
            "\n",
            ". News Articles Search for recent news articles mentioning Baishali Dalmiya and her political affiliations. Reputable news sources like The Hindu The Times of India or Indian Express often provide\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Adivasi woman who fed lunch to bjp's amit shah gets job from tmc govt in wb's siliguri.'.\n",
            "Claim: Adivasi woman who fed lunch to bjp's amit shah gets job from tmc govt in wb's siliguri.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is about nita ambani, a prominent indian businesswoman and philanthropist, and her involvement in the ram mandir movement, which is mentioned in the provided context.\n",
            "Actual Justification: the article from *the statesman* confirms that the adivasi woman, who hosted bjp leader amit shah for lunch, was later given a government job by the tmc government in siliguri, west bengal.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb820e6a9edc16c6765d5\n",
            "Found 22 documents.\n",
            "['TRUE', '', 'The justification is that the provided documents, specifically the press release, confirm that ITC has indeed established a Rs 150 crore relief fund to address the impact of the COVID-19 pandemic on vulnerable sections of society.']\n",
            "Claim #4868\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can provide a summary of the supporting documents for the claim that ITC (Indian Tobacco Company) has set up a Rs 150 crore coronavirus fund for vulnerable sections of society. Here's a breakdown:\n",
            "\n",
            "* ITC has announced the establishment of a Rs 150 crore relief fund to address the impact of the COVID-19 pandemic on vulnerable sections of society.\n",
            "\n",
            "* **Date:** [Date of the press release]\n",
            "* **Title:** \"ITC Launches Rs 150 Crore COVID-19 Relief Fund to Support Vulnerable Communities\"\n",
            "* **Content:**\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Itc sets up rs 150 cr coronavirus fund for vulnerable sections of society'.\n",
            "Claim: Itc sets up rs 150 cr coronavirus fund for vulnerable sections of society\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the provided documents, specifically the press release, confirm that itc has indeed established a rs 150 crore relief fund to address the impact of the covid-19 pandemic on vulnerable sections of society.\n",
            "Actual Justification: the article confirms that itc has established a rs 150 crore fund to support vulnerable sections of society during the coronavirus pandemic.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb824e6a9edc16c6765d6\n",
            "Found 50 documents.\n",
            "['TRUE', '', 'The justification is that the text explicitly states \"It\\'s important to clarify that the celebration of demonetization in India is not a widespread or ongoing event\", which implies that the celebration is not happening.']\n",
            "Claim #4869\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "about ongoing celebrations related to demonetization in India\n",
            "\n",
            "I cannot provide supporting documents for the claim that Indians are still celebrating demonetisation. \n",
            "\n",
            "Heres why\n",
            "\n",
            "It's important to clarify that the celebration of demonetization in India is not a widespread or ongoing event. The decision to demonetize high-value currency notes in November 2016 was a significant\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Indians are still celebrating demonetisation'.\n",
            "Claim: Indians are still celebrating demonetisation\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the text explicitly states \"it's important to clarify that the celebration of demonetization in india is not a widespread or ongoing event\", which implies that the celebration is not happening.\n",
            "Actual Justification: the claim is supported by the article which discusses how some indians are still celebrating demonetisation, despite the challenges it posed to the economy and common people.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb826e6a9edc16c6765d7\n",
            "Found 2 documents.\n",
            "['TRUE', '', 'The claim is verified as TRUE because the quote \"We will emerge as winners, don\\'t fall prey to rumours, maanayata dutt on sanjay dutt\" is mentioned in the given context, which suggests that Maanayata Dutt is encouraging her brother Sanjay Dutt to stay strong in the face of rumors, without any mention of him converting to Islam.']\n",
            "Claim #4870\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you're sharing a quote from Maanayata Dutt about Sanjay Dutt. This quote reflects her support for her brother and encouragement for him to stay strong in the face of rumors. If you have\n",
            "\n",
            "The claim that Sanjay Dutt converted to Islam is a matter of public speculation and has not been confirmed by reliable sources. It is important to respect the privacy of individuals and avoid\n",
            "\n",
            "*Source: [Name of Reputable News Outlet]*\n",
            "\n",
            "---\n",
            "\n",
            "**Headline:** Mumbai Police's Bold Move Against TRP Scam Praised by Shiv Sena Leader Sanjay Raut\n",
            "\n",
            "**Body:**\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'We will emerge as winners, don't fall prey to rumours, maanayata dutt on sanjay dutt.'.\n",
            "Claim: We will emerge as winners, don't fall prey to rumours, maanayata dutt on sanjay dutt.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is verified as true because the quote \"we will emerge as winners, don't fall prey to rumours, maanayata dutt on sanjay dutt\" is mentioned in the given context, which suggests that maanayata dutt is encouraging her brother sanjay dutt to stay strong in the face of rumors, without any mention of him converting to islam.\n",
            "Actual Justification: the claim is verified by the article, which reports that maanayata dutt issued a statement urging fans not to fall prey to rumours regarding sanjay dutt's health and expressed confidence that they would emerge as winners.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb829e6a9edc16c6765d8\n",
            "Found 11 documents.\n",
            "['TRUE', '', 'The claim states that Poonam Pandey married Shamshad Ali alias Sam Bombay, which is a hypothetical scenario according to the provided documents. There is no public record or evidence to support this claim.']\n",
            "Claim #4871\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "3. **Marriage to Shamshad Ali (Sam Bombay)**: The idea of Poonam Pandey marrying someone named Shamshad Ali, also known as Sam Bombay, is a hypothetical scenario. There is no public record or\n",
            "\n",
            "1. **Poonam Pandey**: She is a real-life actress and model known for her work in the Indian film industry. She has been in the news for various reasons, including her social media posts and public\n",
            "\n",
            "2. **Insulting Hindu gods**: There have been instances where Poonam Pandey has made controversial statements or posts that have been perceived as insulting to Hindu gods. However, the specific\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'C-grade actor Poonam Pandey, who has often insulted Hindu gods, is now in hospital after marrying Shamshad Ali alias Sam Bombay to prove her secularism.'.\n",
            "Claim: C-grade actor Poonam Pandey, who has often insulted Hindu gods, is now in hospital after marrying Shamshad Ali alias Sam Bombay to prove her secularism.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim states that poonam pandey married shamshad ali alias sam bombay, which is a hypothetical scenario according to the provided documents. there is no public record or evidence to support this claim.\n",
            "Actual Justification: the claim that poonam pandey is in the hospital due to proving her secularism after marrying shamshad ali is false. poonam pandey was hospitalized due to an assault by her husband, sam bombay.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb82ce6a9edc16c6765d9\n",
            "Found 12 documents.\n",
            "['TRUE', '', 'The claim is true because the text mentions \"Indian Oil Corporation Limited (IOCL) Apprentice Admit Card for the year 2019\" and provides steps to download or view the admit cards, indicating that the admit cards have been released.']\n",
            "Claim #4872\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you're referring to the Indian Oil Corporation Limited (IOCL) Apprentice Admit Card for the year 2019. If you're looking to download your admit card, here are the general steps you can\n",
            "\n",
            "4. **Download or View Admit Cards:** Once you locate the relevant page, you should be able to download or view the admit cards for the 2019 examination.\n",
            "\n",
            "**Important Notes:**\n",
            "\n",
            "The SSC (Staff Selection Commission) has released the admit cards for the General Duty (GD) Constable post in 2019. Here's a breakdown of how to download your admit card:\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'IOCL apprentice admit cards 2019 released at iocl.com. here's how to download admit cards.'.\n",
            "Claim: IOCL apprentice admit cards 2019 released at iocl.com. here's how to download admit cards.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is true because the text mentions \"indian oil corporation limited (iocl) apprentice admit card for the year 2019\" and provides steps to download or view the admit cards, indicating that the admit cards have been released.\n",
            "Actual Justification: indian oil corporation limited (iocl) released the admit cards for the apprentice recruitment exam in 2019, and the procedure for downloading them was shared on the official website.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb82fe6a9edc16c6765da\n",
            "Found 16 documents.\n",
            "['TRUE', '', 'The statement is supported by the context, which suggests that the BJP is trying to present itself as a party that can deliver both economic prosperity and social welfare, and holding business summits is a way for them to appeal to entrepreneurs and demonstrate their ability to drive economic growth.']\n",
            "Claim #4873\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement \"BJP's balancing act ahead of 2019: Hold business summits while talking about welfare\" suggests that the Bharatiya Janata Party (BJP), a major political party in India, is strategically\n",
            "\n",
            "- The 2019 general elections are a significant event in Indian politics, and the BJP aims to secure a strong mandate. This balancing act is likely a part of their broader campaign strategy to win\n",
            "\n",
            "- The BJP's strategy might be to present itself as a party that can deliver both economic prosperity and social welfare. By holding business summits, they can appeal to entrepreneurs,\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'BJP's balancing act ahead of 2019: Hold business summits while talking about welfare.'.\n",
            "Claim: BJP's balancing act ahead of 2019: Hold business summits while talking about welfare.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the statement is supported by the context, which suggests that the bjp is trying to present itself as a party that can deliver both economic prosperity and social welfare, and holding business summits is a way for them to appeal to entrepreneurs and demonstrate their ability to drive economic growth.\n",
            "Actual Justification: the article discusses how the bjp, ahead of the 2019 elections, balanced its approach by holding business summits while also focusing on welfare issues.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb831e6a9edc16c6765db\n",
            "Found 7 documents.\n",
            "['FAKE', '', \"The justification is that NASA's Public Statements explicitly state that they do not have the capability to predict earthquakes with precision, which contradicts the claim that NASA predicted a strong earthquake in Delhi-NCR between April 7-15, 2020.\"]\n",
            "Claim #4874\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that NASA predicted a strong earthquake in Delhi-NCR between April 7-15, 2020. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "* **NASA's Public Statements:** NASA does not have the capability to predict earthquakes with precision. While they study seismic activity and monitor tectonic plate movements, their focus is on\n",
            "\n",
            "- **After earthquake tremors were felt across Delhi-NCR on January 24**: This part provides a specific date and location, indicating that the crows' behavior was influenced by the earthquake that\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'US space agency NASA predicted a strong earthquake in Delhi-ncr between april 7-15 in 2020.'.\n",
            "Claim: US space agency NASA predicted a strong earthquake in Delhi-ncr between april 7-15 in 2020.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that nasa's public statements explicitly state that they do not have the capability to predict earthquakes with precision, which contradicts the claim that nasa predicted a strong earthquake in delhi-ncr between april 7-15, 2020.\n",
            "Actual Justification: the claim is misleading. nasa did not predict a strong earthquake in delhi-ncr between april 7-15. the viral message claiming this prediction is false. the fact-checking arm of the indian government and other sources have confirmed that no such prediction was made by nasa.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb833e6a9edc16c6765dc\n",
            "Found 8 documents.\n",
            "['TRUE', 'The justification is that the AI model acknowledges it cannot provide supporting documents for the claim, but it does not explicitly deny the claim. The example provided of a Rajasthan Congress Leader being jailed for breaking COVID quarantine rules suggests that such incidents can occur, which implies that the claim about a BJP leader in Vadodara is possible but not explicitly verified.']\n",
            "Claim #4875\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that a BJP leader in Vadodara was held for breach of COVID norms. As an AI language model I do not have access to realtime information or specific\n",
            "\n",
            "I cannot provide supporting documents for the claim that a BJP leader in Vadodara was held for breach of COVID norms. As an AI language model I do not have access to realtime information or specific\n",
            "\n",
            "Example Rajasthan Congress Leader Jailed for Breaking COVID Quarantine Rules Date MMDDYYYY\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'vadodara bjp leader held for breach of covid norms'.\n",
            "Claim: vadodara bjp leader held for breach of covid norms\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the ai model acknowledges it cannot provide supporting documents for the claim, but it does not explicitly deny the claim. the example provided of a rajasthan congress leader being jailed for breaking covid quarantine rules suggests that such incidents can occur, which implies that the claim about a bjp leader in vadodara is possible but not explicitly verified.\n",
            "Actual Justification: the claim is based on the news that a bjp leader from vadodara was arrested for violating covid-19 norms during a public gathering.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb834e6a9edc16c6765dd\n",
            "Found 4 documents.\n",
            "['FAKE', 'The justification for labeling this claim as fake is that the text itself states \"I cannot provide supporting documents for the claim...\" and provides steps to find credible news reports or official statements from law enforcement agencies, implying that the claim is unsubstantiated and lacks evidence.']\n",
            "Claim #4876\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that a Dalit family from Karnataka was recently tortured, stripped naked in public, and fined for entering a temple and touching an idol.\n",
            "\n",
            "To support the claim \"Dalit stripped, beaten up in Karnataka; 2 held,\" you would need to provide credible news reports or official statements from law enforcement agencies. Here are some steps to find\n",
            "\n",
            "It's a tragic incident that highlights the ongoing issues of violence and discrimination faced by the Dalit community in India. The killing of two Dalit sisters and the dumping of their bodies in a\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A Dalit family from Karnataka was recently tortured, stripped naked in public, and fined for entering a temple and touching an idol.'.\n",
            "Claim: A Dalit family from Karnataka was recently tortured, stripped naked in public, and fined for entering a temple and touching an idol.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification for labeling this claim as fake is that the text itself states \"i cannot provide supporting documents for the claim...\" and provides steps to find credible news reports or official statements from law enforcement agencies, implying that the claim is unsubstantiated and lacks evidence.\n",
            "Actual Justification: the photo being circulated is not from a recent incident in karnataka. it is an old image of a dalit family from greater noida, and the claim about them being tortured and fined for touching an idol is false.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb836e6a9edc16c6765de\n",
            "Found 13 documents.\n",
            "['TRUE', '', 'The justification is that the given context mentions the second phase of the Malabar exercise will commence in the Bay States, which is a typo and should be \"Bay of Bengal\", not the Northern Arabian Sea.']\n",
            "Claim #4877\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The Malabar exercise is a series of bilateral naval exercises conducted by the Indian Navy and various friendly foreign navies. The second phase of the Malabar exercise, as you mentioned, typically\n",
            "\n",
            "The Indian Navy along with its counterparts from Japan Australia and the United States will commence the second phase of the Malabar exercise today. This annual joint naval exercise held in the Bay\n",
            "\n",
            "States, are preparing to commence the second phase of the Malabar naval exercise.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Second phase of malabar exercise begins in northern arabian sea.'.\n",
            "Claim: Second phase of malabar exercise begins in northern arabian sea.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the given context mentions the second phase of the malabar exercise will commence in the bay states, which is a typo and should be \"bay of bengal\", not the northern arabian sea.\n",
            "Actual Justification: the article confirms that the second phase of the malabar naval exercise began in the northern arabian sea, involving india, the u.s., japan, and australia, with the goal of enhancing maritime security and cooperation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb839e6a9edc16c6765df\n",
            "Found 13 documents.\n",
            "['TRUE', '', \"The claim is supported by the provided documents, specifically document 1, which mentions that the UN often issues notices or reports to highlight human rights violations in conflict zones, and document 2, which describes the act of tearing down a notice issued by the UN as a clear violation of international norms and the UN's authority.\"]\n",
            "Claim #4878\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "2. **Israel’s UN Envoy Tearing Down the Notice**: The act of tearing down a notice issued by the UN is a clear violation of international norms and the UN's authority. It suggests a deliberate\n",
            "\n",
            "1. **UN Notice for Human Rights Violations**: The UN often issues notices or reports to highlight human rights violations in conflict zones. These documents are part of the UN's efforts to monitor\n",
            "\n",
            "United Nations The United Nations Human Rights Council and other UN bodies have issued reports and resolutions addressing human rights concerns in Palestine including allegations of Israeli military\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Amid the ongoing conflict between Israel and Hamas, Israel’s UN envoy tore down a notice issued by the UN for human rights violations.'.\n",
            "Claim: Amid the ongoing conflict between Israel and Hamas, Israel’s UN envoy tore down a notice issued by the UN for human rights violations.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the provided documents, specifically document 1, which mentions that the un often issues notices or reports to highlight human rights violations in conflict zones, and document 2, which describes the act of tearing down a notice issued by the un as a clear violation of international norms and the un's authority.\n",
            "Actual Justification: the claim is false. the video is from october 2021 and shows israeli envoy to the un, gilad erdan, tearing up the un human rights council’s annual report during the un general assembly. it is unrelated to the current conflict between israel and hamas.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb83be6a9edc16c6765e0\n",
            "Found 47 documents.\n",
            "['FAKE', '', 'The provided information explicitly states that \"I cannot provide supporting documents for the claim that a Hindu woman from Kerala is currently jailed in Afghanistan as an ISIS terrorist.\" This indicates that the claim is false and lacks evidence to support it.']\n",
            "Claim #4879\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that a Hindu woman from Kerala is currently jailed in Afghanistan as an ISIS terrorist.\n",
            "\n",
            "I cannot provide supporting documents for the claim that a Hindu woman from Kerala is currently jailed in Afghanistan as an ISIS terrorist.\n",
            "\n",
            "In this specific case, the Hindu woman's refusal to convert to Islam led to a tragic outcome, with her Muslim partner allegedly stabbing her to death. This incident underscores the importance of\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A Hindu woman from Kerala who is currently jailed in Afghanistan as an ISIS terrorist. She converted to Islam and was manipulated to join the terrorist outfit.'.\n",
            "Claim: A Hindu woman from Kerala who is currently jailed in Afghanistan as an ISIS terrorist. She converted to Islam and was manipulated to join the terrorist outfit.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the provided information explicitly states that \"i cannot provide supporting documents for the claim that a hindu woman from kerala is currently jailed in afghanistan as an isis terrorist.\" this indicates that the claim is false and lacks evidence to support it.\n",
            "Actual Justification: the video being circulated is not of a real incident but is clipped from a film teaser. the claim that the woman is jailed in afghanistan as an isis terrorist is fabricated. the footage is part of a fictional film, and no evidence supports the claim that the woman converted to islam and joined isis.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb83de6a9edc16c6765e1\n",
            "Found 12 documents.\n",
            "['FAKE', '', 'The justification is that the text states that \"the responsibility for the damage would typically fall on the entity that owns or operates the satellite\", implying that the compensation would not be a fixed amount (Rs. 74 crore) but would depend on the evidence of damage and the negotiations with the entity responsible for the satellite.']\n",
            "Claim #4880\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "In summary, while the idea of a satellite crashing into your house and providing a large compensation is intriguing, it is not a realistic or practical scenario in the real world. If you have any\n",
            "\n",
            "1. **Legal Context**: In a real-world scenario, if a satellite were to crash into a house, the responsibility for the damage would typically fall on the entity that owns or operates the satellite.\n",
            "\n",
            "2. **Compensation Claims**: If you were to make a claim for damages, you would need to provide evidence of the damage caused by the satellite. This might include photographs, expert reports, and\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'If a satellite crashes into your house, you will receive compensation of Rs. 74 crore.'.\n",
            "Claim: If a satellite crashes into your house, you will receive compensation of Rs. 74 crore.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the text states that \"the responsibility for the damage would typically fall on the entity that owns or operates the satellite\", implying that the compensation would not be a fixed amount (rs. 74 crore) but would depend on the evidence of damage and the negotiations with the entity responsible for the satellite.\n",
            "Actual Justification: the claim about receiving rs. 74 crore as compensation for a satellite crash is incorrect. while international treaties govern liability for space debris, the compensation amount would depend on specific circumstances and legal agreements, not a fixed amount.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb841e6a9edc16c6765e2\n",
            "Found 38 documents.\n",
            "['TRUE', '', 'The claimant is unable to provide specific supporting documents due to lack of access to real-time information, but does not explicitly deny the claim. This implies that the claim may be true, although the lack of evidence makes it difficult to verify.']\n",
            "Claim #4881\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Im sorry but I cannot provide specific documents or information that directly support the claim capt amarinder singh deputes manpreet badal to resolve rdf issue with centre.\n",
            "\n",
            "Im sorry but I cannot provide specific supporting documents for the claim capt amarinder singh deputes manpreet badal to resolve rdf issue with centre as I do not have access to realtime information\n",
            "\n",
            "Im sorry but I cannot provide specific supporting documents for the claim capt amarinder singh deputes manpreet badal to resolve rdf issue with centre as I do not have access to realtime information\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'capt amarinder singh deputes manpreet badal to resolve rdf issue with centre.'.\n",
            "Claim: capt amarinder singh deputes manpreet badal to resolve rdf issue with centre.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claimant is unable to provide specific supporting documents due to lack of access to real-time information, but does not explicitly deny the claim. this implies that the claim may be true, although the lack of evidence makes it difficult to verify.\n",
            "Actual Justification: capt amarinder singh, the chief minister of punjab, assigned manpreet badal, the state's finance minister, to resolve the issue regarding the rural development fund (rdf) with the central government.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb845e6a9edc16c6765e3\n",
            "Found 15 documents.\n",
            "['TRUE', '', 'The justification is that the text states \"The advisory issued by the Ministry of AYUSH of India suggesting the use of Arsenicum Album 30 as a prophylactic measure against coronavirus infection has been a subject of scrutiny and debate.\" This indicates that the Ministry of AYUSH of India did indeed issue an advisory recommending the use of Arsenicum Album 30 as a prophylactic measure against coronavirus infection.']\n",
            "Claim #4882\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The advisory issued by the Ministry of AYUSH of India suggesting the use of Arsenicum Album 30 as a prophylactic measure against coronavirus infection has been a subject of scrutiny and debate. Here\n",
            "\n",
            "1. **Scientific Evidence**: The recommendation is based on traditional homeopathic principles and historical use, but there is currently no scientific evidence to support the efficacy of Arsenicum\n",
            "\n",
            "3. **Public Health Concerns**: Recommending unproven remedies can lead to public health risks. If people rely on Arsenicum Album 30 as a prophylactic measure and it does not prevent infection, they\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'The Ministry of AYUSH of India issued an advisory recommending the homeopathic drug Arsenicum Album 30 as a 'prophylactic medicine' for preventing coronavirus infection.'.\n",
            "Claim: The Ministry of AYUSH of India issued an advisory recommending the homeopathic drug Arsenicum Album 30 as a 'prophylactic medicine' for preventing coronavirus infection.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the text states \"the advisory issued by the ministry of ayush of india suggesting the use of arsenicum album 30 as a prophylactic measure against coronavirus infection has been a subject of scrutiny and debate.\" this indicates that the ministry of ayush of india did indeed issue an advisory recommending the use of arsenicum album 30 as a prophylactic measure against coronavirus infection.\n",
            "Actual Justification: the claim that the homeopathy drug arsenicum album 30 can prevent coronavirus infection is false. the ministry of ayush did release an advisory recommending arsenicum album 30 as a prophylactic measure, but there is no scientific evidence to support its effectiveness in preventing covid-19. the advisory has faced substantial criticism from other medical experts due to insufficient literature and biased observations.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb848e6a9edc16c6765e4\n",
            "Found 22 documents.\n",
            "['TRUE', 'The context suggests that the claim is based on \"academic research papers or historical studies on the Spanish flu pandemic\", which implies that the information is credible and reliable, and provides supporting documents and references to back up the claim.']\n",
            "Claim #4883\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Here are some supporting documents and references for the claim that people wearing different kinds of masks were a part of the Spanish flu pandemic of 1918-1920:\n",
            "\n",
            "- Academic research papers or historical studies on the Spanish flu pandemic might provide detailed analyses of various control measures, including mask-wearing. These sources can offer\n",
            "\n",
            "by showing the different types of masks people attempted to use during the pandemic.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'People in different kinds of masks is from the Spanish flu pandemic of 1918-20.'.\n",
            "Claim: People in different kinds of masks is from the Spanish flu pandemic of 1918-20.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the context suggests that the claim is based on \"academic research papers or historical studies on the spanish flu pandemic\", which implies that the information is credible and reliable, and provides supporting documents and references to back up the claim.\n",
            "Actual Justification: the claim is false. the pictures in question are not from the spanish flu pandemic of 1918-20. these images are unrelated and are actually from various events over the years, including the covid-19 pandemic, and have been misattributed to the spanish flu.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb84be6a9edc16c6765e5\n",
            "Found 43 documents.\n",
            "['TRUE', '', 'The given context suggests that the claim is based on recent heavy rainfall in Chennai and its effects on Marina Beach, which can be verified through articles, official websites of the Chennai Corporation or Tamil Nadu government, and visual documentation. There is no indication that the claim is false or exaggerated, and it is a plausible scenario given the context.']\n",
            "Claim #4884\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "like Marina Beach Chennai underwater Chennai rains or Chennai flooding.\n",
            "\n",
            "Marina Beach. Look for articles mentioning the recent heavy rainfall in Chennai and its effects on the beach.\n",
            "\n",
            "The Chennai Corporation or the Tamil Nadu governments official websites might have information or visual documentation of the recent rains and their impact on Marina Beach.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Marina Beach in Chennai underwater as Chennai is receiving incessant rains.'.\n",
            "Claim: Marina Beach in Chennai underwater as Chennai is receiving incessant rains.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context suggests that the claim is based on recent heavy rainfall in chennai and its effects on marina beach, which can be verified through articles, official websites of the chennai corporation or tamil nadu government, and visual documentation. there is no indication that the claim is false or exaggerated, and it is a plausible scenario given the context.\n",
            "Actual Justification: the video circulating as recent visuals of marina beach underwater is actually an old video from 2017, not related to the current rains or cyclone nivar.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb84de6a9edc16c6765e6\n",
            "Found 9 documents.\n",
            "['TRUE', '', \"The claim is true because Rhea Chakraborty has filed a plea seeking the transfer of the FIR from Patna to Mumbai, which implies that she has filed a complaint or an application in this regard, but it does not specifically mention filing a complaint against Sushant's sister and doctor.\"]\n",
            "Claim #4885\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Rhea Chakraborty filed a complaint against Sushant Singh Rajput's sister and doctor. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "- Rhea Chakraborty, a former girlfriend of Sushant, has filed a plea seeking the transfer of the FIR from Patna to Mumbai, where the investigation is also taking place.\n",
            "\n",
            "* **Contextual Information:** I can provide information about the legal process involved in filing complaints, the potential parties involved (Rhea Chakraborty, Sushant Singh Rajput's sister, and\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Rhea chakraborty files complaint against sushant's sister, doctor.'.\n",
            "Claim: Rhea chakraborty files complaint against sushant's sister, doctor.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is true because rhea chakraborty has filed a plea seeking the transfer of the fir from patna to mumbai, which implies that she has filed a complaint or an application in this regard, but it does not specifically mention filing a complaint against sushant's sister and doctor.\n",
            "Actual Justification: according to the report, rhea chakraborty filed a police complaint against sushant singh rajput's sister, priyanka singh, and a doctor for allegedly procuring a fake prescription for anxiety medication for sushant. the complaint cited concerns about the legality and authenticity of the prescription.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb84fe6a9edc16c6765e7\n",
            "Found 11 documents.\n",
            "['TRUE', '', 'The justification is that the claimant is unable to provide supporting documents, which implies that the claim is likely false or unfounded.']\n",
            "Claim #4886\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Kolkata police beat up Kanwar Yatra pilgrims.\n",
            "\n",
            "I cannot provide supporting documents for the claim that Kolkata police beat up Kanwar Yatra pilgrims.\n",
            "\n",
            "I cannot provide supporting documents for the claim that Kolkata police beat up Kanwar Yatra pilgrims.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Kolkata police beating up Kanwar Yatra pilgrims.'.\n",
            "Claim: Kolkata police beating up Kanwar Yatra pilgrims.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claimant is unable to provide supporting documents, which implies that the claim is likely false or unfounded.\n",
            "Actual Justification: the video is from 2021 and shows a police lathi-charge during covid-19 restrictions, not related to the kanwar yatra.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb852e6a9edc16c6765e8\n",
            "Found 15 documents.\n",
            "['TRUE', '', 'The justification is that the statement is based on the given context, which states that Prime Minister Modi referred to a \"watershed moment\" in the history of Indian agriculture and assured that the Minimum Support Price (MSP) system will continue.']\n",
            "Claim #4887\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement you've mentioned, \"Watershed moment in history of Indian agriculture, says PM Modi assures system of MSP will remain,\" refers to a significant announcement made by the Prime Minister of\n",
            "\n",
            "- In a speech, Prime Minister Modi emphasized the importance of agriculture in India's development and referred to a \"watershed moment\" in the history of Indian agriculture.\n",
            "\n",
            "2. **Assurance of MSP:** Prime Minister Modi assured that the Minimum Support Price (MSP) system, which has been a cornerstone of Indian agricultural policy, will continue. This system ensures that\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Watershed moment in history of indian agriculture, says pm modi assures system of msp will remain'.\n",
            "Claim: Watershed moment in history of indian agriculture, says pm modi assures system of msp will remain\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the statement is based on the given context, which states that prime minister modi referred to a \"watershed moment\" in the history of indian agriculture and assured that the minimum support price (msp) system will continue.\n",
            "Actual Justification: the claim is supported by the statesman article, which reports that prime minister narendra modi referred to a recent development in indian agriculture as a watershed moment and assured that the minimum support price (msp) system would continue.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb854e6a9edc16c6765e9\n",
            "Found 8 documents.\n",
            "['FAKE', 'The given context explicitly states that the AI language model does not have access to real-time information or the ability to verify the accuracy of the claim, and there are no supporting documents provided to back up the claim that Dr. Anthony Fauci has been arrested.']\n",
            "Claim #4888\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Dr. Anthony Fauci has been arrested. As an AI language model I do not have access to realtime information or the ability to verify the accuracy\n",
            "\n",
            "I cannot provide supporting documents for the claim that Dr. Anthony Fauci has been arrested. As an AI language model I do not have access to realtime information or the ability to verify the accuracy\n",
            "\n",
            "comprehensive overview of the case including the names of the arrested individuals and the evidence collected.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.' Dr. Anthony Fauci has been arrested.'.\n",
            "Claim:  Dr. Anthony Fauci has been arrested.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context explicitly states that the ai language model does not have access to real-time information or the ability to verify the accuracy of the claim, and there are no supporting documents provided to back up the claim that dr. anthony fauci has been arrested.\n",
            "Actual Justification: the photos suggesting dr. fauci's arrest are ai-generated. they are not real and have been manipulated using artificial intelligence technology, which is still imperfect.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb856e6a9edc16c6765ea\n",
            "Found 11 documents.\n",
            "['TRUE', '', 'The given context mentions that the statement is a reflection of the Congress party\\'s position and strategy in the political landscape, and the spokesperson is likely referring to Narendra Modi as a \"hero\" in the context of a TV debate, which suggests that the statement is genuine and not fabricated.']\n",
            "Claim #4889\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "2. **Criticism of Rahul Gandhi**: The comment that it's \"very difficult\" for Rahul Gandhi to compete with Modi suggests a perception of Modi's strength and popularity. This could be a strategic move\n",
            "\n",
            "1. **Political Stance**: The statement is a reflection of the Congress party's position and strategy in the political landscape. By referring to Narendra Modi as a \"hero,\" the spokesperson is likely\n",
            "\n",
            "honour of a prominent Indian leader including Narendra Modi.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Congress spokesperson has lauded Narendra Modi as a “hero” in a TV debate and accepted that it’s “very difficult” for Rahul Gandhi to compete with him.'.\n",
            "Claim: Congress spokesperson has lauded Narendra Modi as a “hero” in a TV debate and accepted that it’s “very difficult” for Rahul Gandhi to compete with him.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context mentions that the statement is a reflection of the congress party's position and strategy in the political landscape, and the spokesperson is likely referring to narendra modi as a \"hero\" in the context of a tv debate, which suggests that the statement is genuine and not fabricated.\n",
            "Actual Justification: the claim is false. the tv debate clip circulating on social media is doctored. the congress spokesperson did not praise narendra modi as a 'hero' or acknowledge that it is difficult for rahul gandhi to compete with him. the video was selectively edited to distort the spokesperson's original words.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb859e6a9edc16c6765eb\n",
            "Found 13 documents.\n",
            "['TRUE', '', 'The claim is supported by the provided context, which mentions that the government has taken a proactive approach by shortlisting five potential sites for the proposed mosque, indicating that the development is real and not fake.']\n",
            "Claim #4890\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The recent development mentioned in your prompt suggests that the government has taken a proactive approach by shortlisting five potential sites for the proposed mosque. This move indicates a\n",
            "\n",
            "- The Ayodhya issue refers to the long-standing dispute over the Babri Masjid-Ram Janmabhoomi site in Ayodhya, Uttar Pradesh. The BJP has been advocating for the construction of a Hindu temple at\n",
            "\n",
            "As the process unfolds, it is expected that further discussions and negotiations will take place to determine the most suitable site for the proposed mosque and to address the concerns of all parties\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Ayodhya dispute: yogi adityanath govt shortlists 5 sites for proposed mosque.'.\n",
            "Claim: Ayodhya dispute: yogi adityanath govt shortlists 5 sites for proposed mosque.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the provided context, which mentions that the government has taken a proactive approach by shortlisting five potential sites for the proposed mosque, indicating that the development is real and not fake.\n",
            "Actual Justification: the article confirms that the yogi adityanath government has shortlisted 5 sites for the construction of a proposed mosque in the context of the ayodhya dispute.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb85ce6a9edc16c6765ec\n",
            "Found 15 documents.\n",
            "['TRUE', '', \"The given context does not mention PM Modi's praise or the demand for Tamil to be recognized as an official language after his praise, it only mentions the DMK's long-standing demand for official language status for Tamil.\"]\n",
            "Claim #4891\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "- The DMK has been pushing for the recognition of Tamil as an official language at the national level, arguing that it will help promote the language, culture, and education in Tamil Nadu and among\n",
            "\n",
            "- The DMK's demand for official language status is part of a broader movement to promote Tamil language and culture. They argue that the recognition will help preserve the language, improve access to\n",
            "\n",
            "The demand for Tamil to be recognized as an official language in India is a long-standing issue and has been a topic of discussion and debate for many years. The Dravida Munnetra Kazhagam (DMK), a\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'After pm modi's praise, dmk demands tamil to be recognised as an official language'.\n",
            "Claim: After pm modi's praise, dmk demands tamil to be recognised as an official language\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given context does not mention pm modi's praise or the demand for tamil to be recognized as an official language after his praise, it only mentions the dmk's long-standing demand for official language status for tamil.\n",
            "Actual Justification: following prime minister narendra modi's praise of tamil, the dmk (dravida munnetra kazhagam) party demanded that tamil be officially recognized as a language in india. the party called for constitutional recognition of tamil as an official language after modi's remarks about the language, highlighting its significance and role in india's diversity.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb85fe6a9edc16c6765ed\n",
            "Found 17 documents.\n",
            "['TRUE', 'The supporting information provided, including news articles and reports from farmer organizations and human rights groups, confirms that police used water cannons to disperse farmers protesting in Haryana in February 2023, which supports the claim.']\n",
            "Claim #4892\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "**Claim:** Farmers intensify protests, water cannons used to stop congress activists from entering Haryana.\n",
            "\n",
            "**Supporting Information:**\n",
            "\n",
            "* News articles from February 2023 mentioning the use of water cannons in Haryana.\n",
            "* Reports from farmer organizations and human rights groups documenting the protests and police response.\n",
            "\n",
            "* **Water Cannons in Haryana:**\n",
            "    * In February 2023, reports emerged of police using water cannons to disperse farmers protesting in Haryana.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Farmers intensify protests, water cannons used to stop congress activists from entering haryana.'.\n",
            "Claim: Farmers intensify protests, water cannons used to stop congress activists from entering haryana.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the supporting information provided, including news articles and reports from farmer organizations and human rights groups, confirms that police used water cannons to disperse farmers protesting in haryana in february 2023, which supports the claim.\n",
            "Actual Justification: farmers intensified their protests, and water cannons were used by the police to prevent congress activists from entering haryana during the ongoing demonstrations, as reported by *indian express*.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb861e6a9edc16c6765ee\n",
            "Found 3 documents.\n",
            "['FAKE', '', 'The claim is likely fictional or sensationalized as there is no evidence of a specific incident or video supporting the claim, and the provided information describes a different incident altogether, which is the arrest of four individuals for stealing motorcycles in Rajkot.']\n",
            "Claim #4893\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I'm sorry, but I cannot provide supporting documents for the claim \"Watch brave girl fights off 3 bike-borne snatchers in Punjab\" as it appears to be a fictional scenario or a sensationalized news\n",
            "\n",
            "The news you provided describes an incident where four individuals were arrested for allegedly stealing 31 motorcycles in Rajkot. Here are the key points:\n",
            "\n",
            "Recent Events While I cannot confirm a specific video its possible that such a protest has taken place in Punjab recently.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Watch brave girl fights off 3 bike-borne snatchers in punjab.'.\n",
            "Claim: Watch brave girl fights off 3 bike-borne snatchers in punjab.\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is likely fictional or sensationalized as there is no evidence of a specific incident or video supporting the claim, and the provided information describes a different incident altogether, which is the arrest of four individuals for stealing motorcycles in rajkot.\n",
            "Actual Justification: the claim is accurate as per the article from *times now news*, which reports that a brave girl in punjab successfully fought off three bike-borne snatchers who attempted to steal her bag.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb864e6a9edc16c6765ef\n",
            "Found 18 documents.\n",
            "['TRUE', '', 'The justification is based on the provided sources, which confirm that the Supreme Court will deliver a verdict on Tuesday on pleas seeking a court-monitored probe in the Hathras gang-rape case. The Indian Express article states that the SC will hear the pleas, while The Hindu article specifically mentions that the SC will deliver a verdict on Tuesday.']\n",
            "Claim #4894\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "To support the claim \"Hathras case: SC to deliver verdict on Tuesday on pleas seeking court-monitored probe,\" you can refer to several sources, including news articles, court statements, and official\n",
            "\n",
            "- [The Indian Express - SC to hear pleas seeking court-monitored probe in Hathras gang-rape case on\n",
            "\n",
            "- [The Hindu - Hathras gang-rape: SC to deliver verdict on Tuesday](https://www.thehindu.com/news/national/hathras-gang-rape-sc-to-deliver-verdict-on-tuesday/article33379768.ece)\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Hathras case: sc to deliver verdict on tuesday on pleas seeking court-monitored probe.'.\n",
            "Claim: Hathras case: sc to deliver verdict on tuesday on pleas seeking court-monitored probe.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is based on the provided sources, which confirm that the supreme court will deliver a verdict on tuesday on pleas seeking a court-monitored probe in the hathras gang-rape case. the indian express article states that the sc will hear the pleas, while the hindu article specifically mentions that the sc will deliver a verdict on tuesday.\n",
            "Actual Justification: the claim is accurate as the supreme court of india was scheduled to deliver a verdict on the pleas seeking a court-monitored investigation into the hathras case, as confirmed by the article.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb869e6a9edc16c6765f0\n",
            "Found 5 documents.\n",
            "['TRUE', '', 'The justification is that the provided context, including the press release, confirms that Indian Railways is resuming concessions in ticket pricing for senior citizens, effective July 1, 2023, which matches the claim. The provided press release also supports this claim, as it has the subject \"Indian Railways Resumes Concessions for Senior Citizens\".']\n",
            "Claim #4895\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you've provided a statement about upcoming changes in Indian Railways' policies. Here's a breakdown of the key points:\n",
            "\n",
            "Indian Railways is pleased to announce that it will resume concessions in ticket pricing for senior citizens, effective July 1, 2023. This decision reflects our commitment to supporting the elderly\n",
            "\n",
            "**Press Release:**\n",
            "\n",
            "* **Date:** [Insert Date]\n",
            "* **Subject:** Indian Railways Resumes Concessions for Senior Citizens\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Indian Railways is going to implement 10 new rules from July 1, 2021. These include confirmed tickets in Suvidha Express, paperless ticketing facilities for Rajdhani and Shatabdi trains, and tickets in regional languages.'.\n",
            "Claim: Indian Railways is going to implement 10 new rules from July 1, 2021. These include confirmed tickets in Suvidha Express, paperless ticketing facilities for Rajdhani and Shatabdi trains, and tickets in regional languages.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided context, including the press release, confirms that indian railways is resuming concessions in ticket pricing for senior citizens, effective july 1, 2023, which matches the claim. the provided press release also supports this claim, as it has the subject \"indian railways resumes concessions for senior citizens\".\n",
            "Actual Justification: the claim is false as there is no official notification from indian railways about the implementation of such rules from july 1, 2021. the post is a misrepresentation of old announcements and has been debunked by official sources.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb86de6a9edc16c6765f1\n",
            "Found 16 documents.\n",
            "['TRUE', 'The report suggests that countries like India could potentially benefit from the US-China trade war, implying that India as a GSP (Generalized System of Preferences) country may benefit from the situation, as mentioned in the provided context.']\n",
            "Claim #4896\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The report you mentioned suggests that countries like India could potentially benefit from the US-China trade war. Here's a breakdown of the potential implications:\n",
            "\n",
            "**Benefits for India:**\n",
            "\n",
            "While the report suggests potential benefits for India, it's essential to approach this situation with caution. The trade war's complexities and potential ripple effects on the global economy mean\n",
            "\n",
            "* **Reciprocal Tariffs:** While India might gain from the US-China trade war, it's important to remember that the situation is complex. India could face reciprocal tariffs from China if it increases\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'GSP countries like india to benefit from US trade war with china, report'.\n",
            "Claim: GSP countries like india to benefit from US trade war with china, report\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the report suggests that countries like india could potentially benefit from the us-china trade war, implying that india as a gsp (generalized system of preferences) country may benefit from the situation, as mentioned in the provided context.\n",
            "Actual Justification: a report indicates that countries under the generalized system of preferences (gsp), such as india, are expected to benefit from the us-china trade war as it creates opportunities for these countries to increase their exports to the us.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb871e6a9edc16c6765f2\n",
            "Found 21 documents.\n",
            "['TRUE', '', 'The given context does not explicitly state that the new road has already been opened, but it does provide supporting points and documents to demonstrate how the new road in the Nathu La sector will bolster defense capabilities. The focus is on the potential impact of the road, rather than its current status.']\n",
            "Claim #4897\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can provide some supporting points and documents for the claim that a new road in the Nathu La sector will bolster defense. Here's a breakdown:\n",
            "\n",
            "**Supporting Documents and Points:**\n",
            "\n",
            "* Include maps showing the Nathu La sector, its strategic importance, and the new road's location. This visual representation will help illustrate the road's impact on defense capabilities.\n",
            "\n",
            "* Provide a brief historical overview of the Nathu La sector, including past conflicts, border skirmishes, and any significant events related to the area. This context will help readers understand\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'New road in nathu la sector opened, will bolster defence.'.\n",
            "Claim: New road in nathu la sector opened, will bolster defence.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given context does not explicitly state that the new road has already been opened, but it does provide supporting points and documents to demonstrate how the new road in the nathu la sector will bolster defense capabilities. the focus is on the potential impact of the road, rather than its current status.\n",
            "Actual Justification: the claim is accurate as per the article, which reports that a new road in the nathu la sector was inaugurated to enhance defence logistics and bolster security in the region.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb872e6a9edc16c6765f3\n",
            "Found 10 documents.\n",
            "['TRUE', 'The claim states that the former MLA is running for office again in the Jharkhand polls, and that he hired an assassin to target a rival political figure, who is the son of a rival political figure he got killed. This information is provided in the given documents, specifically in the \"Up Against\" and \"Assassin He Hired\" sections.']\n",
            "Claim #4898\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Up Against:** This person is running for office again in the Jharkhand polls.\n",
            "* **Assassin He Hired:** The former MLA is accused of hiring an assassin to target a rival political figure.\n",
            "\n",
            "* **Rival He Got Killed:** The assassin was hired to kill the son of a rival political figure, who was also an opponent of the former MLA.\n",
            "\n",
            "This incident highlights the challenges and risks faced by political leaders and activists in Jharkhand and the potential for violence in the region. It also underscores the importance of ensuring\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'In jharkhand polls, ex-mla is up against assassin he hired, son of rival he got killed'.\n",
            "Claim: In jharkhand polls, ex-mla is up against assassin he hired, son of rival he got killed\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim states that the former mla is running for office again in the jharkhand polls, and that he hired an assassin to target a rival political figure, who is the son of a rival political figure he got killed. this information is provided in the given documents, specifically in the \"up against\" and \"assassin he hired\" sections.\n",
            "Actual Justification: the article discusses the dramatic political contest in jharkhand, where a former mla is contesting against the son of a man he allegedly hired to kill a political rival.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb874e6a9edc16c6765f4\n",
            "Found 14 documents.\n",
            "['TRUE', '', 'The justification is that the provided context mentions \"The scenario you described is a concerning and potentially dangerous behavior that some students in Alabama have been engaging in during the COVID-19 pandemic. The idea of hosting parties to see who is spreading COVID-19.\" This sentence explicitly states that students in Alabama have been engaging in this behavior, which is the same as the claim being verified.']\n",
            "Claim #4899\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The scenario you described is a concerning and potentially dangerous behavior that some students in Alabama have been engaging in during the COVID-19 pandemic. The idea of hosting parties to see who\n",
            "\n",
            "spreading COVID-19.\n",
            "\n",
            "This statement suggests that a significant number of students or staff members at a school were diagnosed with COVID-19 after the school resumed in-person learning. This could be a cause for concern,\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Students in Alabama, United States, throwing 'COVID-19' parties to see who gets infected first.'.\n",
            "Claim: Students in Alabama, United States, throwing 'COVID-19' parties to see who gets infected first.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided context mentions \"the scenario you described is a concerning and potentially dangerous behavior that some students in alabama have been engaging in during the covid-19 pandemic. the idea of hosting parties to see who is spreading covid-19.\" this sentence explicitly states that students in alabama have been engaging in this behavior, which is the same as the claim being verified.\n",
            "Actual Justification: the claim about college students in alabama throwing 'covid-19' parties is based on a misunderstanding of the image. while such parties have been reported, the specific picture in question does not relate to these events.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb876e6a9edc16c6765f5\n",
            "Found 14 documents.\n",
            "['TRUE', 'The claim is supported by the expert analysis of the video, which confirms the identity of the man as ABVP worker Bharat Sharma and his actions, including hitting a man in the video.']\n",
            "Claim #4900\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I understand youre looking for supporting documents for the claim that a man in both civil clothes and riot armor is an ABVP worker named Bharat Sharma and that he hits a man in a video. However as an\n",
            "\n",
            "I understand youre looking for supporting documents for the claim that a man in both civil clothes and riot armor is an ABVP worker named Bharat Sharma and that he hits a man in a video. However as an\n",
            "\n",
            "Video analysis Expert analysis of the video showing the man in both civil clothes and riot armor confirming his identity and actions.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Man in civil clothes and riot armour is ABVP worker Bharat Sharma. He is also seen hitting a man in the video.'.\n",
            "Claim: Man in civil clothes and riot armour is ABVP worker Bharat Sharma. He is also seen hitting a man in the video.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the expert analysis of the video, which confirms the identity of the man as abvp worker bharat sharma and his actions, including hitting a man in the video.\n",
            "Actual Justification: the man in riot armor and civil clothes is not bharat sharma. the person shown is a delhi police constable, not associated with abvp.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb879e6a9edc16c6765f6\n",
            "Found 27 documents.\n",
            "['TRUE', '', \"The given claim is supported by the context, which mentions Adani Agri Logistics Ltd.'s decision to set up grain silos in the region, and the availability of publications and communications that might mention the company's involvement in Punjab.\"]\n",
            "Claim #4901\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Adani Agri Logistics Ltd.s decision to set up grain silos in the region.\n",
            "\n",
            "publications. Look for any statements or press releases mentioning the construction of grain silos in Punjab.\n",
            "\n",
            "communications that might mention Adani Agri Logistics Ltd. or their involvement in Punjab.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Adani Agri Logistics Ltd. is setting up grain silos in Punjab after three farm bills were passed in the parliament.'.\n",
            "Claim: Adani Agri Logistics Ltd. is setting up grain silos in Punjab after three farm bills were passed in the parliament.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given claim is supported by the context, which mentions adani agri logistics ltd.'s decision to set up grain silos in the region, and the availability of publications and communications that might mention the company's involvement in punjab.\n",
            "Actual Justification: the claim is false. adani agri logistics ltd. was not setting up grain silos in punjab immediately after the passing of the farm bills. the plan for the grain storage facility was initiated before the bills were passed, and the company was already working on its projects in the state well in advance. the claim misrepresents the timeline of events.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb87ee6a9edc16c6765f7\n",
            "Found 17 documents.\n",
            "['TRUE', 'The justification is that the passage states \"When the market price of a crop approaches or even surpasses the MSP, farmers often adopt a \\'wait and watch\\' strategy...\" which directly relates to the scenario described in the claim, where soyabean price inches closer to MSP.']\n",
            "Claim #4902\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The scenario you've described is a common challenge in agricultural markets, particularly in regions where Minimum Support Price (MSP) is set for crops like soyabean. When the market price of a crop\n",
            "\n",
            "approaches or even surpasses the MSP, farmers often adopt a \"wait and watch\" strategy, which can have several implications:\n",
            "\n",
            "demanding better prices for their produce, loan waivers, and a minimum support price (MSP) for crops. In the midst of this protest, neighbours and local communities have stepped in to support the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'As soyabean price inches closer to MSP, farmers follow 'wait & watch' policy to offload their product'.\n",
            "Claim: As soyabean price inches closer to MSP, farmers follow 'wait & watch' policy to offload their product\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the passage states \"when the market price of a crop approaches or even surpasses the msp, farmers often adopt a 'wait and watch' strategy...\" which directly relates to the scenario described in the claim, where soyabean price inches closer to msp.\n",
            "Actual Justification: the claim that farmers are following a 'wait & watch' policy as soybean prices inch closer to the minimum support price (msp) is true. according to the indian express, soybean prices have been fluctuating and are nearing the msp of rs 4,892 per quintal. farmers are adopting a cautious approach, holding back their produce in anticipation of better prices. this strategy is influenced by the recent approval of soybean procurement at msp by the central government, which has given farmers hope for improved market rates.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb881e6a9edc16c6765f8\n",
            "Found 8 documents.\n",
            "['TRUE', '', 'The justification is that the claim states \"The RBI has not yet announced any specific plans to issue a ₹ 7 coin honouring Dhoni\", which implies that the RBI has not made any official announcement about issuing a coin honoring Dhoni, making the original claim false.']\n",
            "Claim #4903\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **The RBI has not yet announced any specific plans to issue a ₹ 7 coin honouring Dhoni.** However, given his significant contributions to Indian cricket and the RBI's track record of issuing\n",
            "\n",
            "* **The Reserve Bank of India (RBI) has a history of issuing commemorative coins to honour significant individuals and events.** They have issued coins for various occasions, including national\n",
            "\n",
            "The question you're referring to pertains to the Financial Sector Reforms and the Reserve Bank of India (RBI) Act. The specific mention of \"Section 7\" of the RBI Act is crucial in understanding the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'The Reserve Bank of India (RBI) is set to issue a ₹ 7 coin honouring cricketer Mahendra Singh Dhoni for his contributions to Indian cricket.'.\n",
            "Claim: The Reserve Bank of India (RBI) is set to issue a ₹ 7 coin honouring cricketer Mahendra Singh Dhoni for his contributions to Indian cricket.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claim states \"the rbi has not yet announced any specific plans to issue a ₹ 7 coin honouring dhoni\", which implies that the rbi has not made any official announcement about issuing a coin honoring dhoni, making the original claim false.\n",
            "Actual Justification: the article confirms that the reserve bank of india (rbi) has not issued or announced a ₹ 7 coin honouring cricketer mahendra singh dhoni. the claim is false and misleading.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb884e6a9edc16c6765f9\n",
            "Found 4 documents.\n",
            "['TRUE', \"The claim is accurate because the provided text mentions a protest in Islamabad, Pakistan, not Faizabad, and the context is about Imran Khan's arrest, not his recent arrest in the Toshakhana case.\"]\n",
            "Claim #4904\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "If you are interested in learning more about the protest in Faizabad, Pakistan, after Imran Khan's arrest, I can offer a general overview of the context and provide some relevant information.\n",
            "\n",
            "The text you provided describes a protest in Islamabad, Pakistan, where a large crowd from Khyber Pakhtunkhwa is demonstrating against the arrest of Imran Khan. This event highlights the political\n",
            "\n",
            "former Prime Minister Imran Khan. During these protests, there were instances of arrests and detentions of PTI supporters and leaders by the Pakistani authorities, including the army.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Protest in Faizabad, Pakistan, after Imran Khan's recent arrest in the Toshakhana case.'.\n",
            "Claim: Protest in Faizabad, Pakistan, after Imran Khan's recent arrest in the Toshakhana case.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is accurate because the provided text mentions a protest in islamabad, pakistan, not faizabad, and the context is about imran khan's arrest, not his recent arrest in the toshakhana case.\n",
            "Actual Justification: the claim is false. the video being circulated is from november 4, 2022, and shows a protest that took place a day after imran khan was shot. it is unrelated to his recent arrest in the toshakhana case.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb886e6a9edc16c6765fa\n",
            "Found 16 documents.\n",
            "['FAKE', '', 'The provided text does not mention a police raid in Madhya Pradesh, nor does it mention 15 couples being caught in compromising positions. The text actually talks about an incident in Uttar Pradesh involving a Muslim man and a Hindu woman who eloped, and highlights caste discrimination and gender inequality.']\n",
            "Claim #4905\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "assaults on Hindu residents.\n",
            "\n",
            "This incident, which involves a violent attack on a woman by upper caste men in Uttar Pradesh, India, highlights the deep-rooted caste discrimination and gender inequality prevalent in the region.\n",
            "\n",
            "The specific incident you mentioned involves a Muslim man who eloped with a Hindu woman in UP last year. Here are some key points to consider:\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'During a police raid in Madhya Pradesh, 15 couples were caught in compromising positions. All the men were Muslim and all the women were Hindu.'.\n",
            "Claim: During a police raid in Madhya Pradesh, 15 couples were caught in compromising positions. All the men were Muslim and all the women were Hindu.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the provided text does not mention a police raid in madhya pradesh, nor does it mention 15 couples being caught in compromising positions. the text actually talks about an incident in uttar pradesh involving a muslim man and a hindu woman who eloped, and highlights caste discrimination and gender inequality.\n",
            "Actual Justification: the video that went viral is not from a police raid in madhya pradesh. it is from a raid in agra, uttar pradesh. additionally, the claim of all the men being muslim and all the women being hindu is false. the video was misattributed and given a false communal angle.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb888e6a9edc16c6765fb\n",
            "Found 11 documents.\n",
            "['TRUE', '', \"The claim is supported by the news article from a reputable source, which confirms the installation of a Jesus Christ idol at a Ganesh temple in Bengaluru's Thyagaraja Nagar. The article also provides context, stating that the installation of religious idols is a common practice in India and should be respected.\"]\n",
            "Claim #4906\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **News Article:** A recent article published in [Reputable News Source] on [Date] titled \" Ganesh Temple in Bengaluru Installs Jesus Christ Idol\" confirms the installation. The article includes\n",
            "\n",
            "The installation of a religious idol, such as Lord Ganesha, is a common practice in many parts of India and should be respected.\n",
            "\n",
            "* **Temple Website:** The official website of the [Temple Name] in Thyagaraja Nagar could provide information about the idol installation, including a statement from the temple administration.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A Ganesh temple in Bengaluru’s Thyagaraja Nagar has recently installed an idol of Jesus Christ on its external structure.'.\n",
            "Claim: A Ganesh temple in Bengaluru’s Thyagaraja Nagar has recently installed an idol of Jesus Christ on its external structure.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the news article from a reputable source, which confirms the installation of a jesus christ idol at a ganesh temple in bengaluru's thyagaraja nagar. the article also provides context, stating that the installation of religious idols is a common practice in india and should be respected.\n",
            "Actual Justification: the claim is false. the temple did not install an idol of jesus christ on its external structure. instead, the temple displayed a small statue of jesus christ as part of a message of unity among religions. the image was misinterpreted and spread out of context, leading to confusion.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb88ce6a9edc16c6765fc\n",
            "Found 11 documents.\n",
            "['TRUE', '', 'The claim is true because according to the provided documents, Mukesh Singh was indeed a convict who was sentenced to death and was also a victim of sexual abuse while being held in Tihar Jail.']\n",
            "Claim #4907\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Mukesh Singh was a convict who was sentenced to death for a crime. He was also a victim of sexual abuse while being held in Tihar Jail, which is a prison in New Delhi, India. The incident involving\n",
            "\n",
            "the sexual abuse of Mukesh Singh is part of a broader issue of violence and abuse in Indian prisons, particularly affecting vulnerable inmates.\n",
            "\n",
            "and led to significant discussions about women's safety and the justice system in India. If Mukesh Singh is being referred to as a \"Nirbhaya convict,\" it could imply that he was also a victim of a\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Mukesh Singh, was sentenced to death but sexually abused in tihar, nirbhaya convict mukesh to sc'.\n",
            "Claim: Mukesh Singh, was sentenced to death but sexually abused in tihar, nirbhaya convict mukesh to sc\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is true because according to the provided documents, mukesh singh was indeed a convict who was sentenced to death and was also a victim of sexual abuse while being held in tihar jail.\n",
            "Actual Justification: mukesh singh, one of the convicts in the nirbhaya case, claimed he was subjected to sexual abuse while in tihar jail, despite being sentenced to death for his crimes.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb88fe6a9edc16c6765fd\n",
            "Found 6 documents.\n",
            "['TRUE', 'The justification is that the original claim states \"I cannot provide supporting documents for the claim\", implying that the information is not verifiable and may be false, whereas the subsequent statements are based on actual events and information provided, which does not mention anything about Swapna Suresh\\'s religion or real name being Mumtaz Ismail.']\n",
            "Claim #4908\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Swapna Suresh, a key accused in the Kerala gold smuggling case, is actually a Muslim and her real name is Mumtaz Ismail.\n",
            "\n",
            "It seems like you've provided a statement or a piece of information about Swapna Suresh, a key accused in the Kerala gold smuggling case, attending an event related to Chief Minister Pinarayi\n",
            "\n",
            "Yes, that's correct. Swapna Suresh, the prime accused in the Kerala gold smuggling case, allegedly threatened to expose certain ministers through a Facebook post. This information is based on the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Swapna Suresh, key accused in the Kerala gold smuggling case, is actually a Muslim and her real name is Mumtaz Ismail.'.\n",
            "Claim: Swapna Suresh, key accused in the Kerala gold smuggling case, is actually a Muslim and her real name is Mumtaz Ismail.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the original claim states \"i cannot provide supporting documents for the claim\", implying that the information is not verifiable and may be false, whereas the subsequent statements are based on actual events and information provided, which does not mention anything about swapna suresh's religion or real name being mumtaz ismail.\n",
            "Actual Justification: the claim is false. swapna suresh's real name is not mumtaz ismail. she is not a muslim as claimed. her actual name is swapna suresh, and she is a hindu by religion. the social media claims about her identity are misleading.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb892e6a9edc16c6765fe\n",
            "Found 18 documents.\n",
            "['TRUE', '', 'The claim \"City\\'s Tally Crosses 94k Mark\" indicates that the total number of confirmed COVID-19 cases in Delhi has surpassed 94,000, which is a true statement.']\n",
            "Claim #4909\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **City's Tally Crosses 94k Mark:** This indicates that the total number of confirmed COVID-19 cases in Delhi has surpassed 94,000.\n",
            "\n",
            "* **Government Health Reports:** Check official websites of the Delhi government or the Indian Ministry of Health for daily or weekly COVID-19 updates, including testing data and case counts.\n",
            "\n",
            "* **Total Cases:** India has recorded over 70 lakh (700,000) COVID-19 cases. This number represents the cumulative total of confirmed infections since the pandemic began.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Delhi needs to be prepared for 15,000 covid cases per day during winter season: report.'.\n",
            "Claim: Delhi needs to be prepared for 15,000 covid cases per day during winter season: report.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim \"city's tally crosses 94k mark\" indicates that the total number of confirmed covid-19 cases in delhi has surpassed 94,000, which is a true statement.\n",
            "Actual Justification: the justification for this claim is based on a report by the national centre for disease control (ncdc). the report highlights several factors contributing to the expected surge in covid-19 cases during the winter season: winter-related respiratory problems, large influx of patients from outside, and festive gatherings.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb893e6a9edc16c6765ff\n",
            "Found 11 documents.\n",
            "['TRUE', 'The justification is that the text does not explicitly state that the claim is false, and it provides information about the possibility of finding ancient mummies in Mongolia, which implies that it is not impossible to find a mummified monk. Additionally, the text notes that the existence of the claimed mummy is \"not a fact\", but it does not provide evidence to disprove the claim.']\n",
            "Claim #4910\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The description you provided is a fascinating and somewhat eerie image. It's important to note that the existence of a 100-year-old mummified monk in Mongolia with a \"smiling\" expression is not a\n",
            "\n",
            "If such a mummified monk were found, it would likely be studied extensively by anthropologists, historians, and archaeologists to determine the cause of death, the individual's background, and the\n",
            "\n",
            "In Mongolia, which has a rich history and cultural heritage, the presence of ancient mummies is not uncommon. The country's harsh climate and arid conditions have often preserved human remains,\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A 100-year-old 'smiling' mummified monk in Mongolia.'.\n",
            "Claim: A 100-year-old 'smiling' mummified monk in Mongolia.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the text does not explicitly state that the claim is false, and it provides information about the possibility of finding ancient mummies in mongolia, which implies that it is not impossible to find a mummified monk. additionally, the text notes that the existence of the claimed mummy is \"not a fact\", but it does not provide evidence to disprove the claim.\n",
            "Actual Justification: the claim is false. the image is of a mummified monk, but it is not 100 years old. the monk is part of a buddhist tradition where monks are preserved after death. the smiling appearance is a result of the preservation process and not the monk’s actual expression.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb89be6a9edc16c676600\n",
            "Found 96 documents.\n",
            "['TRUE', 'The justification is based on the provided context, which states that \"future monuments should embrace inclusivity and diversity\" and that future monuments should be \"inclusive and representative of a broader spectrum of perspectives\", implying that prioritizing inclusivity and diversity is a key aspect of designing future monuments.']\n",
            "Claim #4911\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Here are some supporting documents and arguments for the claim that future monuments should embrace inclusivity and diversity\n",
            "\n",
            "Here are some supporting documents and arguments for the claim that future monuments should embrace inclusivity and diversity\n",
            "\n",
            "future monuments are inclusive and representative of a broader spectrum of perspectives.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Future monuments should prioritize inclusivity and diversity by representing a broader range of histories and perspectives rather than focusing solely on singular figures or events.'.\n",
            "Claim: Future monuments should prioritize inclusivity and diversity by representing a broader range of histories and perspectives rather than focusing solely on singular figures or events.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is based on the provided context, which states that \"future monuments should embrace inclusivity and diversity\" and that future monuments should be \"inclusive and representative of a broader spectrum of perspectives\", implying that prioritizing inclusivity and diversity is a key aspect of designing future monuments.\n",
            "Actual Justification: the article from *cnn* discusses the concept of future monuments, featuring an exploration of their potential designs and purposes by artist hank willis thomas.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb89fe6a9edc16c676601\n",
            "Found 38 documents.\n",
            "['TRUE', '', 'The claim cannot be verified as there are no supporting documents provided, and the documents explicitly state that they cannot provide supporting documents for the claim.']\n",
            "Claim #4912\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The claim that Afghan women are being auctioned as sex slaves on the streets is deeply disturbing and potentially true as there have been reports of human trafficking and genderbased violence in\n",
            "\n",
            "I cannot provide supporting documents for the claim that Afghan women are being auctioned as sex slaves on the streets.\n",
            "\n",
            "I cannot provide supporting documents for the claim that women are being auctioned on the streets of Afghanistan after the Taliban took over the country.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Afghan women are being auctioned as sex slaves on the streets.'.\n",
            "Claim: Afghan women are being auctioned as sex slaves on the streets.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim cannot be verified as there are no supporting documents provided, and the documents explicitly state that they cannot provide supporting documents for the claim.\n",
            "Actual Justification: the video being circulated does not show afghan women being auctioned as sex slaves. it is actually a mock video created to resemble a scene from isis's actions in the past. the video is unrelated to the current situation in afghanistan and has been deliberately misrepresented.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8a5e6a9edc16c676602\n",
            "Found 6 documents.\n",
            "['TRUE', '', 'The claim states that a Navy official was killed in a car crash, and 2 colleagues were hospitalized in Uttar Pradesh. However, the provided documents reveal that the incident involved an aircraft crash, not a car crash. Additionally, the \"colleagues\" mentioned in the claim are actually a trainee pilot and an instructor, who were both killed in the crash, not hospitalized.']\n",
            "Claim #4913\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It sounds like you're describing a tragic incident involving a Navy official and their colleagues in Uttar Pradesh, India. I can provide some general information about car crashes and their impact,\n",
            "\n",
            "Car crashes can have devastating consequences, and the loss of a Navy official and the injuries sustained by their colleagues are deeply concerning. Such incidents often lead to investigations to\n",
            "\n",
            "**Casualties:**\n",
            "- Both occupants of the aircraft, a trainee pilot and an instructor, were killed in the crash.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A Navy official was killed in a car crash, and 2 colleagues were hospitalized in Uttar Pradesh.'.\n",
            "Claim: A Navy official was killed in a car crash, and 2 colleagues were hospitalized in Uttar Pradesh.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim states that a navy official was killed in a car crash, and 2 colleagues were hospitalized in uttar pradesh. however, the provided documents reveal that the incident involved an aircraft crash, not a car crash. additionally, the \"colleagues\" mentioned in the claim are actually a trainee pilot and an instructor, who were both killed in the crash, not hospitalized.\n",
            "Actual Justification: the article reports that a navy official lost his life in a car accident, while two of his colleagues sustained injuries and were hospitalized in uttar pradesh.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8a7e6a9edc16c676603\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The justification is based on the supporting information provided, which mentions a quote from a senior police official stating that the Delhi Police are committed to protecting the public and bringing fraudsters to justice, but there is no mention of the Delhi High Court instructing the police to refrain from using Urdu and Persian words in FIRs. The actual article \"Delhi HC tells police to avoid Urdu, Persian words in FIRs\" is a real news article, but it is not supported by the provided information.']\n",
            "Claim #4914\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "**Claim:** Delhi High Court instructs police to refrain from using Urdu and Persian words in First Information Reports (FIRs).\n",
            "\n",
            "**Supporting Information:**\n",
            "\n",
            "\"The Delhi Police are committed to protecting the interests of the public and bringing fraudsters to justice,\" said [Name of senior police official]. \"We urge anyone who may have fallen victim to\n",
            "\n",
            "Interview TranscriptsExpert Opinions\n",
            "    Transcripts of interviews with Delhi Police officials or government representatives discussing the security enhancements.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Delhi hc tells police to avoid urdu, persian words in FIRs'.\n",
            "Claim: Delhi hc tells police to avoid urdu, persian words in FIRs\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is based on the supporting information provided, which mentions a quote from a senior police official stating that the delhi police are committed to protecting the public and bringing fraudsters to justice, but there is no mention of the delhi high court instructing the police to refrain from using urdu and persian words in firs. the actual article \"delhi hc tells police to avoid urdu, persian words in firs\" is a real news article, but it is not supported by the provided information.\n",
            "Actual Justification: the delhi high court has directed the police to avoid using urdu and persian terms in firs, emphasizing the need for clarity and simplicity in legal documents.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8abe6a9edc16c676604\n",
            "Found 38 documents.\n",
            "['TRUE', 'The claim is supported by the fact that the person responding to the inquiry acknowledges the concern about children being abducted in India and provides steps to take to help, indicating that the issue is real and not fictional.']\n",
            "Claim #4915\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I understand youre seeking information on the claim that children are being abducted in India. However I cannot provide specific documents or evidence as I dont have access to realtime data or\n",
            "\n",
            "I understand youre seeking information on the claim that children are being abducted in India. However I cannot provide specific documents or evidence as I dont have access to realtime data or\n",
            "\n",
            "I understand you're concerned about the recent reports of children being abducted in India. It's a serious issue that requires immediate attention and action. Here are some steps you can take to help\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'children are being abducted in India.'.\n",
            "Claim: children are being abducted in India.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the fact that the person responding to the inquiry acknowledges the concern about children being abducted in india and provides steps to take to help, indicating that the issue is real and not fictional.\n",
            "Actual Justification: the claim that children are being abducted in india is false. according to boom, the rumours about child kidnappings in india are being spread using an edited video originally created to raise awareness about missing children in karachi, pakistan, and an unrelated image from a chemical attack in syria. these materials have been misused on social media to create panic and spread false information about child abductions in india.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8ace6a9edc16c676605\n",
            "Found 12 documents.\n",
            "['TRUE', \"The justification is that the provided context mentions the impact of the conflict on children in Gaza, including the challenges they face in accessing education and the mental health effects, which suggests that a young child's perspective on the situation is being discussed.\"]\n",
            "Claim #4916\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I understand you're looking for a narrative or document that represents a young child's perspective on the impact of the Israel-Hamas war on Gaza. However, I cannot provide a specific document or\n",
            "\n",
            "2. **Context of the Conflict**: The conflict between Israel and Hamas is a complex and often violent situation. Children are often caught in the crossfire, facing threats to their safety and\n",
            "\n",
            "The impact of this conflict extends beyond the immediate loss of life. Children in Gaza face challenges in accessing education, with schools damaged or destroyed, and the mental health of the young\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A young child in gaza narrating how hard life is amid the ongoing israel-hamas war.'.\n",
            "Claim: A young child in gaza narrating how hard life is amid the ongoing israel-hamas war.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided context mentions the impact of the conflict on children in gaza, including the challenges they face in accessing education and the mental health effects, which suggests that a young child's perspective on the situation is being discussed.\n",
            "Actual Justification: the video is from august 2020 and shows a palestinian girl crying as her family’s home was demolished by israeli forces in jerusalem. it is not related to any recent events.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8afe6a9edc16c676606\n",
            "Found 8 documents.\n",
            "['TRUE', 'The claim is true because the provided information does not contradict the claim. In fact, the text states that \"On May 18, if there was an incident of RCB fans attacking CSK fans after a match, it would likely have been a significant event with potential consequences.\" This implies that the incident did occur, and the claim is supported by the text.']\n",
            "Claim #4917\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that RCB fans were beaten up by CSK fans during the IPL match held at Chinnaswamy Stadium in Bengaluru on April 17. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "On May 18, if there was an incident of RCB fans attacking CSK fans after a match, it would likely have been a significant event with potential consequences. Such actions can lead to legal and safety\n",
            "\n",
            "particularly between the Royal Challengers Bangalore (RCB) and Chennai Super Kings (CSK). These two teams have a long-standing rivalry, and their matches often attract a lot of attention and passion\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'RCB fans getting beaten up by CSK fans during the IPL match held at Chinnaswamy Stadium in Bengaluru on April 17.'.\n",
            "Claim: RCB fans getting beaten up by CSK fans during the IPL match held at Chinnaswamy Stadium in Bengaluru on April 17.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is true because the provided information does not contradict the claim. in fact, the text states that \"on may 18, if there was an incident of rcb fans attacking csk fans after a match, it would likely have been a significant event with potential consequences.\" this implies that the incident did occur, and the claim is supported by the text.\n",
            "Actual Justification: the claim is false as the video being circulated does not show rcb fans being beaten up by csk fans during the match. the video is from an unrelated football altercation and is being misrepresented. no such incident occurred during the ipl match between rcb and csk on april 17 at chinnaswamy stadium.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8b1e6a9edc16c676607\n",
            "Found 10 documents.\n",
            "['FAKE', '', 'The justification is that the claim states that documents cannot be provided to support the claim, which implies that the claim is likely false or fabricated.']\n",
            "Claim #4918\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that a man seen putting his foot on a Hindu idol is a Muslim named Mohammad Ansari.\n",
            "\n",
            "I cannot provide supporting documents for the claim that a man seen putting his foot on a Hindu idol is a Muslim named Mohammad Ansari.\n",
            "\n",
            "seen as an attempt to align himself with a historical figure who is revered by some sections of the Hindu population.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Man seen putting foot on Hindu idol is a Muslim named Mohammad Ansari.'.\n",
            "Claim: Man seen putting foot on Hindu idol is a Muslim named Mohammad Ansari.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claim states that documents cannot be provided to support the claim, which implies that the claim is likely false or fabricated.\n",
            "Actual Justification: the claim that the man seen putting his foot on a hindu idol is a muslim named mohammad ansari is false. the man in the video is not mohammad ansari, and the video itself was misrepresented with the intention of inciting communal tensions. the real identity of the man in the video remains unclear, and there is no evidence linking him to the name mohammad ansari.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8b5e6a9edc16c676608\n",
            "Found 47 documents.\n",
            "['TRUE', '', 'The justification is that the text states \"the presence of caps on property values in metro cities might restrict its overall impact\" and \"the claim highlights the potential challenges of\", implying that the caps on property values in metro cities will limit the effectiveness of the Realty Tax Sop, making it \"unlikely to significantly impact\" metro cities.']\n",
            "Claim #4919\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can provide some context and supporting information for the claim that a Realty Tax SOP Standard Operating Procedure is unlikely to significantly impact metro cities due to caps. Here are a few\n",
            "\n",
            "I can provide some context and supporting information for the claim that a Realty Tax Sop a tax relief measure is unlikely to significantly impact metro cities due to caps. Here are a few points to\n",
            "\n",
            "While a Realty Tax Sop could provide some benefits the presence of caps on property values in metro cities might restrict its overall impact. This claim highlights the potential challenges of\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Realty tax sop is unlikely to make a dent in metro cities due to caps'.\n",
            "Claim: Realty tax sop is unlikely to make a dent in metro cities due to caps\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the text states \"the presence of caps on property values in metro cities might restrict its overall impact\" and \"the claim highlights the potential challenges of\", implying that the caps on property values in metro cities will limit the effectiveness of the realty tax sop, making it \"unlikely to significantly impact\" metro cities.\n",
            "Actual Justification: the claim is supported by a report from *the print*, which discusses how the realty tax sop for homebuyers is unlikely to have a significant impact in metro cities due to the implementation of caps.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8b7e6a9edc16c676609\n",
            "Found 18 documents.\n",
            "['TRUE', '', 'The justification is that the provided text does not provide evidence to support or refute the claim, but it does state that the claimant cannot provide supporting documents for the claim, which implies that the claim may be true or false, but there is no concrete evidence to verify it.']\n",
            "Claim #4920\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Hindu families converting to Islam.\n",
            "\n",
            "I cannot provide supporting documents for the claim that a specific Hindu family of four in the US converted to Islam. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that a specific Hindu family of four in the US converted to Islam. \n",
            "\n",
            "Heres why\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'This Hindu family of four in the US converted to Islam.'.\n",
            "Claim: This Hindu family of four in the US converted to Islam.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided text does not provide evidence to support or refute the claim, but it does state that the claimant cannot provide supporting documents for the claim, which implies that the claim may be true or false, but there is no concrete evidence to verify it.\n",
            "Actual Justification: the image shared online is of a german family, not a hindu family from the us, and the claim of conversion is fabricated.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8b9e6a9edc16c67660a\n",
            "Found 14 documents.\n",
            "['TRUE', \"The claim is not explicitly denied, and the person providing the information is unable to confirm or deny it, but is willing to provide factual information about the Odisha train accident and Mohammed Sharif's involvement if asked specific questions. This implies that the claim is not entirely false, but the information is not available to confirm or deny it.\"]\n",
            "Claim #4921\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Station Master Mohammed Sharif has been absconding since the Odisha train accident.\n",
            "\n",
            "I cannot provide supporting documents for the claim that Station Master Mohammed Sharif has been absconding since the Odisha train accident.\n",
            "\n",
            "If you have specific questions about the Odisha train accident or Mohammed Sharifs involvement I can try to provide factual information based on available sources. However I cannot confirm or deny\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Station master Mohammed Sharif has been absconding since the Odisha train accident.'.\n",
            "Claim: Station master Mohammed Sharif has been absconding since the Odisha train accident.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is not explicitly denied, and the person providing the information is unable to confirm or deny it, but is willing to provide factual information about the odisha train accident and mohammed sharif's involvement if asked specific questions. this implies that the claim is not entirely false, but the information is not available to confirm or deny it.\n",
            "Actual Justification: there is no credible information to suggest that station master mohammed sharif has been absconding. he was on leave at the time of the accident and has been cooperating with the investigation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8bae6a9edc16c67660b\n",
            "Found 3 documents.\n",
            "['TRUE', 'The claim is true because the documents provided mention a helicopter crash that resulted in the deaths of a bride and groom, which matches the description.']\n",
            "Claim #4922\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It sounds like you're describing a tragic incident involving a helicopter crash that resulted in the deaths of a bride and groom at a wedding ceremony. This type of event would be a devastating and\n",
            "\n",
            "The crash involved a Mil Mi-17 helicopter, which was on a routine training mission. The helicopter reportedly caught fire during the landing process, leading to the tragic outcome. The Indian Air\n",
            "\n",
            "- According to initial reports, the helicopter crashed due to a technical malfunction, but the exact cause is still under investigation.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A helicopter crash that crashed at a wedding ceremony, claiming the lives of the bride and the groom.'.\n",
            "Claim: A helicopter crash that crashed at a wedding ceremony, claiming the lives of the bride and the groom.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is true because the documents provided mention a helicopter crash that resulted in the deaths of a bride and groom, which matches the description.\n",
            "Actual Justification: the video does not show a helicopter crash at a wedding. the crash occurred before the wedding ceremony, and the bride and groom were not killed as claimed.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8bde6a9edc16c67660c\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The justification is that the text \"go back modi\" on the placard suggests a protest or demonstration against Prime Minister Narendra Modi\\'s visit to Kanyakumari, which is mentioned in the given context.']\n",
            "Claim #4923\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The woman in the photo is holding a placard that reads \"Go back Modi,\" which suggests a protest against Indian Prime Minister Narendra Modi's policies or actions. The placard is likely a form of\n",
            "\n",
            "The text \"go back modi\" on the placard suggests a protest or demonstration against Prime Minister Narendra Modi's visit to Kanyakumari. The woman is expressing her dissatisfaction or disagreement with\n",
            "\n",
            "PM Modi recalled her journey from a successful actress to a powerful political leader emphasizing her unwavering commitment to the welfare of Tamil Nadu. He mentioned her contributions to the states\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A woman in Tamil Nadu holding a placard with the text 'go back modi' amidst modi’s visit to kanyakumari.'.\n",
            "Claim: A woman in Tamil Nadu holding a placard with the text 'go back modi' amidst modi’s visit to kanyakumari.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the text \"go back modi\" on the placard suggests a protest or demonstration against prime minister narendra modi's visit to kanyakumari, which is mentioned in the given context.\n",
            "Actual Justification: the claim that this photo shows a woman in tamil nadu holding a placard with the text 'go back modi' amidst modi’s visit to kanyakumari is false. according to india today, the photo is digitally altered. the original placard read, 'india creates history. 100 crore vaccination. thank you, modi ji.' the woman in the photo is vanathi srinivasan, a bjp mla, and the image was taken in october 2021 to celebrate india's vaccination milestone.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8c0e6a9edc16c67660d\n",
            "Found 7 documents.\n",
            "['TRUE', '', 'The claim \"Bihar polls with LJP out of the equation, NDA parties get a level playing field. BJP gets 121 seats, JD(U) 122\" is true because it is based on a seat-sharing deal where BJP, JD(U), and LJP have agreed to contest on specific seats, with BJP and JD(U) contesting 17 seats each and LJP contesting 6 seats.']\n",
            "Claim #4924\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that \"Bihar polls with LJP out of the equation, NDA parties get a level playing field. BJP gets 121 seats, JD(U) 122.\" \n",
            "\n",
            "Here's why:\n",
            "\n",
            "**Claim:** BJP, JD(U) to contest on 17 seats each, LJP gets 6 in Bihar seat-sharing deal for Lok Sabha.\n",
            "\n",
            "**Supporting Documents/Evidence:**\n",
            "\n",
            "4. **JD(U) and LJP**: The Janata Dal (United) (JD(U)) and the Lok Jan Shakti Party (LJP) are regional political parties in Bihar. They have had various alliances and partnerships with the BJP in the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Bihar polls with LJP out of the equation, nda parties get level playing field. bjp gets 121 seats, jd(u) 122.'.\n",
            "Claim: Bihar polls with LJP out of the equation, nda parties get level playing field. bjp gets 121 seats, jd(u) 122.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim \"bihar polls with ljp out of the equation, nda parties get a level playing field. bjp gets 121 seats, jd(u) 122\" is true because it is based on a seat-sharing deal where bjp, jd(u), and ljp have agreed to contest on specific seats, with bjp and jd(u) contesting 17 seats each and ljp contesting 6 seats.\n",
            "Actual Justification: the seat-sharing pact between bjp and jd(u) in bihar elections led to bjp getting 121 seats and jd(u) securing 122, with ljp no longer part of the equation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8c2e6a9edc16c67660e\n",
            "Found 6 documents.\n",
            "['TRUE', 'The justification is based on the provided context, which states that the temple has a \"2,000-year-old caricature of a cyclist on its walls\", suggesting that this feature is indeed present in the temple, and not a fabrication.']\n",
            "Claim #4925\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The presence of a 2,000-year-old caricature of a cyclist on its walls is indeed remarkable. It suggests that the temple has a rich historical background and that its construction and decoration\n",
            "\n",
            "That's an interesting fact! The Panchavarnaswamy Temple, located in the town of Kanchipuram in Tamil Nadu, India, is known for its ancient architecture and carvings. The temple's walls are adorned\n",
            "\n",
            "cyclist in an ancient temple highlights the diverse and fascinating nature of Indian art and history.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Panchavarnaswamy Temple in Tamil Nadu has a 2,000-year-old caricature of a cyclist on its wall.'.\n",
            "Claim: Panchavarnaswamy Temple in Tamil Nadu has a 2,000-year-old caricature of a cyclist on its wall.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is based on the provided context, which states that the temple has a \"2,000-year-old caricature of a cyclist on its walls\", suggesting that this feature is indeed present in the temple, and not a fabrication.\n",
            "Actual Justification: the claim is false. the image circulating is not from panchavarnaswamy temple in tamil nadu. it is a photograph of a carving on a wall in a temple in thailand, not india. the cyclist depiction is a modern interpretation, not an ancient one.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8c5e6a9edc16c67660f\n",
            "Found 8 documents.\n",
            "['TRUE', '', 'The claim is supported by the provided context, which mentions the Hathras incident and the reaction of Chief Minister Adityanath, indicating that the statement is a response to the Hathras incident and the broader issue of gender-based violence in India.']\n",
            "Claim #4926\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The commitment to safety and security of women, as mentioned in the statement, is a response to the Hathras incident and the broader issue of gender-based violence in India. The statement also\n",
            "\n",
            "Pradesh, India) to safety and security of women, particularly in the context of the Hathras incident, and the reaction of Chief Minister Adityanath.\n",
            "\n",
            "Overall, the advisory issued by the central government to states regarding women's safety in the context of the Hathras outrage highlights the importance of police adhering to established norms and\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Up is committed to safety, security of women, cm adityanath amid nationwide protest against hathras incident'.\n",
            "Claim: Up is committed to safety, security of women, cm adityanath amid nationwide protest against hathras incident\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the provided context, which mentions the hathras incident and the reaction of chief minister adityanath, indicating that the statement is a response to the hathras incident and the broader issue of gender-based violence in india.\n",
            "Actual Justification: uttar pradesh chief minister yogi adityanath tweeted his commitment to the safety and security of women in the state, in response to the outrage following the hathras incident.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8c8e6a9edc16c676610\n",
            "Found 31 documents.\n",
            "['TRUE', '', 'The justification is based on the provided context, which mentions \"various news reports and military analysts\" stating that Ukrainian forces have utilized Bayraktar drones to great effect against Russian military equipment, including tanks, and provides specific examples of drone footage showing Bayraktar drones engaging Russian tanks.']\n",
            "Claim #4927\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Claim Bayraktar drones deployed by Ukrainian forces have been instrumental in taking out Russian tanks on the ground.\n",
            "\n",
            "According to various news reports and military analysts Ukrainian forces have utilized Bayraktar drones to great effect against Russian military equipment including tanks. These drones have been\n",
            "\n",
            "On multiple occasions footage and images have emerged showing Bayraktar drones engaging Russian tanks. For example in the battle of Mariupol drone footage showed a Bayraktar drone launching a\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Bayraktar drones deployed by the Ukrainian forces taking out Russian tanks on the ground.'.\n",
            "Claim: Bayraktar drones deployed by the Ukrainian forces taking out Russian tanks on the ground.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is based on the provided context, which mentions \"various news reports and military analysts\" stating that ukrainian forces have utilized bayraktar drones to great effect against russian military equipment, including tanks, and provides specific examples of drone footage showing bayraktar drones engaging russian tanks.\n",
            "Actual Justification: the video is from a past conflict between azerbaijan and armenia in 2020, not from the ukraine-russia war.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8cae6a9edc16c676611\n",
            "Found 10 documents.\n",
            "['TRUE', '', \"The justification is that the text does not provide any concrete evidence to refute the claim, and instead suggests checking official government sources or local farmers' organizations for information. This implies that the claim is plausible and may be true, but requires further verification to confirm.\"]\n",
            "Claim #4928\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim \"Returning to Punjab from Delhi border, two farmers killed, 8 injured in accident\" as I do not have access to real-time information or specific news\n",
            "\n",
            "* **Farmers' Organizations:** Contact local farmers' organizations or agricultural unions in Punjab. They may have information or reports about the accident.\n",
            "\n",
            "* **Government Sources:** Check official government websites, such as those of the Punjab government or the Ministry of Agriculture, for reports or statements related to the incident.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Returning to punjab from delhi border, two farmers killed, 8 injured in accident'.\n",
            "Claim: Returning to punjab from delhi border, two farmers killed, 8 injured in accident\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the text does not provide any concrete evidence to refute the claim, and instead suggests checking official government sources or local farmers' organizations for information. this implies that the claim is plausible and may be true, but requires further verification to confirm.\n",
            "Actual Justification: the claim that two farmers were killed and eight injured in an accident while returning to punjab from the delhi border is true. according to the indian express, the incident occurred in haryana’s karnal district when a truck hit a tractor-trolley carrying the farmers. the accident resulted in the deaths of gurpreet singh (22) and labh singh (62), both from saferal village in patiala. the injured were taken to hospitals in patiala and karnal for treatment. the accident was caused by the truck driver, who appeared to have fallen asleep behind the wheel.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8cce6a9edc16c676612\n",
            "Found 9 documents.\n",
            "['FAKE', '', 'The justification for this classification is that the original claim states \"I cannot provide supporting documents for the claim\", implying that the claim is unsubstantiated and therefore likely false.']\n",
            "Claim #4929\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that a Kenyan man ran over his wife for kicking him out of his own house in Texas.\n",
            "\n",
            "I cannot provide supporting documents for the claim that a Kenyan man ran over his wife for kicking him out of his own house in Texas.\n",
            "\n",
            "It sounds like you're describing a scenario involving a man from Kenya who was involved in an incident in Texas where he allegedly ran over his wife with a vehicle. This is a serious and tragic\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A Kenyan man running over his wife for kicking him out of his own house in Texas.'.\n",
            "Claim: A Kenyan man running over his wife for kicking him out of his own house in Texas.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification for this classification is that the original claim states \"i cannot provide supporting documents for the claim\", implying that the claim is unsubstantiated and therefore likely false.\n",
            "Actual Justification: the claim is false. the video actually shows a deadly road rage incident in texas and is not related to a kenyan man running over his wife. it is being misrepresented in the current context.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8cde6a9edc16c676613\n",
            "Found 11 documents.\n",
            "['FAKE', '', 'The justification is that the original claim is stated as \"not based on scientific\" and the subsequent text clarifies that penguin urine is not a substantial component of Antarctic glaciers, which are primarily composed of compacted snow and ice.']\n",
            "Claim #4930\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Im sorry but I cannot provide supporting documents for the claim that Nearly three per cent of the ice in the Antarctic glaciers is made of penguin urine. This claim is not based on scientific\n",
            "\n",
            "Im sorry but I cannot provide supporting documents for the claim that Nearly three per cent of the ice in the Antarctic glaciers is made of penguin urine. This claim is not based on scientific\n",
            "\n",
            "Penguins do produce a significant amount of urine but it is not a substantial component of Antarctic glaciers. Glaciers are primarily composed of compacted snow and ice and the presence of penguin\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Nearly three per cent of the ice in the Antarctic glaciers is made of penguin urine.'.\n",
            "Claim: Nearly three per cent of the ice in the Antarctic glaciers is made of penguin urine.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the original claim is stated as \"not based on scientific\" and the subsequent text clarifies that penguin urine is not a substantial component of antarctic glaciers, which are primarily composed of compacted snow and ice.\n",
            "Actual Justification: penguins cannot urinate in the conventional sense. they excrete waste in the form of uric acid, which is a solid. therefore, the claim that penguin urine makes up three percent of antarctic ice is scientifically inaccurate.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8d0e6a9edc16c676614\n",
            "Found 13 documents.\n",
            "['FAKE', '', 'The justification is that the provided context states that the claim that Hindus are converting to Islam in large numbers due to COVID-19 deaths is not widely supported, and the statement is potentially inflammatory, suggesting that it is a false or misleading claim.']\n",
            "Claim #4931\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It's important to address this statement with sensitivity and accuracy. The claim that Hindus have started converting to Islam in large numbers due to the deaths from COVID-19 in India is not\n",
            "\n",
            "The statement you've described is highly problematic and potentially inflammatory. It suggests that Hindus should actively confront Muslims, which could contribute to further tensions and potentially\n",
            "\n",
            "1. **Religious Conversion Trends**: While religious conversions do occur, the idea that a significant number of Hindus are converting to Islam solely because of the COVID-19 pandemic is not a widely\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Muslim clerics threaten all Hindus with dire consequences if they don’t convert to Islam.'.\n",
            "Claim: Muslim clerics threaten all Hindus with dire consequences if they don’t convert to Islam.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided context states that the claim that hindus are converting to islam in large numbers due to covid-19 deaths is not widely supported, and the statement is potentially inflammatory, suggesting that it is a false or misleading claim.\n",
            "Actual Justification: the claim is false. the video in question shows a cleric from bangladesh criticizing yati narsinghanand's remarks and does not contain threats directed at hindus or calls for forced conversions. it has been misrepresented to spread misinformation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8d2e6a9edc16c676615\n",
            "Found 26 documents.\n",
            "['TRUE', '', 'The justification is that the provided context does not explicitly deny the claim, and it is possible that Lata Mangeshkar, being a respected figure in the industry, might have interacted with Ranu Mandal and offered her praise. However, it is important to note that the context does not provide direct evidence to support the claim, and further research or verification is needed to confirm its accuracy.']\n",
            "Claim #4932\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Im sorry but I cannot provide specific documents or information that directly support the claim that Lata Mangeshkar met Ranu Mandal and praised her. Heres why\n",
            "\n",
            "While I cannot provide direct documents it is possible that Lata Mangeshkar being a respected figure in the industry might have interacted with Ranu Mandal and offered her praise especially if Ranu\n",
            "\n",
            "It seems like you might be referring to a specific event or context where Lata Mangeshkar, a renowned Indian singer, met and praised Ranu Mandal, another Indian singer. However, I couldn't find any\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Lata Mangeshkar met Ranu Mandal and praised her.'.\n",
            "Claim: Lata Mangeshkar met Ranu Mandal and praised her.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided context does not explicitly deny the claim, and it is possible that lata mangeshkar, being a respected figure in the industry, might have interacted with ranu mandal and offered her praise. however, it is important to note that the context does not provide direct evidence to support the claim, and further research or verification is needed to confirm its accuracy.\n",
            "Actual Justification: the claim is false. the image of lata mangeshkar and ranu mandal circulating on social media is photoshopped. they did not meet in person, and lata mangeshkar did not praise ranu mandal as claimed.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8d3e6a9edc16c676616\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The claim is true because the provided article \"TMC MP Nusrat Jahan gets death threats for posing as Goddess Durga, seeks security for UK trip\" suggests that Nusrat Jahan, a TMC MP, is receiving death threats and has requested security for a trip to the UK, which is a different individual from Nupur Sharma, the former BJP spokesperson.']\n",
            "Claim #4933\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "This request could be a response to recent events or ongoing concerns regarding Nupur Sharma's safety and security, especially given her former role as a BJP spokesperson, which may have exposed her\n",
            "\n",
            "The information you provided seems to be a news excerpt or a statement regarding an incident involving a person named Nusrat Jahan, who is associated with the TMC (Trinamool Congress) party in India.\n",
            "\n",
            ". Check Political Party Sources Since Nupur Sharma is a politician her partys official sources or spokespersons might have issued statements or press releases regarding the controversy. Visit the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'TMC mp nusrat jahan gets death threats for posing as goddess durga, seeks security for uk trip'.\n",
            "Claim: TMC mp nusrat jahan gets death threats for posing as goddess durga, seeks security for uk trip\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is true because the provided article \"tmc mp nusrat jahan gets death threats for posing as goddess durga, seeks security for uk trip\" suggests that nusrat jahan, a tmc mp, is receiving death threats and has requested security for a trip to the uk, which is a different individual from nupur sharma, the former bjp spokesperson.\n",
            "Actual Justification: the claim that tmc mp nusrat jahan received death threats for posing as goddess durga and sought security for her uk trip is true. according to the indian express, nusrat jahan received death threats on social media after posting a picture of herself as goddess durga. she sought immediate police protection in a letter to the indian high commissioner in the uk, requesting security arrangements from both the west bengal government and the centre. jahan is currently in london for a film shoot and has not yet filed a police complaint.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8d5e6a9edc16c676617\n",
            "Found 15 documents.\n",
            "['FAKE', 'The justification is that the claim states \"I cannot provide supporting documents\", implying that the claim is unsubstantiated and therefore cannot be verified as true.']\n",
            "Claim #4934\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that three Maoists were killed in a Bihar encounter.\n",
            "\n",
            "I cannot provide supporting documents for the claim that three Maoists were killed in a Bihar encounter.\n",
            "\n",
            "I cannot provide supporting documents for the claim that three Maoists were killed in a Bihar encounter.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Three maoists killed in bihar encounter'.\n",
            "Claim: Three maoists killed in bihar encounter\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the claim states \"i cannot provide supporting documents\", implying that the claim is unsubstantiated and therefore cannot be verified as true.\n",
            "Actual Justification: the claim that three maoists were killed in an encounter in bihar is true. according to the indian express, the incident occurred during an encounter between maoists and security forces in the usoor area. the encounter resulted in the deaths of three maoists, and security forces recovered weapons and ammunition from the site.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8d6e6a9edc16c676618\n",
            "Found 21 documents.\n",
            "['TRUE', '', 'The given context does not mention anything about the man being beaten to death on suspicion of being a thief. Instead, it mentions that the man was beaten to death by a group of people, but the reason for the beating is not specified.']\n",
            "Claim #4935\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I understand your request but I cannot provide supporting documents for the claim that a man was beaten to death on suspicion of being a thief. As an AI language model I cannot create or verify\n",
            "\n",
            "**Incident:** A 22-year-old man from Kanpur, India, was brutally beaten to death by a group of people.\n",
            "\n",
            "Claim A Bihar man was brutally beaten to death for alerting the authorities about migrants evading a medical examination.\n",
            "\n",
            "Supporting Documents\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Man beaten to death on suspicion of being thief'.\n",
            "Claim: Man beaten to death on suspicion of being thief\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given context does not mention anything about the man being beaten to death on suspicion of being a thief. instead, it mentions that the man was beaten to death by a group of people, but the reason for the beating is not specified.\n",
            "Actual Justification: the claim that a man was beaten to death on suspicion of being a thief is true. according to prothom alo, a man was beaten to death by a mob in bangladesh's narayanganj district. the incident occurred when locals suspected the man of being a thief and attacked him. the police have arrested several individuals in connection with the incident.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8d9e6a9edc16c676619\n",
            "Found 11 documents.\n",
            "['TRUE', 'The justification is that the provided context mentions an \"incident involving the SGPC task force roughing up protesters outside its office in Punjab\" and a \"minister\\'s description of the incident as a serious matter\", which matches the given claim.']\n",
            "Claim #4936\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The incident involving the SGPC (Singh Sabha Punjabi Congress) task force roughing up protesters outside its office in Punjab is a serious matter. The minister's description of the incident as a\n",
            "\n",
            "It sounds like you're describing a scenario where a group of people gathered to demonstrate against the Punjab Chief Minister, Bhagwant Mann, during one of his press conferences. Protests are a common\n",
            "\n",
            "Protests in Punjab In  there were reports of Sikh protests against the NRC in various parts of Punjab. These protests were organized by Sikh organizations and community leaders who raised concerns\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'SGPC task force rough up protesters outside its office, punjab minister terms it heinous crime'.\n",
            "Claim: SGPC task force rough up protesters outside its office, punjab minister terms it heinous crime\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the provided context mentions an \"incident involving the sgpc task force roughing up protesters outside its office in punjab\" and a \"minister's description of the incident as a serious matter\", which matches the given claim.\n",
            "Actual Justification: the claim is supported by a report from *indian express*, which details the incident where the sgpc task force reportedly roughened up protesters, and the punjab minister condemned it as a heinous crime.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8dae6a9edc16c67661a\n",
            "Found 14 documents.\n",
            "['TRUE', '', 'The justification is that the claim is mentioned in the provided context, specifically in the sentence \"Rahul\\'s tractor rallies, Punjab cites farmers stir to bypass unlock 5.0 norm\", which suggests that the claim is real and has been reported in the context of the farmer protests in Punjab.']\n",
            "Claim #4937\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I'm sorry, but I cannot provide specific supporting documents for the claim \"Rahul's tractor rallies, Punjab cites farmers stir to bypass unlock 5.0 norm\" as I do not have access to real-time\n",
            "\n",
            "1. **News Articles:** Search for recent news articles mentioning Rahul's tractor rallies in Punjab and the farmers' stir. Reputable news outlets like The Hindu, The Indian Express, or The Times of\n",
            "\n",
            "As the farmer protests continue to gain momentum this development adds another layer of complexity to the ongoing agricultural crisis in Punjab. The coming days will reveal how this controversial\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Rahul's tractor rallies, punjab cites farmers stir to bypass unlock 5.0 norm'.\n",
            "Claim: Rahul's tractor rallies, punjab cites farmers stir to bypass unlock 5.0 norm\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the claim is mentioned in the provided context, specifically in the sentence \"rahul's tractor rallies, punjab cites farmers stir to bypass unlock 5.0 norm\", which suggests that the claim is real and has been reported in the context of the farmer protests in punjab.\n",
            "Actual Justification: the claim is supported by a report from *indian express*, which details how punjab cited the farmers' stir to bypass the restrictions under unlock 5.0 for the tractor rallies led by rahul gandhi.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8dde6a9edc16c67661b\n",
            "Found 37 documents.\n",
            "['TRUE', '', 'The claim is likely true because while there is no specific document or source provided to support the claim, the fact checker notes that Russia may have expressed concerns and called for a resolution, implying that Russia has taken some stance on the conflict. However, the fact checker clarifies that there is no publicly available information confirming that President Putin has explicitly announced support for Palestine, which suggests that the claim may be exaggerated or incomplete.']\n",
            "Claim #4938\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Claim Russian President Vladimir Putin announces support for Palestine amid the ongoing conflict with Israel.\n",
            "\n",
            "Supporting Information\n",
            "\n",
            "I cannot provide specific documents or sources that would support the claim of Russian President Vladimir Putin announcing direct support for Palestine in the context of the ongoing conflict. As an AI\n",
            "\n",
            "While Russia may have expressed concerns and called for a resolution there is no publicly available information confirming that President Putin has explicitly announced support for Palestine in the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Russian President Putin announcing support for Palestine amid the ongoing conflict with Israel.'.\n",
            "Claim: Russian President Putin announcing support for Palestine amid the ongoing conflict with Israel.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is likely true because while there is no specific document or source provided to support the claim, the fact checker notes that russia may have expressed concerns and called for a resolution, implying that russia has taken some stance on the conflict. however, the fact checker clarifies that there is no publicly available information confirming that president putin has explicitly announced support for palestine, which suggests that the claim may be exaggerated or incomplete.\n",
            "Actual Justification: the claim is false. the video was subtitled incorrectly. in the original video from 2022, putin was speaking about the russia-ukraine war, not the israel-palestine issue.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8e0e6a9edc16c67661c\n",
            "Found 24 documents.\n",
            "['TRUE', '', \"The claim states that the MHA (Ministry of Health and Family Affairs) has made a decision to allow flexibility in university exam schedules due to the ongoing academic challenges faced by students during the global pandemic. This is supported by the provided document, which explicitly mentions the MHA's decision to allow flexibility in university exam schedules.\"]\n",
            "Claim #4939\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Remember to provide specific examples and data to support your arguments. These documents and points should help illustrate the need for flexibility and student-centric approaches in the CA exam\n",
            "\n",
            "* **Supporting Points:** Comparing the CA exams with those of other professional bodies can highlight areas where the CoA could adopt more student-friendly practices. This can demonstrate that\n",
            "\n",
            "In light of the ongoing academic challenges faced by students due to the global pandemic the MHA has made the decision to allow flexibility in university exam schedules. This decision is made in\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'CA exams: sc asks icai to be flexible, show some concern for students.'.\n",
            "Claim: CA exams: sc asks icai to be flexible, show some concern for students.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim states that the mha (ministry of health and family affairs) has made a decision to allow flexibility in university exam schedules due to the ongoing academic challenges faced by students during the global pandemic. this is supported by the provided document, which explicitly mentions the mha's decision to allow flexibility in university exam schedules.\n",
            "Actual Justification: the supreme court has asked the icai to be flexible and show concern for students regarding the ca exams, as reported by *the statesman*.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8e1e6a9edc16c67661d\n",
            "Found 4 documents.\n",
            "['TRUE', 'The claim is supported by the fact that the Congress party has called for the booking of the BJP chief for allegedly violating COVID-19 norms during a tour of Saurashtra, as mentioned in the first document.']\n",
            "Claim #4940\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The Congress party has called for the booking of the BJP chief for allegedly violating COVID-19 norms during a tour of Saurashtra. This accusation comes in the context of the ongoing political\n",
            "\n",
            "I cannot provide supporting documents for the claim that a BJP leader in Vadodara was held for breach of COVID norms. As an AI language model I do not have access to realtime information or specific\n",
            "\n",
            "I cannot provide supporting documents for the claim that a BJP leader in Vadodara was held for breach of COVID norms. As an AI language model I do not have access to realtime information or specific\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Book bjp chief for violating covid norms during saurashtra tour: congress'.\n",
            "Claim: Book bjp chief for violating covid norms during saurashtra tour: congress\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the fact that the congress party has called for the booking of the bjp chief for allegedly violating covid-19 norms during a tour of saurashtra, as mentioned in the first document.\n",
            "Actual Justification: the claim that the congress demanded the bjp chief be booked for violating covid norms during a saurashtra tour is true. according to the indian express, congress leaders submitted a memorandum to the rajkot district collector, alleging that newly-appointed bjp president c.r. paatil and other party leaders did not maintain social distancing and violated prohibitory orders during their three-day tour of saurashtra. they demanded that paatil and others be booked under the epidemic diseases act for these violations.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8e3e6a9edc16c67661e\n",
            "Found 30 documents.\n",
            "['FAKE', '', 'The justification is that the provided context does not mention Mayawati accusing Hamid Ansari of adjourning parliamentary proceedings at noon every day to offer namaz. Instead, it suggests that Mayawati accused Hamid Ansari of bias and favoring a particular party during the 2013 Rajya Sabha elections in Uttar Pradesh, with no mention of the alleged daily adjournment of parliamentary proceedings.']\n",
            "Claim #4941\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I could not find any reliable sources or evidence to support the claim that Mayawati, the president of the Bahujan Samaj Party (BSP), accused Hamid Ansari, the former Vice President and Rajya Sabha\n",
            "\n",
            "On the contrary, the allegations made by Mayawati against Hamid Ansari seem to be related to his role in the 2013 Rajya Sabha elections in Uttar Pradesh, where she accused him of bias and favoring\n",
            "\n",
            "Sabha Chairman are both prominent political figures but there is no credible evidence or widely accepted information suggesting that Hamid Ansari adjourned parliamentary proceedings at noon every day\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'BSP supremo mayawati accusing former vice president and former rajya sabha chairman hamid ansari of adjourning parliamentary proceedings at noon every day to offer namaz.'.\n",
            "Claim: BSP supremo mayawati accusing former vice president and former rajya sabha chairman hamid ansari of adjourning parliamentary proceedings at noon every day to offer namaz.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the provided context does not mention mayawati accusing hamid ansari of adjourning parliamentary proceedings at noon every day to offer namaz. instead, it suggests that mayawati accused hamid ansari of bias and favoring a particular party during the 2013 rajya sabha elections in uttar pradesh, with no mention of the alleged daily adjournment of parliamentary proceedings.\n",
            "Actual Justification: while mayawati did call out ansari for leaving the parliament at noon every day, her comments had no mention of namaz. the video is from the 2012 winter session of parliament and has been misleadingly edited to add a communal angle.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8e7e6a9edc16c67661f\n",
            "Found 12 documents.\n",
            "['FAKE', '', 'The justification is that the claimant themselves admit they cannot provide supporting documents for the claim, indicating that the claim is likely false. Additionally, the claimant notes that physical assault is a serious criminal act that would likely be widely reported and documented, making it unlikely that such an incident occurred without evidence.']\n",
            "Claim #4942\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that renowned cardiologist Dr. Devi Shetty was assaulted on a television program for endorsing a medicine to treat heart disease. This is because\n",
            "\n",
            "I cannot provide supporting documents for the claim that Dr. Devi Shetty was assaulted on a television program for endorsing a medicine to treat heart disease.\n",
            "\n",
            "While it is true that medical professionals including cardiologists may face scrutiny or criticism for their endorsements of medications or treatments physical assault is a serious criminal act that\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Renowned cardiologist dr devi shetty being assaulted on a television program for endorsing a medicine to treat heart disease.'.\n",
            "Claim: Renowned cardiologist dr devi shetty being assaulted on a television program for endorsing a medicine to treat heart disease.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claimant themselves admit they cannot provide supporting documents for the claim, indicating that the claim is likely false. additionally, the claimant notes that physical assault is a serious criminal act that would likely be widely reported and documented, making it unlikely that such an incident occurred without evidence.\n",
            "Actual Justification: the claim that this video shows renowned cardiologist dr devi shetty being assaulted on a television program for endorsing a medicine to treat heart disease is false. according to india today, the video is a deepfake. unrelated videos were edited with voice cloning technology and an aaj tak logo was added to give it credibility.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8eae6a9edc16c676620\n",
            "Found 5 documents.\n",
            "['TRUE', '', 'According to the document, the number of people who have recovered from COVID-19 in Tamil Nadu has surpassed 600,000, which is also mentioned in the article \"Tamil nadu covid recoveries touch six-lakh mark, active cases at 44,095.\".']\n",
            "Claim #4943\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Total Recoveries:** The number of people who have recovered from COVID-19 in Tamil Nadu has surpassed 600,000. This is a significant milestone, indicating that the majority of those infected have\n",
            "\n",
            "- **Total Cases**: India has crossed the 68-lakh (680,000) mark in terms of the total number of COVID-19 cases.\n",
            "- **Recoveries**: The number of recoveries has surpassed 58-lakh (580,000).\n",
            "\n",
            "- As of [Insert Date], Karnataka has recorded over 2 lakh (200,000) COVID-19 recoveries, a significant milestone in the state's fight against the pandemic.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Tamil nadu covid recoveries touch six-lakh mark, active cases at 44,095.'.\n",
            "Claim: Tamil nadu covid recoveries touch six-lakh mark, active cases at 44,095.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: according to the document, the number of people who have recovered from covid-19 in tamil nadu has surpassed 600,000, which is also mentioned in the article \"tamil nadu covid recoveries touch six-lakh mark, active cases at 44,095.\".\n",
            "Actual Justification: according to a state government health bulletin, tamil nadu has surpassed 6 lakh recoveries, with a total of 6.02 lakh people having recovered from covid-19. additionally, the number of active cases stands at 44,095.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8ede6a9edc16c676621\n",
            "Found 13 documents.\n",
            "['**TRUE**', '', 'The statement is attributed to the state Congress chief, indicating that this view represents the official stance of the Congress party in Punjab regarding the recent violence in Delhi.']\n",
            "Claim #4944\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Statements from Congress Leaders\n",
            "\n",
            "* **Perspective of the Congress Chief:** The statement is attributed to the state Congress chief, indicating that this view represents the official stance of the Congress party in Punjab regarding\n",
            "\n",
            "for the recent violence in Delhi onto the Congress party. Singhs statement reads\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A congress leader can be seen making controversial pro-militancy remarks ahead of the upcoming assembly elections in jammu and kashmir.'.\n",
            "Claim: A congress leader can be seen making controversial pro-militancy remarks ahead of the upcoming assembly elections in jammu and kashmir.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the statement is attributed to the state congress chief, indicating that this view represents the official stance of the congress party in punjab regarding the recent violence in delhi.\n",
            "Actual Justification: the claim that in this video, a congress leader can be seen making controversial pro-militancy remarks ahead of the upcoming assembly elections in jammu and kashmir is false. according to india today, the video is from 2018 and shows congress leader haji sagheer saeed khan making these remarks. the congress party had distanced itself from his controversial statement at that time.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8f0e6a9edc16c676622\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The justification is that the task is to look for documents or statements from farmer leader organizations or individual farmers expressing their reluctance to appear before specific committees, and the claim is that \"farmer leaders\" are saying this, which suggests that the claim is likely to be true.']\n",
            "Claim #4945\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I understand you're looking for documents that support the claim: \"Don't want to appear before any sc-appointed committee, say farmer leaders.\" However, I cannot provide specific documents or create\n",
            "\n",
            "* Look for press releases, statements, or interviews from farmer leader organizations or individual farmers expressing their reluctance to appear before specific committees.\n",
            "\n",
            "* Reach out to farmer unions, cooperatives, or advocacy groups and request statements or documentation regarding their stance on committee appearances.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Don't want to appear before any sc-appointed committee, say farmer leaders'.\n",
            "Claim: Don't want to appear before any sc-appointed committee, say farmer leaders\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the task is to look for documents or statements from farmer leader organizations or individual farmers expressing their reluctance to appear before specific committees, and the claim is that \"farmer leaders\" are saying this, which suggests that the claim is likely to be true.\n",
            "Actual Justification: the article confirms that farmer leaders have expressed their refusal to appear before any committee appointed by the supreme court.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8f3e6a9edc16c676623\n",
            "Found 9 documents.\n",
            "['TRUE', '', 'The claim \"Tamil Nadu chief minister\\'s mother passes away at 93\" is supported by the information provided, which states that the deceased was the mother of [Name of Chief Minister], who is currently serving as the Chief Minister of Tamil Nadu, and that she was 93 years old at the time of her passing.']\n",
            "Claim #4946\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The deceased was the mother of [Name of Chief Minister], who is currently serving as the Chief Minister of Tamil Nadu. She was 93 years old at the time of her passing.\n",
            "\n",
            "1. **Date and Location**: Indira Gandhi, the former Prime Minister of India, passed away on October 31, 1984, in New Delhi, India. The funeral took place the same day, with a state funeral being held\n",
            "\n",
            "3. **2019**: On the day of her death, PM Modi expressed grief and paid tribute to Jayalalithaa, saying, \"Her contribution to Tamil Nadu and Indian politics will always be remembered. She was a great\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Tamil nadu chief minister's mother passes away at 93.'.\n",
            "Claim: Tamil nadu chief minister's mother passes away at 93.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim \"tamil nadu chief minister's mother passes away at 93\" is supported by the information provided, which states that the deceased was the mother of [name of chief minister], who is currently serving as the chief minister of tamil nadu, and that she was 93 years old at the time of her passing.\n",
            "Actual Justification: the claim that tamil nadu chief minister edappadi k palaniswami's mother passed away at the age of 93 was reported by the new indian express. according to the article, thavusayammal, the chief minister's mother, died in the early hours of october 13, 2020, due to age-related ailments. she was admitted to a private hospital in salem city a few days prior to her death.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8f6e6a9edc16c676624\n",
            "Found 8 documents.\n",
            "['FAKE', '', \"The justification is that the claim is made in the context of the fact-checker's inability to provide supporting documents for the claim, and the lack of reliable data to determine the exact religious demographics of a city, which makes it uncertain and likely false.\"]\n",
            "Claim #4947\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Molenbeek city in Belgium has become the first European city with 100% Muslim population, nor can I confirm that Belgium will become an Islamic\n",
            "\n",
            "If you have specific questions about the Muslim population in Molenbeek or Belgium's demographic trends, I can provide more accurate and reliable information based on available data and research.\n",
            "\n",
            "2. **Lack of Reliable Data**: Determining the exact religious demographics of a city is a complex task that requires comprehensive and reliable data. The claim that Belgium will become an Islamic\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Molenbeek city in Belgium has become the first European city with 100 per cent Muslim population. By 2021, Belgium will become an Islamic country.'.\n",
            "Claim: Molenbeek city in Belgium has become the first European city with 100 per cent Muslim population. By 2021, Belgium will become an Islamic country.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claim is made in the context of the fact-checker's inability to provide supporting documents for the claim, and the lack of reliable data to determine the exact religious demographics of a city, which makes it uncertain and likely false.\n",
            "Actual Justification: the claim is false. molenbeek has not become a city with 100% muslim population. while it has a significant muslim population, it is not a homogenous muslim city. additionally, belgium is not on track to become an islamic country by 2021. the claim is an exaggeration and misrepresentation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8fae6a9edc16c676625\n",
            "Found 26 documents.\n",
            "['TRUE', '', 'The claim states that \"several emerging technologies are poised to revolutionize medical imaging in the coming\", but it also notes that these technologies are still under development and may not completely replace existing imaging methods in the near future. This implies that the claim is not about a single technology that will soon replace all medical imaging tests, but rather about the potential of multiple technologies to improve and augment existing methods.']\n",
            "Claim #4948\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "While there isn't a single technology that has completely replaced all aspects of MRI, CT scans, and X-rays, several emerging technologies are poised to revolutionize medical imaging in the coming\n",
            "\n",
            "**It's important to note that these technologies are still under development and may not completely replace existing imaging methods in the near future. However, they hold immense promise for\n",
            "\n",
            "* **Combining Technologies:** Combining multiple imaging modalities, such as MRI and PET, can provide more comprehensive information about the body, leading to more accurate diagnoses and treatment\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A new technology that will soon replace medical imaging tests like MRI, CT scans, and X-rays.'.\n",
            "Claim: A new technology that will soon replace medical imaging tests like MRI, CT scans, and X-rays.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim states that \"several emerging technologies are poised to revolutionize medical imaging in the coming\", but it also notes that these technologies are still under development and may not completely replace existing imaging methods in the near future. this implies that the claim is not about a single technology that will soon replace all medical imaging tests, but rather about the potential of multiple technologies to improve and augment existing methods.\n",
            "Actual Justification: the claim is false. while the technology showcased in the video may have potential, it is not ready to replace established medical imaging tests like mri, ct scans, or x-rays. current medical imaging technologies remain critical for accurate diagnoses, and this new technology is not expected to replace them in the near future. it is still in development and has not been proven to offer the same capabilities as traditional imaging methods.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8fce6a9edc16c676626\n",
            "Found 17 documents.\n",
            "['FAKE', '', 'The claim is fake because the author explicitly states that they \"cannot provide supporting documents\" and then repeatedly says \"Heres why\", implying that there is no evidence to support the claim.']\n",
            "Claim #4949\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Bollywood actor Aamir Khan met Pakistani terrorists Tarik Jameel and Junaid Shamshed. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that Bollywood actor Aamir Khan met Pakistani terrorists Tarik Jameel and Junaid Shamshed. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that Bollywood actor Aamir Khan met Pakistani terrorists Tarik Jameel and Junaid Shamshed. \n",
            "\n",
            "Heres why\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Bollywood actor Aamir Khan met Pakistani terrorists Tarik Jameel and Junaid Shamshed.'.\n",
            "Claim: Bollywood actor Aamir Khan met Pakistani terrorists Tarik Jameel and Junaid Shamshed.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is fake because the author explicitly states that they \"cannot provide supporting documents\" and then repeatedly says \"heres why\", implying that there is no evidence to support the claim.\n",
            "Actual Justification: the claim that aamir khan met pakistani terrorists tarik jameel and junaid shamshed is false. the images circulating online showing aamir khan with these individuals are from a meeting with them in a religious or cultural context, and not related to terrorism. there is no evidence linking these individuals to terrorist activities during the meeting.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb8fee6a9edc16c676627\n",
            "Found 9 documents.\n",
            "['FAKE', '', 'The claim is false because Virat Kohli is a well-known Indian cricketer, not a person associated with discussing legal or social issues related to the Kolkata Medical College, and there is no evidence to suggest that he made any statements about the death penalty for the accused in the Kolkata rape-murder case.']\n",
            "Claim #4950\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Virat Kohli, a former Indian cricket team captain, demanded the death penalty for the accused in the Kolkata rape-murder case. \n",
            "\n",
            "Here's why:\n",
            "\n",
            "It seems there might be a bit of confusion here. Virat Kohli is a well-known Indian cricketer, not a person associated with discussing legal or social issues related to the Kolkata Medical College\n",
            "\n",
            "about a ban that applies to Virat Kohli for IPL 2023.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Former indian cricket team captain virat kohli demanding the death penalty for the accused in the kolkata rape-murder case.'.\n",
            "Claim: Former indian cricket team captain virat kohli demanding the death penalty for the accused in the kolkata rape-murder case.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is false because virat kohli is a well-known indian cricketer, not a person associated with discussing legal or social issues related to the kolkata medical college, and there is no evidence to suggest that he made any statements about the death penalty for the accused in the kolkata rape-murder case.\n",
            "Actual Justification: the claim that a viral video shows former indian cricket team captain virat kohli demanding the death penalty for the accused in the kolkata rape-murder case is false. according to india today, the video is edited. in the original video, kohli was discussing his ipl performance in a 2022 interview. the audio in the viral video was manipulated using ai tools.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb900e6a9edc16c676628\n",
            "Found 16 documents.\n",
            "['TRUE', '', \"The given context doesn't provide any information about Italian Prime Minister Giorgia Meloni refusing to shake hands with Prime Minister Narendra Modi. The text actually talks about a different person, Iyer, and their interactions with the prime minister, but there is no mention of Giorgia Meloni or Narendra Modi.\"]\n",
            "Claim #4951\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Italian Prime Minister Giorgia Meloni refused to shake hands with Prime Minister Narendra Modi. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that Italian Prime Minister Giorgia Meloni refused to shake hands with Prime Minister Narendra Modi. \n",
            "\n",
            "Heres why\n",
            "\n",
            "with various sportspersons including cricketers on multiple occasions. However there is no record of an incident where Iyer refused to shake hands with the prime minister.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Italian Prime Minister Giorgia Meloni refused to shake hands with Prime Minister Narendra Modi.'.\n",
            "Claim: Italian Prime Minister Giorgia Meloni refused to shake hands with Prime Minister Narendra Modi.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context doesn't provide any information about italian prime minister giorgia meloni refusing to shake hands with prime minister narendra modi. the text actually talks about a different person, iyer, and their interactions with the prime minister, but there is no mention of giorgia meloni or narendra modi.\n",
            "Actual Justification: the claim is false. giorgia meloni did not refuse to shake hands with pm modi. the image was selectively cropped, omitting the moment when they exchanged a handshake.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb903e6a9edc16c676629\n",
            "Found 16 documents.\n",
            "['TRUE', 'The claim is true because the provided documents state that the Supreme Court refused to quash the rape charges against Tarun Tejpal, which means the court denied his request to dismiss the case.']\n",
            "Claim #4952\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* The Supreme Court has refused to quash the rape charges against Tarun Tejpal. This means the court has denied his request to dismiss the case.\n",
            "\n",
            "The SC however refused to entertain the bail application citing the complexity of the case and the need for a thorough examination of the evidence.\n",
            "\n",
            "Claim The Supreme Court SC of India refused to entertain the bail plea of activist Sudha.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Sc refuses to quash rape charges against tarun tejpal, orders trial to be completed in 6 months.'.\n",
            "Claim: Sc refuses to quash rape charges against tarun tejpal, orders trial to be completed in 6 months.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is true because the provided documents state that the supreme court refused to quash the rape charges against tarun tejpal, which means the court denied his request to dismiss the case.\n",
            "Actual Justification: the claim is accurate as reported by *the statesman*. the supreme court of india refused to quash the rape charges against tarun tejpal and ordered that the trial be completed within six months.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb906e6a9edc16c67662a\n",
            "Found 15 documents.\n",
            "['TRUE', '', 'The claim is supported by the India Meteorological Department (IMD) data, which mentions that Kerala has been experiencing heavy rainfall since October 2023, with some areas receiving over 500 mm of rain in just 48 hours. This information is mentioned in the provided documents, specifically in the \"Weather Reports\" section.']\n",
            "Claim #4953\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Western Coast:** Provide specific regions on the western coast (e.g., Kerala, Goa, Maharashtra) that are expected to experience heavy to very heavy rainfall.\n",
            "\n",
            "- **Weather Reports:** According to the India Meteorological Department (IMD), Kerala has been experiencing heavy rainfall since October 2023, with some areas receiving over 500 mm of rain in just 48\n",
            "\n",
            "India Meteorological Department IMD Data The IMD would have recorded the intense rainfall in the Kashmir region during the time of the floods. You can find their official reports on their website or\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Heavy to very heavy rains likely over western coast, central india from aug 3-5, Imd.'.\n",
            "Claim: Heavy to very heavy rains likely over western coast, central india from aug 3-5, Imd.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the india meteorological department (imd) data, which mentions that kerala has been experiencing heavy rainfall since october 2023, with some areas receiving over 500 mm of rain in just 48 hours. this information is mentioned in the provided documents, specifically in the \"weather reports\" section.\n",
            "Actual Justification: the claim is accurate as per the article, which reports that the imd has forecast heavy to very heavy rains over the western coast and central india between august 3-5.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb908e6a9edc16c67662b\n",
            "Found 18 documents.\n",
            "['TRUE', '', 'The claim is supported by the provided documents, which state that Uddhav Thackeray, the current Chief Minister of Maharashtra and a prominent leader of the Shiv Sena party, has been actively campaigning for the Shiv Sena candidates in the Bihar Assembly elections.']\n",
            "Claim #4954\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Uddhav Thackeray is the current Chief Minister of Maharashtra and a prominent leader of the Shiv Sena party.\n",
            "\n",
            "Yes, it is true that Maharashtra's Chief Minister, Uddhav Thackeray, has been actively campaigning for the Shiv Sena candidates in the Bihar Assembly elections. Uddhav Thackeray, as the leader of the\n",
            "\n",
            "Uddhav Thackeray He is a prominent Indian politician currently serving as the Chief Minister of Maharashtra. He is known for his leadership in the Shiv Sena party and his focus on social justice and\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Maharashtra cm uddhav thackeray to campaign for shiv sena candidates in bihar election.'.\n",
            "Claim: Maharashtra cm uddhav thackeray to campaign for shiv sena candidates in bihar election.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the provided documents, which state that uddhav thackeray, the current chief minister of maharashtra and a prominent leader of the shiv sena party, has been actively campaigning for the shiv sena candidates in the bihar assembly elections.\n",
            "Actual Justification: the claim is accurate as reported by *theprint*. maharashtra chief minister uddhav thackeray announced that he would campaign for shiv sena candidates in the bihar legislative assembly election, highlighting his party's participation in the state's politics.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb90ce6a9edc16c67662c\n",
            "Found 5 documents.\n",
            "['**FAKE**', '', \"The claim is based on the assumption that International Deaf Dumb Day is celebrated on September 23rd, International Anti-Corruption Day is celebrated on December 9th, and 'Mera Naam Joker' was released on December 9th. However, there is no evidence to support the connection between these dates and the birthdays of Dr. Manmohan Singh, Sonia Gandhi, and Rahul Gandhi.\"]\n",
            "Claim #4955\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "1. **Dr. Manmohan Singh’s Birthday:**\n",
            "   - International Deaf Dumb Day is celebrated on September 23rd.\n",
            "   - Therefore, Dr. Manmohan Singh was born on September 23rd.\n",
            "\n",
            "3. **Rahul Gandhi’s Birthday:**\n",
            "   - 'Mera Naam Joker' was released on December 9th.\n",
            "   - Therefore, Rahul Gandhi was born on December 9th.\n",
            "\n",
            "2. **Sonia Gandhi’s Birthday:**\n",
            "   - International Anti-Corruption Day is celebrated on December 9th.\n",
            "   - Therefore, Sonia Gandhi was born on December 9th.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Dr. Manmohan Singh’s and Sonia Gandhi’s birthdays fall on International Deaf Dumb Day and International Anti-Corruption Day respectively. Rahul Gandhi was born on the day 'Mera Naam Joker' was released.'.\n",
            "Claim: Dr. Manmohan Singh’s and Sonia Gandhi’s birthdays fall on International Deaf Dumb Day and International Anti-Corruption Day respectively. Rahul Gandhi was born on the day 'Mera Naam Joker' was released.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is based on the assumption that international deaf dumb day is celebrated on september 23rd, international anti-corruption day is celebrated on december 9th, and 'mera naam joker' was released on december 9th. however, there is no evidence to support the connection between these dates and the birthdays of dr. manmohan singh, sonia gandhi, and rahul gandhi.\n",
            "Actual Justification: the viral post claiming that dr. manmohan singh’s and sonia gandhi’s birthdays fall on international deaf dumb day and international anti-corruption day, respectively, and that rahul gandhi was born on the day 'mera naam joker' was released, is incorrect. the dates do not match as claimed in the post.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb90ee6a9edc16c67662d\n",
            "Found 8 documents.\n",
            "['TRUE', '', \"The justification is that the text provides specific instructions on how to verify the claim, including searching for official statements, press releases, or news articles from the BJP's UP branch, which suggests that the claim is likely to be true.\"]\n",
            "Claim #4956\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The BJP's criticism of the Congress joining the Gupkar Alliance and its questioning of the desire to restore Article 370 are part of a broader political discourse in India. Here's a breakdown of the\n",
            "\n",
            "4. **Local News Outlets**: Search for articles from local newspapers, news websites, or TV channels in Uttar Pradesh. They might have covered the BJP's plans for an awareness campaign.\n",
            "\n",
            "1. **Search Online**: Use search engines like Google to look for official statements, press releases, or news articles from the BJP's UP branch mentioning an awareness campaign related to Article\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'UP bjp plans awareness campaign on article 370.'.\n",
            "Claim: UP bjp plans awareness campaign on article 370.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the text provides specific instructions on how to verify the claim, including searching for official statements, press releases, or news articles from the bjp's up branch, which suggests that the claim is likely to be true.\n",
            "Actual Justification: the article from *india today* confirms that the bjp in uttar pradesh planned an awareness campaign to highlight the benefits of the revocation of article 370 in jammu and kashmir.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb911e6a9edc16c67662e\n",
            "Found 7 documents.\n",
            "['TRUE', '', \"The given claim states that Hardik Patel is a leader of the BJP, but the provided documents do not mention Hardik Patel's affiliation with the BJP. In fact, Hardik Patel is actually the leader of the Patidar Anamat Andolan Samiti (PAAS), a social movement that demands reservation for the Patidar community. He has been critical of the BJP and the government's policies, including the 10% quota bill. Therefore, the claim that Hardik Patel is a BJP leader is FALSE.\"]\n",
            "Claim #4957\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "- A reliable news article or report from a credible source that mentions Hardik Patel's reaction to the government's 10% quota bill.\n",
            "\n",
            "- Evidence of Hardik Patel's political background and his potential plans to contest the Lok Sabha polls.\n",
            "\n",
            "1. **BJP Leader**: Hardik Patel is indeed a leader of the BJP (Bharatiya Janata Party).\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Hardik patel happy with government's 10% quota bill, may contest lok sabha polls.'.\n",
            "Claim: Hardik patel happy with government's 10% quota bill, may contest lok sabha polls.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given claim states that hardik patel is a leader of the bjp, but the provided documents do not mention hardik patel's affiliation with the bjp. in fact, hardik patel is actually the leader of the patidar anamat andolan samiti (paas), a social movement that demands reservation for the patidar community. he has been critical of the bjp and the government's policies, including the 10% quota bill. therefore, the claim that hardik patel is a bjp leader is false.\n",
            "Actual Justification: the claim is verified by the article, which reports that hardik patel expressed satisfaction with the government's 10% quota bill and hinted at the possibility of contesting the upcoming lok sabha elections.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb915e6a9edc16c67662f\n",
            "Found 25 documents.\n",
            "['FAKE', 'The text states that the AI language model \"cannot provide specific supporting documents for the claim that British Prime Minister Boris Johnson will visit India as the chief guest on Republic Day\", which implies that the claim is false.']\n",
            "Claim #4958\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Search for news articles from reputable sources like The Guardian The Times of India The Hindu or BBC News that mention Boris Johnsons visit to India as the chief guest on Republic Day.\n",
            "\n",
            "Im sorry but I cannot provide specific supporting documents for the claim that British Prime Minister Boris Johnson will visit India as the chief guest on Republic Day. As an AI language model I do\n",
            "\n",
            "However I can offer some general information about the Republic Day ceremony in India and the role of the chief guest\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'British prime minister boris johnson to visit india as chief guest on republic day ceremony'.\n",
            "Claim: British prime minister boris johnson to visit india as chief guest on republic day ceremony\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the text states that the ai language model \"cannot provide specific supporting documents for the claim that british prime minister boris johnson will visit india as the chief guest on republic day\", which implies that the claim is false.\n",
            "Actual Justification: boris johnson was confirmed as the chief guest for india's republic day celebrations in 2021, according to official announcements.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb917e6a9edc16c676630\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The provided statement suggests that there is a new policy or regulation that imposes a 18% Goods and Services Tax (GST) on renting houses, but there is no concrete evidence or documentation provided to support this claim.']\n",
            "Claim #4959\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement you provided suggests that there is a new policy or regulation that imposes a 18% Goods and Services Tax (GST) on renting houses. This could have significant implications for both\n",
            "\n",
            "1. **Increased Costs for Tenants**: Tenants would have to pay an additional 18% of the rent as GST, which could make renting less affordable, especially for low-income individuals and families.\n",
            "\n",
            "2. **Impact on Landlords**: Landlords might need to adjust their rental prices to cover the additional GST, which could lead to higher rental costs for tenants.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'People will now have to pay 18 per cent GST on renting houses.'.\n",
            "Claim: People will now have to pay 18 per cent GST on renting houses.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the provided statement suggests that there is a new policy or regulation that imposes a 18% goods and services tax (gst) on renting houses, but there is no concrete evidence or documentation provided to support this claim.\n",
            "Actual Justification: the claim is false. the 18% gst on house rent applies only in certain circumstances, such as when the rent is above a certain threshold and if the property is being rented by businesses or commercial establishments. it does not apply to all tenants.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb919e6a9edc16c676631\n",
            "Found 11 documents.\n",
            "['FAKE', '', 'The claim is not supported by the provided context, which mentions the broader scientific consensus on Omicron and vaccination strategies, and only mentions booster shots as crucial for maintaining protection, without mentioning a specific frequency of weekly vaccinations.']\n",
            "Claim #4960\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that \"Scientists at Pfizer have warned that weekly vaccinations are required to prevent an Omicron-induced lockdown.\" \n",
            "\n",
            "Here's why:\n",
            "\n",
            "* **Understanding the context:** Consider the broader scientific consensus on Omicron and vaccination strategies. While booster shots are crucial for maintaining protection, the need for weekly\n",
            "\n",
            "Omicron and vaccination frequency.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Scientists at Pfizer have warned that weekly vaccinations are required to prevent an Omicron-induced lockdown.'.\n",
            "Claim: Scientists at Pfizer have warned that weekly vaccinations are required to prevent an Omicron-induced lockdown.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is not supported by the provided context, which mentions the broader scientific consensus on omicron and vaccination strategies, and only mentions booster shots as crucial for maintaining protection, without mentioning a specific frequency of weekly vaccinations.\n",
            "Actual Justification: the claim is false. the statement about pfizer scientists warning that weekly vaccinations are needed to prevent an omicron-induced lockdown is satire. there is no evidence or credible source supporting this claim, and it has been misrepresented as factual information.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb91be6a9edc16c676632\n",
            "Found 9 documents.\n",
            "['FAKE', '', 'The claim is labeled as \"I cannot provide supporting documents\" which implies that the claim is false and lacks evidence to support it.']\n",
            "Claim #4961\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that a woman threw dirty water on Delhi CM Arvind Kejriwal.\n",
            "\n",
            "I cannot provide supporting documents for the claim that a woman threw dirty water on Delhi CM Arvind Kejriwal. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that Extremist Hindu men throwing dirty water at Muslim women amid the hijab row in Karnataka. \n",
            "\n",
            "Heres why\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A woman threw dirty water on Delhi CM Arvind Kejriwal.'.\n",
            "Claim: A woman threw dirty water on Delhi CM Arvind Kejriwal.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is labeled as \"i cannot provide supporting documents\" which implies that the claim is false and lacks evidence to support it.\n",
            "Actual Justification: the claim is based on an old video from 2018 that was misleadingly linked to a recent event. the video was not related to any incident involving arvind kejriwal during the time in question.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb91de6a9edc16c676633\n",
            "Found 7 documents.\n",
            "['FAKE', 'The claim states that the NDRF\\'s official records and news reports do not indicate that 41 teams were prepositioned specifically for Orissa and West Bengal in relation to a storm named \"Amphan\", contradicting the claim that 41 teams were prepositioned for Orissa and West Bengal.']\n",
            "Claim #4962\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "However, the NDRF's official records and news reports do not indicate that 41 teams were prepositioned specifically for Orissa and West Bengal in relation to a storm named \"Amphan.\" The storm you\n",
            "\n",
            "(NDRF) is a specialized force in India that is deployed to assist in disaster management and relief operations. The specific mention of 41 teams being prepositioned for Orissa and West Bengal, and\n",
            "\n",
            "- **Political Implications**: The BJP's focus on Bengal could be part of a broader strategy to expand its influence in the eastern region of India. This move might be aimed at consolidating its\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'41 teams are prepositioned for orissa, west bengal which are likely to be hit by amphan NDRF'.\n",
            "Claim: 41 teams are prepositioned for orissa, west bengal which are likely to be hit by amphan NDRF\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim states that the ndrf's official records and news reports do not indicate that 41 teams were prepositioned specifically for orissa and west bengal in relation to a storm named \"amphan\", contradicting the claim that 41 teams were prepositioned for orissa and west bengal.\n",
            "Actual Justification: the claim is accurate as 41 ndrf (national disaster response force) teams were prepositioned in orissa and west bengal to respond to the potential impact of cyclone amphan.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb91fe6a9edc16c676634\n",
            "Found 13 documents.\n",
            "['TRUE', '', 'The justification is that the claim is a statement made by Kailash Vijayvargiya, which is a factual claim that can be verified.']\n",
            "Claim #4963\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide specific documents or support for the claim \"Central forces should be deployed immediately in Bengal: Kailash Vijayvargiya\" as it is a statement and not a factual claim that can be\n",
            "\n",
            "* **Context of the Claim:** The claim suggests that there is a need for immediate deployment of central forces in Bengal. This could be related to various issues such as law and order, security\n",
            "\n",
            "However, I can offer some general information and context about the situation in Bengal and the role of central forces:\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Central forces should be deployed immediately in bengal: kailash vijayvargiya'.\n",
            "Claim: Central forces should be deployed immediately in bengal: kailash vijayvargiya\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the claim is a statement made by kailash vijayvargiya, which is a factual claim that can be verified.\n",
            "Actual Justification: the claim is true, as reported by the hindu. kailash vijayvargiya stated that central forces should be deployed immediately in bengal due to the situation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb922e6a9edc16c676635\n",
            "Found 2 documents.\n",
            "['TRUE', \"The claim is supported by the first sentence, which states that it's possible for Cristiano Ronaldo to watch the FIFA World Cup 2022 final match between Argentina and France in Qatar, as he is a well-known football player and a fan of the sport.\"]\n",
            "Claim #4964\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It's possible that Cristiano Ronaldo could have watched the FIFA World Cup 2022 final match between Argentina and France in Qatar, as he is a well-known football player and a fan of the sport.\n",
            "\n",
            "Cristiano Ronaldo the legendary Portuguese soccer player made a powerful statement after his teams recent victory. As the players celebrated Ronaldo was seen on camera waving a Palestinian flag a\n",
            "\n",
            "Cristiano Ronaldo is a Portuguese professional soccer player known for his involvement in various social and humanitarian causes. He has been vocal about issues related to human rights equality and\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Cristiano Ronaldo watching the FIFA World Cup 2022 final match between Argentina and France in Qatar.'.\n",
            "Claim: Cristiano Ronaldo watching the FIFA World Cup 2022 final match between Argentina and France in Qatar.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the first sentence, which states that it's possible for cristiano ronaldo to watch the fifa world cup 2022 final match between argentina and france in qatar, as he is a well-known football player and a fan of the sport.\n",
            "Actual Justification: the image circulating online does not show ronaldo watching the final match. it was taken during the 2018 fifa world cup in russia, and the claim that he is in qatar for the 2022 final is false.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb923e6a9edc16c676636\n",
            "Found 11 documents.\n",
            "['TRUE', '', 'The claim is supported by the context, which states that PM Modi \"expressed a preference for Giriraj Singh to be the Chief Minister of Bihar\", suggesting that PM Modi wrote a letter to BJP President JP Nadda requesting Giriraj Singh to be made the Chief Minister of Bihar.']\n",
            "Claim #4965\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Content:** PM Modi expressed a preference for Giriraj Singh to be the Chief Minister of Bihar. This suggests a desire to influence the party's decision-making process regarding the state's\n",
            "\n",
            "* **Giriraj Singh's Role:** The specific mention of Giriraj Singh suggests that he is a prominent figure within the BJP in Bihar or has been considered for a leadership position.\n",
            "\n",
            "support his government. The BJP's national president, Mr. J.P. Nadda, is expected to play a pivotal role in the campaign, as the party's success in Bihar is closely tied to its performance in the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'On November 5, days before the Bihar election results, PM Modi wrote a letter to BJP President JP Nadda expressing willingness that Giriraj Singh be made the Chief Minister of Bihar.'.\n",
            "Claim: On November 5, days before the Bihar election results, PM Modi wrote a letter to BJP President JP Nadda expressing willingness that Giriraj Singh be made the Chief Minister of Bihar.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the context, which states that pm modi \"expressed a preference for giriraj singh to be the chief minister of bihar\", suggesting that pm modi wrote a letter to bjp president jp nadda requesting giriraj singh to be made the chief minister of bihar.\n",
            "Actual Justification: the claim is false. the letter attributed to pm modi is fake. there is no evidence to suggest that pm modi wrote such a letter to bjp president jp nadda about making giriraj singh the chief minister of bihar.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb926e6a9edc16c676637\n",
            "Found 4 documents.\n",
            "['TRUE', '', 'According to the provided documents, the CDC continues to use the term \"COVID-19 pandemic\" to refer to the ongoing global health emergency, and there is no official update to transition from \"pandemic\" to \"outbreak\", contradicting the claim that the CDC has updated its terminology to describe it as a COVID-19 outbreak.']\n",
            "Claim #4966\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The CDC's website and official statements consistently use the term \"COVID-19 pandemic\" to describe the situation, acknowledging that the virus has caused a global pandemic with widespread impact.\n",
            "\n",
            "crisis as a \"COVID-19 outbreak.\" Instead, the CDC continues to use the term \"COVID-19 pandemic\" to refer to the ongoing global health emergency caused by the SARS-CoV-2 virus.\n",
            "\n",
            "The organization has not made any official update to transition from \"pandemic\" to \"outbreak.\"\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'The Centers for Disease Control and Prevention (CDC) has updated its terminology, transitioning from references to the 'COVID-19 pandemic' to describing it as a COVID-19 outbreak.'.\n",
            "Claim: The Centers for Disease Control and Prevention (CDC) has updated its terminology, transitioning from references to the 'COVID-19 pandemic' to describing it as a COVID-19 outbreak.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: according to the provided documents, the cdc continues to use the term \"covid-19 pandemic\" to refer to the ongoing global health emergency, and there is no official update to transition from \"pandemic\" to \"outbreak\", contradicting the claim that the cdc has updated its terminology to describe it as a covid-19 outbreak.\n",
            "Actual Justification: there is no evidence that the cdc has removed the term 'covid-19 pandemic' and replaced it with 'covid-19 outbreak' on its website. the cdc continues to refer to covid-19 as a pandemic on various pages of its website. the world health organization (who) declared covid-19 a pandemic in march 2020, and this designation has not changed.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb928e6a9edc16c676638\n",
            "Found 21 documents.\n",
            "['TRUE', '', 'The claim is true because the provided context mentions a real-life scenario of a rise in COVID-19 cases among inmates and staff at the Jaipur District Jail, which is a factual report.']\n",
            "Claim #4967\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            ". Government Records and Reports Explore governmentpublished reports and statistics related to COVID in Chhattisgarh. These reports might include data on case spikes and the corresponding public\n",
            "\n",
            "[Jaipur, India] - The Jaipur District Jail has reported a significant rise in COVID-19 cases among its inmates and staff. As of [date], 47 inmates have tested positive for the virus, with more cases\n",
            "\n",
            "- **Safety Measures**: While the shops are allowed to open, it is likely that strict safety protocols and social distancing measures will be implemented to minimize the risk of COVID-19 transmission.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Watch robbers follow covid protocol as they loot jewellery shop at gunpoint in aligarh.'.\n",
            "Claim: Watch robbers follow covid protocol as they loot jewellery shop at gunpoint in aligarh.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is true because the provided context mentions a real-life scenario of a rise in covid-19 cases among inmates and staff at the jaipur district jail, which is a factual report.\n",
            "Actual Justification: three robbers followed covid-19 protocols while looting a jewellery shop at gunpoint in aligarh, as reported by *the tribune india*.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb92be6a9edc16c676639\n",
            "Found 4 documents.\n",
            "['TRUE', '', 'The justification is that the claim is based on the provided footage and eyewitness accounts, which suggest that vehicles are being washed away by the floodwaters in Karachi, Pakistan. There is no evidence to suggest that the claim is false or exaggerated.']\n",
            "Claim #4968\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It's concerning to hear about the devastating floods in Pakistan, particularly in Karachi, where vehicles are being washed away. This situation highlights the severe impact of the floods on\n",
            "\n",
            "* Footage from different angles and perspectives capturing the following:\n",
            "        * Vehicles being washed away by the tide.\n",
            "        * People trying to save their cars.\n",
            "\n",
            "It sounds like you're describing a recent natural disaster in Pakistan. If you have specific questions or need information about the situation, feel free to ask! I can provide details about the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Vehicles getting washed away in Karachi, Pakistan, amid the ongoing floods in the country.'.\n",
            "Claim: Vehicles getting washed away in Karachi, Pakistan, amid the ongoing floods in the country.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claim is based on the provided footage and eyewitness accounts, which suggest that vehicles are being washed away by the floodwaters in karachi, pakistan. there is no evidence to suggest that the claim is false or exaggerated.\n",
            "Actual Justification: the viral video showing vehicles getting washed away was misattributed to the recent floods in pakistan. the video actually shows the 2011 tsunami in japan, not floods in karachi. the footage is from a completely different event and location, as confirmed by video verification and analysis.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb930e6a9edc16c67663a\n",
            "Found 54 documents.\n",
            "['TRUE', '', 'The justification is based on the context provided, which mentions that the decision to pursue land and labor reforms is influenced by \"political, economic, social, and legal factors\" and that the Modi government may be taking a \"cautious approach\" and \"carefully weighing\" the factors, indicating that they may wait before making a decision.']\n",
            "Claim #4969\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can provide some context and supporting points for the claim that Modi may wait before pursuing land and labor reforms. Here are some potential reasons and considerations\n",
            "\n",
            "I can provide some context and supporting points for the claim that Modi may wait before pursuing land and labor reforms. Here are a few reasons why\n",
            "\n",
            ". Political Sensitivity and Public Opinion\n",
            "\n",
            "The decision to pursue land and labor reforms is a complex one influenced by political economic social and legal factors. Modis government may be taking a cautious approach carefully weighing the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Modi may wait before pursuing land and labor reforms.'.\n",
            "Claim: Modi may wait before pursuing land and labor reforms.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is based on the context provided, which mentions that the decision to pursue land and labor reforms is influenced by \"political, economic, social, and legal factors\" and that the modi government may be taking a \"cautious approach\" and \"carefully weighing\" the factors, indicating that they may wait before making a decision.\n",
            "Actual Justification: the claim is true as reported by *the print*. the article discusses that prime minister narendra modi may delay pursuing land and labor reforms, considering the political environment and the potential challenges in implementing these reforms during the covid-19 recovery period.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb934e6a9edc16c67663b\n",
            "Found 13 documents.\n",
            "['TRUE', '', 'The claim is based on the provided documents, which describe a civil suit filed in a court in Mathura, India, seeking the removal of a mosque believed by some to be built on the birthplace of Krishna, a site of significant religious importance to Hindus.']\n",
            "Claim #4970\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The news you've provided is about a legal case in Mathura, India, where a civil suit has been filed seeking the removal of a mosque that was constructed on a site believed by some to be the birthplace\n",
            "\n",
            "2. **Legal Action**: A civil suit has been filed in a court in Mathura, seeking the removal of the mosque. The suit argues that the mosque was built on a site that is historically significant to\n",
            "\n",
            "3. **Religious Significance**: The site in question is believed by some Hindus to be the birthplace of Krishna, known as \"Varanasi\" or \"Mathura.\" The construction of a mosque on this site has been a\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Mathura: civil suit seeks removal of mosque from 'krishna birthplace''.\n",
            "Claim: Mathura: civil suit seeks removal of mosque from 'krishna birthplace'\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is based on the provided documents, which describe a civil suit filed in a court in mathura, india, seeking the removal of a mosque believed by some to be built on the birthplace of krishna, a site of significant religious importance to hindus.\n",
            "Actual Justification: the claim that a civil suit seeks the removal of a mosque from the 'krishna birthplace' in mathura is true. according to the indian express, a group of devotees filed a civil suit seeking the removal of the shahi idgah mosque, which they allege was built after a part of a hindu shrine was razed on orders of mughal emperor aurangzeb in the 17th century. the suit was filed in the mathura civil court.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb936e6a9edc16c67663c\n",
            "Found 8 documents.\n",
            "['TRUE', '', 'The justification is that the document \"Rejected\" states that the Governor has denied the request, indicating that Shiv Sena does not have the necessary support to form a government, which implies that the Governor has rejected their request.']\n",
            "Claim #4971\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **Rejected:** The Governor has denied this request, indicating that Shiv Sena does not have the necessary support to form a government.\n",
            "\n",
            "* **48-hour Shiv Sena Request:** Shiv Sena likely requested the Governor to give them 48 hours (two days) to prove their majority and form the government.\n",
            "\n",
            "* **Request for Government Formation:** This implies that Shiv Sena, after winning the state elections, approached the Governor to form a government.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Governor has rejected 48-hour shiv sena request for government formation: aaditya thackeray.'.\n",
            "Claim: Governor has rejected 48-hour shiv sena request for government formation: aaditya thackeray.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the document \"rejected\" states that the governor has denied the request, indicating that shiv sena does not have the necessary support to form a government, which implies that the governor has rejected their request.\n",
            "Actual Justification: according to aaditya thackeray, the maharashtra governor bhagat singh koshyari rejected shiv sena's request for an additional 48 hours to form the government. this followed the bjp's inability to form the government, and the shiv sena claimed it was ready to provide a letter of support.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb939e6a9edc16c67663d\n",
            "Found 9 documents.\n",
            "['TRUE', '', 'The given context does not mention a specific event or incident, but rather mentions \"attacks against Israeli targets\" and \"a powerful display of resistance and unity\" in cities like Paris, Lyon, and Marseille, which suggests that the claim is referring to a general pattern of protests or resistance against Israeli actions in those cities, rather than a specific incident.']\n",
            "Claim #4972\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "against Israeli actions have occurred regularly especially in major cities like Paris Lyon and Marseille.\n",
            "\n",
            "attacks against Israeli targets.\n",
            "\n",
            "against stone echoes through the streets a powerful display of resistance and unity. The womans bravery inspires her fellow villagers and her actions become a symbol of Palestinian resilience in the\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A street fight in Paris where three Israeli women overpowered 10 Arab men.'.\n",
            "Claim: A street fight in Paris where three Israeli women overpowered 10 Arab men.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not mention a specific event or incident, but rather mentions \"attacks against israeli targets\" and \"a powerful display of resistance and unity\" in cities like paris, lyon, and marseille, which suggests that the claim is referring to a general pattern of protests or resistance against israeli actions in those cities, rather than a specific incident.\n",
            "Actual Justification: the video is a staged stunt and has been falsely shared as a real street fight. it does not depict israeli women overpowering arab men.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb93be6a9edc16c67663e\n",
            "Found 14 documents.\n",
            "['TRUE', '', 'The claim is true because the text states \"The tragic death of a 14-year-old fan of Sushant Singh Rajput in Odisha is a deeply concerning and unfortunate incident.\" This explicitly mentions the death of a 14-year-old fan of Sushant Singh Rajput in Odisha, which is the same claim being verified.']\n",
            "Claim #4973\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The tragic death of a 14-year-old fan of Sushant Singh Rajput in Odisha is a deeply concerning and unfortunate incident. It is important to approach this situation with empathy and sensitivity,\n",
            "\n",
            "The death of Sushant Singh Rajput, a popular Bollywood actor, has been a highly publicized and controversial case. The actor was found dead in his home in Mumbai on June 14, 2020, and the cause of\n",
            "\n",
            "the truth behind Sushant Singh Rajput's death.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Sushant singh rajput's 14-year-old fan commits suicide in odisha.'.\n",
            "Claim: Sushant singh rajput's 14-year-old fan commits suicide in odisha.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is true because the text states \"the tragic death of a 14-year-old fan of sushant singh rajput in odisha is a deeply concerning and unfortunate incident.\" this explicitly mentions the death of a 14-year-old fan of sushant singh rajput in odisha, which is the same claim being verified.\n",
            "Actual Justification: the claim is supported by the article, which reports that a 14-year-old fan of sushant singh rajput committed suicide in odisha, allegedly due to the actor's death.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb93de6a9edc16c67663f\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The claim is supported by the provided context, which mentions that 12 Hindu tribal people, including 10 women and 2 children, were burnt to death by TMC workers in Birbhum, West Bengal.']\n",
            "Claim #4974\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement you provided describes a tragic incident involving the deaths of 12 Hindu tribal people, including 10 women and 2 children, who were burnt to death by TMC (Trinamool Congress) workers in\n",
            "\n",
            "I'm sorry, but I cannot provide specific supporting documents for the claim about the women and children who were burnt to death in Bengal's Birbhum. As an AI language model, I do not have access to\n",
            "\n",
            "**Claim:** A worker was beaten to death in West Bengal, and the BJP (Bharatiya Janata Party) has blamed the TMC (Trinamool Congress).\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'12 Hindu tribal people — 10 women and 2 children — were burnt to death by TMC workers in Birbhum, West Bengal.'.\n",
            "Claim: 12 Hindu tribal people — 10 women and 2 children — were burnt to death by TMC workers in Birbhum, West Bengal.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the provided context, which mentions that 12 hindu tribal people, including 10 women and 2 children, were burnt to death by tmc workers in birbhum, west bengal.\n",
            "Actual Justification: the claim that 12 hindu tribal people were burnt to death by tmc workers in birbhum is false. the victims in the birbhum violence were not specifically identified as hindus, and there is no evidence to support that the killings were based on their religious identity. furthermore, the perpetrators of the attack have not been conclusively identified as tmc workers, and the incident is under investigation.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb93ee6a9edc16c676640\n",
            "Found 9 documents.\n",
            "['FAKE', '', 'The document explicitly states that \"this is a false statement\" and \"I cannot provide supporting documents for the claim\", indicating that the claim is entirely fabricated and has no basis in reality.']\n",
            "Claim #4975\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Donald Trump was shot in the chest and saved by a bulletproof vest as this is a false statement. Donald Trump the th President of the United\n",
            "\n",
            "I cannot provide supporting documents for the claim that Donald Trump was shot in the chest and saved by a bulletproof vest.\n",
            "\n",
            "details and outcomes of this incident would depend on the source and the context of the news article you are referring to.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Donald trump was shot in the chest but was saved because of the bulletproof vest.'.\n",
            "Claim: Donald trump was shot in the chest but was saved because of the bulletproof vest.\n",
            "Predicted Label: fake\n",
            "Actual Label: fake\n",
            "Predicted Justification: the document explicitly states that \"this is a false statement\" and \"i cannot provide supporting documents for the claim\", indicating that the claim is entirely fabricated and has no basis in reality.\n",
            "Actual Justification: the claim that this picture shows donald trump was also shot in the chest but was saved because of the bulletproof vest is false. according to india today, the photo is misleading. the apparent bullet hole is actually a fold in the jacket of a secret service agent protecting trump. the original photo shows no such hole in trump's jacket.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb940e6a9edc16c676641\n",
            "Found 15 documents.\n",
            "['TRUE', 'The justification is that the claim is being made repeatedly, but the supporting documents are not provided, implying that there is no evidence to support the claim.']\n",
            "Claim #4976\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Hezbollah forces destroyed an Israeli tank in Lebanon.\n",
            "\n",
            "I cannot provide supporting documents for the claim that Hezbollah forces destroyed an Israeli tank in Lebanon.\n",
            "\n",
            "I cannot provide supporting documents for the claim that Hezbollah forces destroyed an Israeli tank in Lebanon.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Hezbollah forces destroying an israeli tank in lebanon.'.\n",
            "Claim: Hezbollah forces destroying an israeli tank in lebanon.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the claim is being made repeatedly, but the supporting documents are not provided, implying that there is no evidence to support the claim.\n",
            "Actual Justification: the claim that this video shows hezbollah forces destroying an israeli tank in lebanon is false. according to india today, the video is actually from the ongoing conflict in ukraine and shows a russian tank being destroyed in luhansk. it has no connection to recent events involving hezbollah and israeli forces.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb944e6a9edc16c676642\n",
            "Found 18 documents.\n",
            "['TRUE', '', 'The justification is based on the provided documents, which state that the grace period for premium payments has been extended until May 31, as specified in the announcement and press release.']\n",
            "Claim #4977\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* Announce the extension of the grace period for life insurance policies.\n",
            "    * Specify the original grace period and the new extended date (May 31).\n",
            "\n",
            "* **Explanation:** Clearly state that the grace period for premium payments has been extended until May 31. Reference the press release and highlight the reasons for this extension.\n",
            "\n",
            "* **Headline:** \"Life Insurance Company Extends Grace Period for Policyholders\"\n",
            "* **Date:** [Insert Date]\n",
            "* **Company Name:** [Your Insurance Company Name]\n",
            "* **Body:**\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Grace period for life insurance policies extended till may 31.'.\n",
            "Claim: Grace period for life insurance policies extended till may 31.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is based on the provided documents, which state that the grace period for premium payments has been extended until may 31, as specified in the announcement and press release.\n",
            "Actual Justification: the claim is verified by the article, which reports that the insurance regulatory and development authority of india (irdai) has extended the grace period for life insurance policies till may 31 due to the ongoing covid-19 pandemic.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb946e6a9edc16c676643\n",
            "Found 15 documents.\n",
            "['FAKE', '', 'The justification is that the claim is repeatedly stated as \"I cannot provide supporting documents for the claim\", implying that the claim is false and there is no evidence to support it.']\n",
            "Claim #4978\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that a COVID patient died while awaiting treatment at a private hospital in Kolkata.\n",
            "\n",
            "I cannot provide supporting documents for the claim that a COVID patient died while awaiting treatment at a private hospital in Kolkata.\n",
            "\n",
            "I cannot provide supporting documents for the claim that a COVID patient died while awaiting treatment at a private hospital in Kolkata.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Covid patient dies awaiting treatment by kolkata pvt hospital'.\n",
            "Claim: Covid patient dies awaiting treatment by kolkata pvt hospital\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the claim is repeatedly stated as \"i cannot provide supporting documents for the claim\", implying that the claim is false and there is no evidence to support it.\n",
            "Actual Justification: the claim that a covid-19 patient died while awaiting treatment by a private hospital in kolkata is true. according to etv bharat, a covid-19 patient passed away on august 11, 2020, after being denied timely treatment by a private hospital in kolkata.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb949e6a9edc16c676644\n",
            "Found 16 documents.\n",
            "['TRUE', \"The claim states that India's single-day spike drops to 55,342, and the total number of confirmed COVID-19 cases in India is nearing 7.2 million. The provided information supports this claim, stating that as of the current date, India's COVID-19 tally has crossed 33.8 lakh (3,380,000) cases, which is less than 7.2 million.\"]\n",
            "Claim #4979\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Here's a breakdown of the information you provided and how it supports the claim:\n",
            "\n",
            "* **Claim:** \"Covid-19: India's single-day spike drops to 55,342 as tally approaches 72 lakh.\"\n",
            "\n",
            "single day. The \"tally approaching 72 lakh\" suggests that the total number of confirmed COVID-19 cases in India is nearing 7.2 million.\n",
            "\n",
            "in the world. As of [current date], India's COVID-19 tally has crossed 33.8 lakh (3,380,000) cases.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'covid-19: India's single-day spike drops to 55,342 as tally approaches 72 lakh.'.\n",
            "Claim: covid-19: India's single-day spike drops to 55,342 as tally approaches 72 lakh.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim states that india's single-day spike drops to 55,342, and the total number of confirmed covid-19 cases in india is nearing 7.2 million. the provided information supports this claim, stating that as of the current date, india's covid-19 tally has crossed 33.8 lakh (3,380,000) cases, which is less than 7.2 million.\n",
            "Actual Justification: the claim that \"india's single-day spike in covid-19 cases dropped to 55,342 as the tally approached 72 lakh\" is supported. according to the ministry of health and family welfare, india reported 55,342 new cases in a single day, and the total number of cases reached 71,75,881, which is close to 72 lakh.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb94ce6a9edc16c676645\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The claim is not about Rupesh Baisoya\\'s murder, but rather about the murder of a 20-year-old Hindu girl from West Midnapore, allegedly gang-raped and murdered by individuals described as \"Rohingyas and Bangladeshi jihadis\". The provided context does not mention Rupesh Baisoya\\'s murder, and the claim about him being murdered by the \"Bangladeshi drug mafia\" is not supported by the given information.']\n",
            "Claim #4980\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you've provided a snippet of information about an incident involving the murder of a man named Rupesh Baisoya in Delhi, allegedly linked to the \"Bangladeshi drug mafia.\" However, the\n",
            "\n",
            "* **Victim:** A 20-year-old Hindu girl from West Midnapore.\n",
            "\n",
            "* **Allegations:** She was allegedly gang-raped and murdered by individuals described as \"Rohingyas and Bangladeshi jihadis.\"\n",
            "\n",
            "- The BHIM army chief, a social activist, and the SP (Samajwadi Party) leaders met with the family of the victim, a 19-year-old Dalit woman who was allegedly gang-raped and murdered in Hathras,\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'In the afternoon of october 4, rebel AAP mla kapil mishra alleged in a tweet that a man named Rupesh Baisoya was murdered in delhi by 'Bangladeshi drug mafia'.'.\n",
            "Claim: In the afternoon of october 4, rebel AAP mla kapil mishra alleged in a tweet that a man named Rupesh Baisoya was murdered in delhi by 'Bangladeshi drug mafia'.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is not about rupesh baisoya's murder, but rather about the murder of a 20-year-old hindu girl from west midnapore, allegedly gang-raped and murdered by individuals described as \"rohingyas and bangladeshi jihadis\". the provided context does not mention rupesh baisoya's murder, and the claim about him being murdered by the \"bangladeshi drug mafia\" is not supported by the given information.\n",
            "Actual Justification: the claim that a man named rupesh baisoya was murdered in delhi by 'bangladeshi drug mafia' is false. according to alt news, the delhi police arrested the alleged perpetrators, who were not bangladeshi but residents of delhi. the incident was related to a brawl over drugs, but there was no involvement of a 'bangladeshi drug mafia'.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb94ee6a9edc16c676646\n",
            "Found 11 documents.\n",
            "['TRUE', '', 'The statement implies that Matuas in West Bengal do not require traditional land ownership certificates (patta) but instead are advocating for the implementation of the CAA (Citizenship Amendment Act) of land, which is consistent with the given context.']\n",
            "Claim #4981\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Mr. Thakur's statement implies that the Matuas in West Bengal do not necessarily require traditional land ownership certificates (patta) but instead are advocating for the implementation of the CAA\n",
            "\n",
            "of land. The statement suggests that Matuas do not require traditional land ownership certificates (patta) but instead advocate for something else.\n",
            "\n",
            "The statement made by BJP MP Shantanu Thakur regarding Matuas in West Bengal is a specific reference to a community and their land rights. Here's a breakdown of the key points:\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Matuas don't need patta land, we only want caa in west bengal, says bjp mp shantanu thakur.'.\n",
            "Claim: Matuas don't need patta land, we only want caa in west bengal, says bjp mp shantanu thakur.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the statement implies that matuas in west bengal do not require traditional land ownership certificates (patta) but instead are advocating for the implementation of the caa (citizenship amendment act) of land, which is consistent with the given context.\n",
            "Actual Justification: the claim is verified by the article, which reports that bjp mp shantanu thakur stated that the matua community does not require patta land but wants the implementation of the caa in west bengal.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb950e6a9edc16c676647\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The given context does not mention anything about a man performing namaz in the aisle and kicking windows in an Indian aircraft during flight. The context only talks about the Indian Air Force performing synchronized maneuvers with their aircraft, which is a common practice for their fighter jets and transport planes.']\n",
            "Claim #4982\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "from fighter jets to transport planes, performing synchronized maneuvers that leave spectators in awe. It is a testament to the Indian Air Force's role in safeguarding the country's sovereignty and\n",
            "\n",
            "It sounds like you're describing a memorable moment in cricket, where Mohammed Siraj, an Indian cricketer, celebrated a significant achievement by jumping dramatically high in the air during the Asia\n",
            "\n",
            "reports of a specific aircraft performing stunts.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'A man performing namaz in the aisle and kicking windows in an Indian aircraft during flight.'.\n",
            "Claim: A man performing namaz in the aisle and kicking windows in an Indian aircraft during flight.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not mention anything about a man performing namaz in the aisle and kicking windows in an indian aircraft during flight. the context only talks about the indian air force performing synchronized maneuvers with their aircraft, which is a common practice for their fighter jets and transport planes.\n",
            "Actual Justification: the video is not from india. it was filmed on a flight between pakistan and the uae, not in an indian aircraft as claimed.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb953e6a9edc16c676648\n",
            "Found 13 documents.\n",
            "['TRUE', 'The claim \"Two held in connection with BJP leader Manish Shukla\\'s killing in Bengal\" is supported by the incident mentioned in the documents, which states that Manish Kumar was killed on July 22, 2020, in the Saran district, and the police\\'s efforts to investigate and bring the perpetrators to justice, indicating that the claim is true.']\n",
            "Claim #4983\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The arrest of two individuals in connection with the killing of BJP leader Manish Shukla in Bengal is a significant development in the case. The police's efforts to investigate and bring the\n",
            "\n",
            "The recent incident of a BJP leader being shot dead in West Bengal has sparked concern and calls for a thorough investigation. The victim, identified as [Name of the BJP Leader], was allegedly shot by\n",
            "\n",
            "**Incident:**\n",
            "- Manish Kumar, a resident of Bihar, was killed on July 22, 2020, in the Saran district.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Two held in connection with bjp leader manish shukla's killing in bengal.'.\n",
            "Claim: Two held in connection with bjp leader manish shukla's killing in bengal.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim \"two held in connection with bjp leader manish shukla's killing in bengal\" is supported by the incident mentioned in the documents, which states that manish kumar was killed on july 22, 2020, in the saran district, and the police's efforts to investigate and bring the perpetrators to justice, indicating that the claim is true.\n",
            "Actual Justification: two individuals were arrested in connection with the killing of bjp leader manish shukla in bengal, as reported by *the tribune*.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb957e6a9edc16c676649\n",
            "Found 39 documents.\n",
            "['TRUE', 'The justification is that the text states \"Many Indian states and cities organize special programs, speeches, and ceremonies at August Kranti Maidan to remember the martyrs of the Quit India Movement\", which implies that the Quit India Day martyrs are indeed remembered at August Kranti Maidan.']\n",
            "Claim #4984\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I can provide some supporting information and documents for the claim Quit India Day martyrs remembered at August Kranti Maidan but please note that I cannot directly access or provide specific\n",
            "\n",
            "Many Indian states and cities organize special programs speeches and ceremonies at August Kranti Maidan to remember the martyrs of the Quit India Movement. These events often include speeches by\n",
            "\n",
            "the remembrance of martyrs at August Kranti Maidan.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Quit india day martyrs remembered at august kranti maidan.'.\n",
            "Claim: Quit india day martyrs remembered at august kranti maidan.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the text states \"many indian states and cities organize special programs, speeches, and ceremonies at august kranti maidan to remember the martyrs of the quit india movement\", which implies that the quit india day martyrs are indeed remembered at august kranti maidan.\n",
            "Actual Justification: the article confirms that quit india day martyrs were remembered at mumbai's august kranti maidan, a significant site in india's independence movement.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb95de6a9edc16c67664a\n",
            "Found 3 documents.\n",
            "['TRUE', '', 'The given context states that Sanjay Raut is a prominent leader within Shiv Sena and a Member of the Legislative Assembly MLA from the party, which implies that he is a prominent figure in the Shiv Sena party. The event mentioned, \"sanjay raut meets sharad pawar for 2nd time, rules out new proposals between shiv sena, bjp,\" is mentioned as a specific event, which suggests that it is a real event and not a fabrication.']\n",
            "Claim #4985\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Sanjay RAUT is a prominent figure in the Shiv Sena party a regional political party based in Maharashtra India.\n",
            "\n",
            "Congress Party (NCP) in India. However, the specific event you're mentioning, \"sanjay raut meets sharad pawar for 2nd time, rules out new proposals between shiv sena, bjp,\" doesn't seem to be a\n",
            "\n",
            "Sanjay Raut Sanjay Raut is a prominent leader within Shiv Sena and a Member of the Legislative Assembly MLA from the party.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'sanjay raut meets sharad pawar for 2nd time, rules out new proposals between shiv sena, bjp.'.\n",
            "Claim: sanjay raut meets sharad pawar for 2nd time, rules out new proposals between shiv sena, bjp.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given context states that sanjay raut is a prominent leader within shiv sena and a member of the legislative assembly mla from the party, which implies that he is a prominent figure in the shiv sena party. the event mentioned, \"sanjay raut meets sharad pawar for 2nd time, rules out new proposals between shiv sena, bjp,\" is mentioned as a specific event, which suggests that it is a real event and not a fabrication.\n",
            "Actual Justification: sanjay raut confirmed that there are no new proposals for collaboration between shiv sena and bjp after his second meeting with sharad pawar.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb95fe6a9edc16c67664b\n",
            "Found 6 documents.\n",
            "['FAKE', \"The claim is contradicted by Rajinikanth's own statement in a press conference, where he explicitly stated that he would not be joining politics due to his frail health, making it impossible for him to announce a political party.\"]\n",
            "Claim #4986\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that Rajinikanth will announce his political party on December 31 and launch it in January. As an AI language model, I do not have access to\n",
            "\n",
            "Rajinikanth, in a press conference, stated that he would not be joining politics, citing his frail health as a primary reason. He expressed his gratitude to his fans and well-wishers for their\n",
            "\n",
            "Rajya Sabha Website Check the official website of the Rajya Sabha httpswww.rajyasabha.nic.inhttpswww.rajyasabha.nic.in for news releases press statements or announcements related to the election\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Rajinikanth to announce his long-anticipated political party on december 31, launch it in january'.\n",
            "Claim: Rajinikanth to announce his long-anticipated political party on december 31, launch it in january\n",
            "Predicted Label: fake\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is contradicted by rajinikanth's own statement in a press conference, where he explicitly stated that he would not be joining politics due to his frail health, making it impossible for him to announce a political party.\n",
            "Actual Justification: rajinikanth has confirmed plans to announce his political party on december 31 and officially launch it in january, a move that has been eagerly awaited by his supporters.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb960e6a9edc16c67664c\n",
            "Found 11 documents.\n",
            "['TRUE', \"The statement is TRUE because the provided context confirms that a lab technician from Kanpur was indeed abducted and killed, as stated by the police. The family's accusation of police connivance is also mentioned, indicating that the event is not just a tragic incident but also a complex situation with potential police involvement.\"]\n",
            "Claim #4987\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement \"abducted, kanpur lab technician killed, say cops; family accuses police of connivance\" suggests a complex situation involving a missing person, a tragic outcome, and a family's\n",
            "\n",
            "- **Abduction and Death:** A lab technician from Kanpur was abducted, and unfortunately, the individual did not survive. The police have confirmed this tragic event.\n",
            "\n",
            "that the family believes the police might have known about or even participated in the abduction and subsequent death.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'abducted kanpur lab technician killed, say cops; family accuses police of connivance'.\n",
            "Claim: abducted kanpur lab technician killed, say cops; family accuses police of connivance\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the statement is true because the provided context confirms that a lab technician from kanpur was indeed abducted and killed, as stated by the police. the family's accusation of police connivance is also mentioned, indicating that the event is not just a tragic incident but also a complex situation with potential police involvement.\n",
            "Actual Justification: the claim that an abducted kanpur lab technician was killed and that his family accused the police of connivance is true. according to the statesman, the lab technician, sanjeet yadav, was kidnapped and later killed. his family alleged that the police were involved in the incident, claiming that the police forced them to arrange a ransom of rs 30 lakh, which the kidnappers escaped with in the presence of the police. the police later informed the family that sanjeet had been killed, but his body was yet to be recovered. the incident led to the suspension of several police officers and an investigation into the matter.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb964e6a9edc16c67664d\n",
            "Found 16 documents.\n",
            "['TRUE', \"The given context provides quotes or statements from residents directly describing their experiences and the reasons why they believe 4G internet services should be restored, as well as recent news articles from reputable sources that mention residents' protests or petitions demanding the restoration of 4G internet.\"]\n",
            "Claim #4988\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "**Personal Testimonies:**\n",
            "\n",
            "* If possible, include quotes or statements from residents directly describing their experiences and the reasons why they believe 4G internet services should be restored.\n",
            "\n",
            "* Search for recent news articles from reputable sources (e.g., The Hindu, The Wire, The Indian Express) that mention residents' protests or petitions demanding the restoration of 4G internet\n",
            "\n",
            "**Petition Signatures:**\n",
            "\n",
            "* If there are any publicly available online petitions or signatures from residents demanding the restoration of 4G, include screenshots or links to these documents.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Residents demand restoration of 4g in j&k.'.\n",
            "Claim: Residents demand restoration of 4g in j&k.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given context provides quotes or statements from residents directly describing their experiences and the reasons why they believe 4g internet services should be restored, as well as recent news articles from reputable sources that mention residents' protests or petitions demanding the restoration of 4g internet.\n",
            "Actual Justification: the claim is verified by the article, which reports that residents in jammu and kashmir have been demanding the restoration of 4g internet services in the region.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb966e6a9edc16c67664e\n",
            "Found 2 documents.\n",
            "['TRUE', \"The given information states that Maharashtra's lockdown measures will remain in place beyond June 30, 2021, which contradicts the initial claim that the lockdown was extended till July 31, 2020.\"]\n",
            "Claim #4989\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The information you provided describes the extension of lockdown measures in Maharashtra until July 31, 2020, and the announcement of specific curbs and relaxations in Tamil Nadu until July 5, 2020.\n",
            "\n",
            "Maharashtra's Chief Minister, Uddhav Thackeray, has announced that the state's lockdown measures will remain in place beyond June 30, 2021. This decision comes as the state continues to grapple with a\n",
            "\n",
            "The lockdown measures in Maharashtra have been in effect since March 2020, with periodic relaxations and restrictions imposed based on the state's COVID-19 situation. The government has been closely\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Maharashtra extends lockdown till july 31, tamil nadu announces curbs and relaxations till july 5.'.\n",
            "Claim: Maharashtra extends lockdown till july 31, tamil nadu announces curbs and relaxations till july 5.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given information states that maharashtra's lockdown measures will remain in place beyond june 30, 2021, which contradicts the initial claim that the lockdown was extended till july 31, 2020.\n",
            "Actual Justification: the claim is accurate as per the article, which reports that maharashtra extended its lockdown until july 31, while tamil nadu implemented specific curbs and relaxations until july 5.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb969e6a9edc16c67664f\n",
            "Found 4 documents.\n",
            "['TRUE', '', 'The justification is that the provided documents show that the death toll has risen to 7,200, which matches the claim.']\n",
            "Claim #4990\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "- **Death Toll:** India's COVID-19 death toll has risen to 7,200.\n",
            "- **Record Jump in Cases:** There has been a record jump in the number of COVID-19 cases in India.\n",
            "\n",
            "- India's COVID-19 cases have surpassed the 4.9 million mark.\n",
            "- The death toll has risen to over 80,000.\n",
            "\n",
            "- **Total Cases and Deaths:** As of August 16, India reported a total of over 2.7 million confirmed COVID-19 cases, with the death toll crossing 52,000. The number of active cases was around 700,000,\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'India's covid-19 death toll rises to 7,200, record jump in cases'.\n",
            "Claim: India's covid-19 death toll rises to 7,200, record jump in cases\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the provided documents show that the death toll has risen to 7,200, which matches the claim.\n",
            "Actual Justification: the article confirms that india's covid-19 death toll reached 7,200 with a significant increase in cases. the claim is accurate based on the reported statistics provided in the source article.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb96ce6a9edc16c676650\n",
            "Found 7 documents.\n",
            "['TRUE', 'The claim matches the given context, stating that the Supreme Court of India has recently dismissed the anticipatory bail plea filed by activist Rehana, which is consistent with the provided information.']\n",
            "Claim #4991\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The Supreme Court of India has recently dismissed the anticipatory bail plea filed by activist Rehana. The court's decision was based on the grounds that Rehana's activities and statements were deemed\n",
            "\n",
            "The rejection of Rehana's anticipatory bail plea has also raised questions about the balance between freedom of expression and public order in India. It highlights the ongoing tensions between the\n",
            "\n",
            "Claim The Supreme Court SC of India refused to entertain the bail plea of activist Sudha.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'SC rejects activist rehana's anticipatory bail plea'.\n",
            "Claim: SC rejects activist rehana's anticipatory bail plea\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim matches the given context, stating that the supreme court of india has recently dismissed the anticipatory bail plea filed by activist rehana, which is consistent with the provided information.\n",
            "Actual Justification: the claim is based on the report that the supreme court rejected activist rehana's anticipatory bail plea in connection with the case against her.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb96de6a9edc16c676651\n",
            "Found 6 documents.\n",
            "['TRUE', 'The given context does not explicitly state that Japanese performers wore Indian tricolour-coordinated clothing and performed Surya Namaskar, but it does mention that the Indian tricolour was used in the Tokyo Olympics opening ceremony and that Surya Namaskar was performed, indicating a cultural exchange between Japan and India, but it does not specify the performers.']\n",
            "Claim #4992\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "That's an interesting observation! The use of the Indian tricolour in the Tokyo Olympics opening ceremony, along with the performance of Surya Namaskar, highlights the cultural exchange and\n",
            "\n",
            "This particular performance at the Olympics showcased a beautiful blend of Japanese and Indian traditions, creating a unique and memorable moment in the history of the Games. It is a testament to the\n",
            "\n",
            "- **Cultural Performances:** Cultural events, including traditional dance performances, music, and storytelling, are organized to showcase the rich cultural heritage of Nagaland's Hindu community.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'At the opening ceremony of Tokyo Olympics, Japanese performers wore Indian tricolour-coordinated clothing and performed Surya Namaskar.'.\n",
            "Claim: At the opening ceremony of Tokyo Olympics, Japanese performers wore Indian tricolour-coordinated clothing and performed Surya Namaskar.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not explicitly state that japanese performers wore indian tricolour-coordinated clothing and performed surya namaskar, but it does mention that the indian tricolour was used in the tokyo olympics opening ceremony and that surya namaskar was performed, indicating a cultural exchange between japan and india, but it does not specify the performers.\n",
            "Actual Justification: the claim is false. the performers were from mongolia, not japan, and they performed a different cultural routine, not surya namaskar. the clothing was not coordinated with the indian tricolour.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb971e6a9edc16c676652\n",
            "Found 12 documents.\n",
            "['TRUE', '', 'The claim is supported by the article, which mentions that the state government decided to put the new fines on hold for three months, indicating that the fines were not being fully enforced.']\n",
            "Claim #4993\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "stricter fines were fully enforced.\n",
            "\n",
            "1. **Report the Incident**: If you or someone you know has been a victim of illegal fines or harassment by police, it's crucial to report the incident to the appropriate authorities. This could\n",
            "\n",
            "the new fines on hold for three months. The article mentions, \"The state government on Tuesday decided to put on hold for three months the steep fines imposed for traffic violations under the new\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'After the implementation of new traffic rules, police are now illegally collecting fines from people by beating them.'.\n",
            "Claim: After the implementation of new traffic rules, police are now illegally collecting fines from people by beating them.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the article, which mentions that the state government decided to put the new fines on hold for three months, indicating that the fines were not being fully enforced.\n",
            "Actual Justification: the claim is false. the video showing police beating people is not related to the new traffic rules under the amended motor vehicles act. the incident in the video predates the implementation of the new rules, and the police actions were not connected to the collection of fines as claimed.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb975e6a9edc16c676653\n",
            "Found 2 documents.\n",
            "['TRUE', '', 'The claim states that the earthquake occurred on November 23, but the provided information reveals that the earthquake occurred on February 6, 2023, which contradicts the date mentioned in the claim.']\n",
            "Claim #4994\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It seems like you're referring to the recent earthquake that hit Turkey. The phrase \"Stranded cars\" suggests that vehicles were left immobile or damaged due to the earthquake.\n",
            "\n",
            "- **Earthquake Data**: The February 6, 2023, earthquake in Turkey was a significant event, with a magnitude of 7.8. It caused widespread damage and loss of life. You can find official reports and\n",
            "\n",
            "occurring in the aftermath of this event. The earthquake was centered near the city of Gaziantep and affected several provinces in southern Turkey, causing widespread destruction and loss of life.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Stranded cars shows the damage caused by an earthquake that occurred in Turkey in the early hours of November 23.'.\n",
            "Claim: Stranded cars shows the damage caused by an earthquake that occurred in Turkey in the early hours of November 23.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim states that the earthquake occurred on november 23, but the provided information reveals that the earthquake occurred on february 6, 2023, which contradicts the date mentioned in the claim.\n",
            "Actual Justification: the video showing stranded cars is not related to any earthquake in turkey on november 23. it is an old video from istanbul that depicts a traffic accident caused by a faulty traffic signal system, not an earthquake.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb978e6a9edc16c676654\n",
            "Found 5 documents.\n",
            "['TRUE', '', 'The claim is supported by the context, which mentions a \"planned protest by Haryana farmers on November 26\" with the intention to \"gherao\" (surround) the national capital. There is no evidence in the provided context to suggest that the claim is false or misleading.']\n",
            "Claim #4995\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The planned protest by Haryana farmers on November 26, with the intention to \"gherao\" (surround) the national capital, is a significant development in the ongoing farmers' movement in India. This\n",
            "\n",
            "Look for interviews or statements from Haryanas agriculture minister or other relevant government officials. They might provide insights into the governments plans and priorities regarding farmer\n",
            "\n",
            "Keep an eye on official government websites press releases or statements from the Haryana government. They might announce initiatives or proposals related to farmer welfare including potential\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Haryana farmers to gather on national highways on nov 26, plan to gherao national capital.'.\n",
            "Claim: Haryana farmers to gather on national highways on nov 26, plan to gherao national capital.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the context, which mentions a \"planned protest by haryana farmers on november 26\" with the intention to \"gherao\" (surround) the national capital. there is no evidence in the provided context to suggest that the claim is false or misleading.\n",
            "Actual Justification: the claim is accurate as haryana farmers planned to gather on national highways on november 26, 2020, and intended to gherao the national capital as part of their protest against farm laws.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb979e6a9edc16c676655\n",
            "Found 17 documents.\n",
            "['TRUE', '', 'The claim is mentioned in the context as \"Offering sweets to Prime Minister Modi can be seen as a gesture of appreciation and support for the government\\'s role in facilitating the temple\\'s construction.\" This implies that Murli Manohar Joshi, a prominent leader and key advocate for the temple\\'s construction, may have offered sweets to PM Modi, supporting the claim.']\n",
            "Claim #4996\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "2. **Symbolism**: Offering sweets to Prime Minister Modi can be seen as a gesture of appreciation and support for the government's role in facilitating the temple's construction. It also symbolizes\n",
            "\n",
            ". Murli Manohar Joshi A former Minister of Human Resource Development and a senior BJP leader. He was charged with conspiracy and incitement to violence.\n",
            "\n",
            "Joshi is a prominent leader, has been a key advocate for the temple's construction.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Veteran BJP leader Murli Manohar Joshi offering sweets to PM Modi as soon as Ram Temple construction began in Ayodhya.'.\n",
            "Claim: Veteran BJP leader Murli Manohar Joshi offering sweets to PM Modi as soon as Ram Temple construction began in Ayodhya.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is mentioned in the context as \"offering sweets to prime minister modi can be seen as a gesture of appreciation and support for the government's role in facilitating the temple's construction.\" this implies that murli manohar joshi, a prominent leader and key advocate for the temple's construction, may have offered sweets to pm modi, supporting the claim.\n",
            "Actual Justification: the claim is false. the picture is not related to the ram temple construction in ayodhya. the image was taken in 2018 when murli manohar joshi met pm modi to offer sweets on the occasion of bjp’s victory in uttar pradesh. it is not linked to the ram temple event.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb97de6a9edc16c676656\n",
            "Found 14 documents.\n",
            "['TRUE', 'The statement is supported by the provided context, which mentions \"Haryana residents have shown solidarity and support by offering various forms of assistance to their Punjabi counterparts. This includes providing food, lodging, and other\" which implies that Haryana residents have indeed provided help, food, and lodging to Punjab farmers, leading to the gratitude and appreciation expressed in the statement.']\n",
            "Claim #4997\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The statement \"Punjab farmers thank Haryana residents for help, food, lodging\" reflects the gratitude and appreciation felt by the Punjabi farming community. It highlights the positive impact of\n",
            "\n",
            "* **Haryana's Support:** Haryana residents have shown solidarity and support by offering various forms of assistance to their Punjabi counterparts. This includes providing food, lodging, and other\n",
            "\n",
            "Overall, the story of Punjab farmers thanking Haryana residents for their support is a testament to the power of human connection and the potential for positive change through mutual aid.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Punjab farmers thank haryana residents for help, food, lodging.'.\n",
            "Claim: Punjab farmers thank haryana residents for help, food, lodging.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the statement is supported by the provided context, which mentions \"haryana residents have shown solidarity and support by offering various forms of assistance to their punjabi counterparts. this includes providing food, lodging, and other\" which implies that haryana residents have indeed provided help, food, and lodging to punjab farmers, leading to the gratitude and appreciation expressed in the statement.\n",
            "Actual Justification: the claim is accurate as the article reports that punjab farmers expressed gratitude to haryana residents for their help, including food and lodging, during their protests.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb980e6a9edc16c676657\n",
            "Found 27 documents.\n",
            "['TRUE', 'The justification is that the claim \"Letter to bs invoking section 7 of rbi act by govt has come under scrutiny\" is mentioned in the draft of a letter, which implies that the invocation of Section 7 of the RBI Act by the government is indeed under scrutiny.']\n",
            "Claim #4998\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "Here’s a draft of a letter addressing this issue:\n",
            "\n",
            "---\n",
            "\n",
            "**To:** [Recipient's Name], [Position], [Government Department]\n",
            "\n",
            "**Subject:** Scrutiny of Government's Invocation of Section 7 of the RBI Act\n",
            "\n",
            "I am writing to express my concerns regarding the recent invocation of Section 7 of the Reserve Bank of India (RBI) Act by the government. This provision, while intended to ensure the RBI's\n",
            "\n",
            "In summary, the invocation of Section 7 of the RBI Act is a regulatory action taken by the RBI, and the FinMin's silence may reflect a decision to allow the RBI to operate within its mandated powers.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Letter to bs invoking section 7 of rbi act by govt has come under scrutiny.'.\n",
            "Claim: Letter to bs invoking section 7 of rbi act by govt has come under scrutiny.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the justification is that the claim \"letter to bs invoking section 7 of rbi act by govt has come under scrutiny\" is mentioned in the draft of a letter, which implies that the invocation of section 7 of the rbi act by the government is indeed under scrutiny.\n",
            "Actual Justification: the article discusses the scrutiny surrounding the government's invocation of section 7 of the rbi act, emphasizing its controversial nature.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb984e6a9edc16c676658\n",
            "Found 10 documents.\n",
            "['TRUE', '', 'The claim is true because the provided context mentions the incident taking place in Bulandshahr, Uttar Pradesh, and the jeweller being robbed of gold and silver ornaments at gunpoint, which matches the details of the given claim.']\n",
            "Claim #4999\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "- The incident took place in Bulandshahr, a city in the Indian state of Uttar Pradesh.\n",
            "- The jeweller was robbed of gold and silver ornaments at gunpoint.\n",
            "\n",
            "- **Jewelry and Other Assets:** Along with the black money, the authorities also seized jewelry worth Rs 52 lakh. This suggests that the raids uncovered valuable assets, possibly belonging to the\n",
            "\n",
            "- Recently, she was seen buying onions in Chennai, which is a city in Tamil Nadu, India.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'In Tirupur, Tamil Nadu, a woman was attacked and robbed of jewelry worth several lakhs after she opened the gates of her house to offer water to a stranger.'.\n",
            "Claim: In Tirupur, Tamil Nadu, a woman was attacked and robbed of jewelry worth several lakhs after she opened the gates of her house to offer water to a stranger.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is true because the provided context mentions the incident taking place in bulandshahr, uttar pradesh, and the jeweller being robbed of gold and silver ornaments at gunpoint, which matches the details of the given claim.\n",
            "Actual Justification: the claim is true. a woman in tirupur was indeed attacked and robbed after opening her gates to offer water to a stranger. the robbers assaulted her and stole jewelry worth several lakhs.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb986e6a9edc16c676659\n",
            "Found 6 documents.\n",
            "['TRUE', '', 'The statement is true because the calculation confirms that the total number of names is 95,300, and the number of Muslim names is 61,945, which is consistent with the given information.']\n",
            "Claim #5000\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "To verify the statement that out of 95,300 names of freedom fighters inscribed on India Gate, 61,945 are Muslims, we need to check if the given information is consistent with the total number of\n",
            "\n",
            "The calculation confirms that the total number of names is 95,300, and the number of Muslim names is 61,945, which is consistent with the given information.\n",
            "\n",
            "Final Answer: The statement is correct.\n",
            "\n",
            "Step 1: Calculate the number of non-Muslim names.\n",
            "- Total names = 95,300\n",
            "- Muslim names = 61,945\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Out of 95,300 names of freedom fighters inscribed on India Gate, 61,945 are Muslims.'.\n",
            "Claim: Out of 95,300 names of freedom fighters inscribed on India Gate, 61,945 are Muslims.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the statement is true because the calculation confirms that the total number of names is 95,300, and the number of muslim names is 61,945, which is consistent with the given information.\n",
            "Actual Justification: there is no verification or credible data to support that 61,945 names inscribed on india gate belong to muslims. the claim made by owaisi is misleading.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb988e6a9edc16c67665a\n",
            "Found 24 documents.\n",
            "['TRUE', 'The justification is that the text does not contain any evidence or supporting documents to contradict the claim, and the phrase \"I cannot provide supporting documents\" suggests that the claim is false.']\n",
            "Claim #5001\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I cannot provide supporting documents for the claim that US President Donald Trump had allegedly tweeted recently that he has received a shot of the Russian vaccine. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that US President Donald Trump had allegedly tweeted about receiving a shot of the Russian vaccine. \n",
            "\n",
            "Heres why\n",
            "\n",
            "I cannot provide supporting documents for the claim that US President Donald Trump had allegedly tweeted about receiving a shot of the Russian vaccine. \n",
            "\n",
            "Heres why\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'US President Donald Trump had allegedly tweeted recently that he has received a shot of the Russian vaccine.'.\n",
            "Claim: US President Donald Trump had allegedly tweeted recently that he has received a shot of the Russian vaccine.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is that the text does not contain any evidence or supporting documents to contradict the claim, and the phrase \"i cannot provide supporting documents\" suggests that the claim is false.\n",
            "Actual Justification: the claim is false. donald trump did not tweet about receiving the russian vaccine. the tweet was fabricated, and there is no evidence that he made such a statement.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb98ce6a9edc16c67665b\n",
            "Found 14 documents.\n",
            "['TRUE', 'The given context provides a statement from the fact checker that they do not have specific supporting documents or articles for the claim, but suggests that relevant articles can be found by searching for specific keywords. This implies that the claim is not entirely false, and it is possible to find articles or information that support the claim, making it TRUE.']\n",
            "Claim #5002\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "I'm sorry, but I cannot provide specific supporting documents or articles for the claim \"Yashwant Sinha searches for relevance in Bihar, looks to make third front ahead of polls\" as I do not have\n",
            "\n",
            "India, and others often have articles on political developments, including those related to Yashwant Sinha and Bihar elections.\n",
            "\n",
            "valuable resources. Search for keywords like \"Yashwant Sinha,\" \"Bihar elections,\" \"third front,\" and \"political alliances\" to find relevant articles.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Yashwant sinha searches for relevance in bihar, looks to make third front ahead of polls'.\n",
            "Claim: Yashwant sinha searches for relevance in bihar, looks to make third front ahead of polls\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the given context provides a statement from the fact checker that they do not have specific supporting documents or articles for the claim, but suggests that relevant articles can be found by searching for specific keywords. this implies that the claim is not entirely false, and it is possible to find articles or information that support the claim, making it true.\n",
            "Actual Justification: yashwant sinha is reportedly exploring the possibility of forming a third front ahead of elections in bihar, seeking to create a political alternative to the existing parties.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb98fe6a9edc16c67665c\n",
            "Found 7 documents.\n",
            "['TRUE', '', 'The claim is supported by the context, which mentions a \"tragic incident involving a crab catcher who was killed by a tiger in the Sundarbans, a vast mangrove forest in the Bengal region of India and Bangladesh.\"']\n",
            "Claim #5003\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "It sounds like you're describing a tragic incident involving a crab catcher who was killed by a tiger in the Sundarbans, a vast mangrove forest in the Bengal region of India and Bangladesh. This area\n",
            "\n",
            "farmer's activities, the tiger's behavior, and the sequence of events leading to the fatal attack.\n",
            "\n",
            "The discovery of a tiger carcass in a forest in Goa, India, has sparked an investigation by wildlife authorities. The incident highlights the ongoing challenges in protecting and conserving tiger\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Crab catcher killed in tiger attack in bengal's sundarbans.'.\n",
            "Claim: Crab catcher killed in tiger attack in bengal's sundarbans.\n",
            "Predicted Label: true\n",
            "Actual Label: true\n",
            "Predicted Justification: the claim is supported by the context, which mentions a \"tragic incident involving a crab catcher who was killed by a tiger in the sundarbans, a vast mangrove forest in the bengal region of india and bangladesh.\"\n",
            "Actual Justification: a crab catcher was killed by a tiger in the sundarbans, a region known for its tiger population. the incident has raised concerns over human-wildlife conflict in the area.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb992e6a9edc16c67665d\n",
            "Found 13 documents.\n",
            "['TRUE', 'The claim is supported by the provided documents, which mention a \"massive group of bikers\" and a \"bikers\\' rally\", indicating a large gathering of bikers to show support for a child with cancer.']\n",
            "Claim #5004\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "* **20,000 Bikers:** The presence of a massive group of bikers shows the power of community and solidarity. Their willingness to gather and support the patient demonstrates a strong sense of\n",
            "\n",
            "* **Sustainability of Support:** While the bikers' rally was a powerful gesture, it's important to explore long-term ways to provide ongoing support to the child and their family.\n",
            "\n",
            "* **Inspiration for Others:** The bikers' actions could inspire other communities to organize similar events, fostering a culture of compassion and solidarity.\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'20,000 bikers in Germany rallying to cheer up a six-year-old cancer patient.'.\n",
            "Claim: 20,000 bikers in Germany rallying to cheer up a six-year-old cancer patient.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the claim is supported by the provided documents, which mention a \"massive group of bikers\" and a \"bikers' rally\", indicating a large gathering of bikers to show support for a child with cancer.\n",
            "Actual Justification: the video is not from germany, nor does it show bikers cheering up a cancer patient. the video is from a brazilian bike rally held in 2021, where bikers participated in a similar event. the claim is a misattribution of the footage.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb994e6a9edc16c67665e\n",
            "Found 22 documents.\n",
            "['TRUE', '', \"The given context does not mention the PLAAF shooting down an Indian Sukhoi Su-30 fighter jet in Tibet. Instead, it mentions an IAF fighter jet being shot down by Nepal's air defense forces after it entered Nepalese territory, and another scenario mentioning Tibet, but not involving the PLAAF.\"]\n",
            "Claim #5005\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The claim that the People’s Liberation Army Air Force (PLAAF) has shot down an Indian Sukhoi Su-30 fighter jet in Tibet is a serious and significant matter. However, as an AI assistant, I cannot\n",
            "\n",
            "The claim that the People’s Liberation Army Air Force (PLAAF) has shot down an Indian Sukhoi Su-30 fighter jet in Tibet is a serious and significant matter. However, as an AI assistant, I cannot\n",
            "\n",
            "This scenario describes a tragic incident involving an Indian Air Force (IAF) fighter jet that was shot down by Nepal's air defense forces after it entered Nepalese territory. The incident resulted in\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Expert on China claims People’s Liberation Army Air Force (PLAAF) has shot down an Indian Sukhoi Su-30 fighter jet in Tibet.'.\n",
            "Claim: Expert on China claims People’s Liberation Army Air Force (PLAAF) has shot down an Indian Sukhoi Su-30 fighter jet in Tibet.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the given context does not mention the plaaf shooting down an indian sukhoi su-30 fighter jet in tibet. instead, it mentions an iaf fighter jet being shot down by nepal's air defense forces after it entered nepalese territory, and another scenario mentioning tibet, but not involving the plaaf.\n",
            "Actual Justification: the claim is false. the so-called 'expert' spreading this information is based in pakistan and has no credible sources. no such incident involving the plaaf shooting down an indian sukhoi su-30 fighter jet in tibet has occurred.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Inserted Document ID: 678cb998e6a9edc16c67665f\n",
            "Found 9 documents.\n",
            "['TRUE', 'The justification is based on the provided context, which mentions \"The protest in London, which included pro-Pakistan and pro-Khalistan slogans, highlights the complex and sometimes conflicting interests of those involved in the farmers\\' agitation in Delhi.\" This sentence explicitly states that pro-Pakistan and pro-Khalistan slogans were raised during a protest in London, which is in support of the farmers\\' agitation in Delhi.']\n",
            "Claim #5006\n",
            "Prompt: Here are the relevant documents:\n",
            "\n",
            "The protest in London, which included pro-Pakistan and pro-Khalistan slogans, highlights the complex and sometimes conflicting interests of those involved in the farmers' agitation in Delhi. The\n",
            "\n",
            "The use of pro-Khalistan and pro-Pakistan slogans during a protest can be seen as a form of political expression, but it also carries potential implications for regional stability and the\n",
            "\n",
            "presence of pro-Khalistan slogans, which advocate for the creation of a separate state for the Punjabi-speaking regions of India, suggests that the protest may have a broader political agenda beyond\n",
            "\n",
            "Based on the above information,     provide in the first line only 'FAKE' or 'TRUE'. And provide the justification from the given context     in the second line.'Pro-Pakistan and pro-Khalistan slogans raised at a protest in London held in support of the ongoing farmers' agitation in Delhi.'.\n",
            "Claim: Pro-Pakistan and pro-Khalistan slogans raised at a protest in London held in support of the ongoing farmers' agitation in Delhi.\n",
            "Predicted Label: true\n",
            "Actual Label: fake\n",
            "Predicted Justification: the justification is based on the provided context, which mentions \"the protest in london, which included pro-pakistan and pro-khalistan slogans, highlights the complex and sometimes conflicting interests of those involved in the farmers' agitation in delhi.\" this sentence explicitly states that pro-pakistan and pro-khalistan slogans were raised during a protest in london, which is in support of the farmers' agitation in delhi.\n",
            "Actual Justification: the video being shared is an old video from a different event, not related to the current farmers' protest. the claim that this video shows a protest in support of the farmers' agitation in delhi is false.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Accuracy: 62.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import"
      ],
      "metadata": {
        "id": "7vAAPV0AUDq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "O2oTTtf8UFDX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sacrebleu.metrics import CHRF, TER\n",
        "from bert_score import score\n",
        "from bleurt import score as bleurt_score\n",
        "import json\n",
        "import pandas as pd\n",
        "import random\n",
        "import warnings\n",
        "from groq import Groq\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhARUbk3tT28",
        "outputId": "b591b099-0d85-4c51-ca63-902205333fdc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Metrics initialization\n",
        "rouge = Rouge()\n",
        "smoothing_function = SmoothingFunction().method4\n",
        "chrf = CHRF()\n",
        "ter = TER()\n",
        "bleurt_scorer = bleurt_score.BleurtScorer(\"BLEURT-20\")\n",
        "\n",
        "# Filter out empty justifications\n",
        "filtered_justifications = [\n",
        "    (actual, predicted)\n",
        "    for actual, predicted in zip(actual_justifications, predicted_justifications)\n",
        "    if predicted.strip()\n",
        "]\n",
        "\n",
        "# Calculate metrics\n",
        "def calculate_metrics_extended(justifications):\n",
        "    bleu_scores = []\n",
        "    rouge_scores = []\n",
        "    meteor_scores = []\n",
        "    chrf_scores = []\n",
        "    ter_scores = []\n",
        "    bert_scores = []\n",
        "    bleurt_scores = []\n",
        "    bart_scores = []\n",
        "\n",
        "    for ref, pred in justifications:\n",
        "        # BLEU score\n",
        "        bleu = sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothing_function)\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "        # ROUGE score\n",
        "        rouge_score = rouge.get_scores(pred, ref, avg=True)\n",
        "        rouge_scores.append(rouge_score)\n",
        "\n",
        "        # METEOR score\n",
        "        meteor = meteor_score([ref.split()], pred.split())\n",
        "        meteor_scores.append(meteor)\n",
        "\n",
        "        # ChrF\n",
        "        chrf_scores.append(chrf.corpus_score([pred], [[ref]]).score)\n",
        "\n",
        "        # TER\n",
        "        ter_scores.append(ter.corpus_score([pred], [[ref]]).score)\n",
        "\n",
        "        # BERTScore\n",
        "        P, R, F1 = score([pred], [ref], lang=\"en\", device=device)\n",
        "        bert_scores.append(F1.mean().item())\n",
        "\n",
        "        # BLEURT\n",
        "        bleurt_scores.append(bleurt_scorer.score(references=[ref], candidates=[pred])[0])\n",
        "\n",
        "        # BARTScore\n",
        "        bart_scores.append(bart_scorer.score([pred], [ref])[0])\n",
        "\n",
        "    return bleu_scores, rouge_scores, meteor_scores, chrf_scores, ter_scores, bert_scores, bleurt_scores, bart_scores\n",
        "\n",
        "# Calculate metrics\n",
        "bleu_scores, rouge_scores, meteor_scores, chrf_scores, ter_scores, bert_scores, bleurt_scores, bart_scores = calculate_metrics_extended(filtered_justifications)\n",
        "\n",
        "# Summarize and print results\n",
        "avg_rouge_1 = sum([score['rouge-1']['f'] for score in rouge_scores]) / len(rouge_scores)\n",
        "avg_rouge_2 = sum([score['rouge-2']['f'] for score in rouge_scores]) / len(rouge_scores)\n",
        "avg_rouge_l = sum([score['rouge-l']['f'] for score in rouge_scores]) / len(rouge_scores)\n",
        "\n",
        "print(f\"Average BLEU Score: {sum(bleu_scores) / len(bleu_scores):.4f}\")\n",
        "print(f\"Average METEOR Score: {sum(meteor_scores) / len(meteor_scores):.4f}\")\n",
        "print(f\"Average ChrF Score: {sum(chrf_scores) / len(chrf_scores):.4f}\")\n",
        "print(f\"Average TER Score: {sum(ter_scores) / len(ter_scores):.4f}\")\n",
        "print(f\"Average BERTScore F1: {sum(bert_scores) / len(bert_scores):.4f}\")\n",
        "print(f\"Average BLEURT Score: {sum(bleurt_scores) / len(bleurt_scores):.4f}\")\n",
        "print(f\"Average BARTScore: {sum(bart_scores) / len(bart_scores):.4f}\")\n",
        "print(f\"Average ROUGE-1 F1 Score: {avg_rouge_1:.4f}\")\n",
        "print(f\"Average ROUGE-2 F1 Score: {avg_rouge_2:.4f}\")\n",
        "print(f\"Average ROUGE-L F1 Score: {avg_rouge_l:.4f}\")\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (correct_predictions / total_processed_claims) * 100 if total_processed_claims > 0 else 0\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted', labels=[\"true\", \"fake\"])\n",
        "print(f\"F1 Score Average: {f1}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(actual_labels, predicted_labels, labels=[\"true\", \"fake\"])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"true\", \"fake\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "10454c728a434c7f9afe6a0e7f8a4c52",
            "11e2590f11374553b122f7b55a38127b",
            "32b04e2dbea245e9a4cb2b394afbb9f7",
            "0e505cdfab654d67a18a88445c64f561",
            "6be34d60460f478ebca44b0f9df5db56",
            "05aac84f025a484abeb4d99d3049bba7",
            "7fb091441c9a4e8db55d75598389e3ce",
            "150e72b2d08b4df2a756e0124a0f07f2",
            "dba4929b9ec24e599a14b51f41aa1b9b",
            "e3787eaa63864966b13cb4782e876bdd",
            "dbe29551da92428392ffb7260ddf0ade",
            "93b4e10a352047dab76214c3902c14e9",
            "52918b695ae247309215b29ad2d0d04b",
            "a96c6de0aabe4df782cc27c056eb66fc",
            "dec5b2f3f74b42e087e25e1f8f001e46",
            "9737dbdd1026491cae936e6e08453062",
            "1c7f7eec0c4240c5b3d5d71d8e0666a2",
            "c6122e5c2e4c47aa97f7dbfeeffc6548",
            "b6037da069824295a696721672e29949",
            "a94f9be8e2994d949923b0287dccfa6b",
            "142692b04d98422fa243943bcaa88165",
            "f273f296b39a4b6a9b5502032299079d",
            "cb5d5617bb9d401d91c17828be30cc8c",
            "db243bd6f9b142a99ab2b87c1fa6138b",
            "a7fd0a25e37142a1be65516dbed93e37",
            "cac975f02207447baae753016388043c",
            "e8eff1db869b4c049e8ab283aadb4f07",
            "4639d1488002453a92614e113596f3d2",
            "fa3bdb2ff56642fab89250af3a0d51b7",
            "9e1a3f5de7c043928ace6f4811f7b07c",
            "5ea54bd7f3984601a2ab0494e82ab7d5",
            "7309d622630e4d218c5986c4b78c5354",
            "cdaabca792a444efa4d072b00dcb8693",
            "1536d0a7fc21455f91d31b7392025d9c",
            "321f6b8266064e938092725dde977bfa",
            "c0c598ac6adf4ff883683d7769e0e1b9",
            "3189a75b786b464d9a68a0dc2be0ac65",
            "451b53bd148b42b2a62bbddd7bdb187d",
            "da3ae1a0c3234a2ca0e574a602e52354",
            "0498fbb51b0c41c38d99be09cb6884f0",
            "80d359a6b3d04366ba5202e0d4bc672a",
            "10a27d7dff9445f48eeb98b9a993bfeb",
            "967318d0d4c14317a331368500681e3b",
            "5f5bee841c8942fd8444a2493bd98f06",
            "4694d0c755764a6fbc3fc7c2344c93f2",
            "405ea57640d44dde8543209d34c2e488",
            "5707be7179d9423096254aa09884257f",
            "fa17d3f66bac40b684c75d843af6e12d",
            "69c8fdc71e1846e293c06f327f51e723",
            "cb2ebdb6c9344117b0900146db4c9882",
            "547a07e2c4494db68898b46aa4b0c994",
            "3b070b7de8104fbc95f24cbfab3f537b",
            "de84ee7e1903448992d0fe427b8d2718",
            "bf5ee879d00d4f87b4799eae8b68165a",
            "7c1effd8758b425ba72c97acfc60271f",
            "0062b1e98ff843028de8642dd04111c2",
            "7e3efb5886924672bfd2274222d6876e",
            "f18c65d9c9df4e10aaf5f090d4eb8724",
            "9bde4a8139a7464db1703ec9c5b89cf6",
            "25eb79baf8ca4fd7b7d89a6db19b79b9",
            "bb948c4ecf274400ace864221bf27934",
            "33af5f2d1da64ae6a360ad2cf4d91f22",
            "72c775a95fbb4da19816f4c783d74a10",
            "ddb72afeadb2491da0d359fb74dd4409",
            "4969959c897e41fa90d2471766e7a204",
            "e9e288587594499e80816d117afb86ac"
          ]
        },
        "id": "YxsjPiXkHK-W",
        "outputId": "13096112-9abc-4cc4-aa3c-39e6866c7ca6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10454c728a434c7f9afe6a0e7f8a4c52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93b4e10a352047dab76214c3902c14e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb5d5617bb9d401d91c17828be30cc8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1536d0a7fc21455f91d31b7392025d9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4694d0c755764a6fbc3fc7c2344c93f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0062b1e98ff843028de8642dd04111c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 0.0676\n",
            "Average METEOR Score: 0.2662\n",
            "Average ChrF Score: 37.4760\n",
            "Average TER Score: 121.8807\n",
            "Average BERTScore F1: 0.8774\n",
            "Average BLEURT Score: 0.4606\n",
            "Average BARTScore: -3.2223\n",
            "Average ROUGE-1 F1 Score: 0.3179\n",
            "Average ROUGE-2 F1 Score: 0.1184\n",
            "Average ROUGE-L F1 Score: 0.2700\n",
            "Model Accuracy: 62.47%\n",
            "F1 Score Average: 0.5841028745574284\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_t4WKjQZUOG0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}